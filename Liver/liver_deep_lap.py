# -*- coding: utf-8 -*-
"""Liver_Deep_Lap

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IKLBmx5_3ZUAktej_gOpF9rz-RIno7XD
"""

from google.colab import files
print("Upload your kaggle.json file (download from Kaggle > Account > Create New API Token)")
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Part 1: Setup and Data Loading for Liver Segmentation with DeepLab
# Run this in Google Colab

import os
import sys
import urllib.request
import tarfile
import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import nibabel as nib
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

print("üöÄ Part 1: Setting up Liver Segmentation with DeepLab")
print("="*60)

# ============================================================================
# STEP 1: Install Required Packages
# ============================================================================

def install_requirements():
    """Install all required packages for the project"""

    packages = [
        'nibabel',                    # For medical image processing
        'scikit-image',              # Image processing
        'opencv-python',             # Computer vision
        'plotly',                    # 3D visualization
        'ipywidgets',                # Interactive widgets
        'torch torchvision',         # PyTorch
        'torchvision',               # DeepLab models
        'monai',                     # Medical imaging AI
        'vtk',                       # 3D visualization
        'pyvista',                   # 3D mesh processing
        'trimesh',                   # 3D geometry
        'pillow',                    # Image handling
        'scipy'                      # Scientific computing
    ]

    print("üì¶ Installing required packages...")
    for package in packages:
        try:
            os.system(f'pip install -q {package}')
            print(f"‚úÖ Installed: {package}")
        except:
            print(f"‚ö†Ô∏è Failed to install: {package}")

# Uncomment the next line to install packages
# install_requirements()

# ============================================================================
# STEP 2: Setup Directories
# ============================================================================

def setup_directories():
    """Create project directory structure"""

    base_dir = Path("/content/liver_segmentation")
    dirs = {
        'base': base_dir,
        'data': base_dir / "data",
        'models': base_dir / "models",
        'results': base_dir / "results",
        'visualizations': base_dir / "visualizations",
        'checkpoints': base_dir / "checkpoints"
    }

    for name, path in dirs.items():
        path.mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Created: {path}")

    return dirs

# Setup directories
directories = setup_directories()

# ============================================================================
# STEP 3: Download and Extract Dataset
# ============================================================================

def download_dataset(data_dir):
    """Download Task03_Liver dataset"""

    url = "https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar"
    tar_path = data_dir / "Task03_Liver.tar"

    if tar_path.exists():
        print(f"‚úÖ Dataset already exists: {tar_path}")
        return tar_path

    print("üì• Downloading liver dataset...")
    try:
        urllib.request.urlretrieve(url, tar_path)
        print(f"‚úÖ Downloaded: {tar_path}")
        return tar_path
    except Exception as e:
        print(f"‚ùå Download failed: {e}")
        return None

def extract_dataset(tar_path, data_dir):
    """Extract the dataset"""

    if not tar_path or not tar_path.exists():
        return None

    print("üìÇ Extracting dataset...")
    try:
        with tarfile.open(tar_path, 'r') as tar:
            tar.extractall(data_dir)

        extracted_path = data_dir / "Task03_Liver"
        if extracted_path.exists():
            print(f"‚úÖ Extracted to: {extracted_path}")
            return extracted_path
        else:
            print("‚ùå Extraction failed")
            return None

    except Exception as e:
        print(f"‚ùå Error extracting: {e}")
        return None

# Download and extract
dataset_file = download_dataset(directories['data'])
dataset_path = extract_dataset(dataset_file, directories['data'])

# ============================================================================
# STEP 4: Explore Dataset Structure
# ============================================================================

def explore_dataset(dataset_path):
    """Explore the dataset structure and load configuration"""

    if not dataset_path or not dataset_path.exists():
        print("‚ùå Dataset path not found!")
        return None, None

    # Load dataset configuration
    config_file = dataset_path / "dataset.json"
    config = {}

    if config_file.exists():
        with open(config_file, 'r') as f:
            config = json.load(f)

        print("\nüìã Dataset Information:")
        print(f"   Name: {config.get('name', 'Unknown')}")
        print(f"   Description: {config.get('description', 'N/A')}")
        print(f"   Modality: {config.get('modality', 'Unknown')}")
        print(f"   Training samples: {config.get('numTraining', 0)}")
        print(f"   Test samples: {config.get('numTest', 0)}")

        if 'labels' in config:
            print(f"   Labels: {config['labels']}")

    # Check subdirectories
    subdirs = ['imagesTr', 'labelsTr', 'imagesTs']
    dataset_info = {}

    for subdir in subdirs:
        subdir_path = dataset_path / subdir
        if subdir_path.exists():
            files = list(subdir_path.glob("*.nii.gz"))
            dataset_info[subdir] = {
                'path': subdir_path,
                'files': files,
                'count': len(files)
            }
            print(f"   üìÅ {subdir}: {len(files)} files")
        else:
            dataset_info[subdir] = {'path': None, 'files': [], 'count': 0}
            print(f"   ‚ùå {subdir}: Not found")

    return dataset_info, config

# Explore dataset
if dataset_path:
    dataset_info, dataset_config = explore_dataset(dataset_path)

    # Save paths for next parts
    with open(directories['base'] / 'paths.json', 'w') as f:
        json.dump({
            'dataset_path': str(dataset_path),
            'directories': {k: str(v) for k, v in directories.items()},
            'train_images': len(dataset_info['imagesTr']['files']) if 'imagesTr' in dataset_info else 0,
            'train_labels': len(dataset_info['labelsTr']['files']) if 'labelsTr' in dataset_info else 0,
            'model_type': 'deeplabv3_resnet101'
        }, f, indent=2)

    print(f"\nüéâ Part 1 Complete!")
    print(f"‚úÖ Dataset ready with {dataset_info['imagesTr']['count']} training images")
    print(f"üìç All paths saved to: {directories['base'] / 'paths.json'}")
    print(f"ü§ñ Model: DeepLabV3+ with ResNet-101 backbone")

else:
    print("‚ùå Failed to setup dataset. Please check the download URL.")

print("\nüéØ Next: Run Part 2 - Data Preprocessing and DeepLab Model Setup")

# Part 2: Data Preprocessing and DeepLab Model Setup
# Run after Part 1

import numpy as np
import matplotlib.pyplot as plt
import nibabel as nib
from pathlib import Path
import json
from skimage import measure, filters
from scipy import ndimage
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import torch
import torch.nn as nn
import torchvision.models.segmentation as models
from PIL import Image
import cv2

print("üöÄ Part 2: Data Preprocessing and DeepLab Model Setup")
print("="*50)

# Load paths from Part 1
with open('/content/liver_segmentation/paths.json', 'r') as f:
    paths_info = json.load(f)

dataset_path = Path(paths_info['dataset_path'])
directories = {k: Path(v) for k, v in paths_info['directories'].items()}

# ============================================================================
# STEP 1: Data Loading and Preprocessing Functions
# ============================================================================

def load_nifti_data(image_path, label_path=None):
    """Load NIfTI image and optional label"""

    # Load image
    image_nii = nib.load(image_path)
    image_data = image_nii.get_fdata()

    result = {
        'image': image_data,
        'image_nii': image_nii,
        'spacing': image_nii.header.get_zooms(),
        'affine': image_nii.affine
    }

    # Load label if provided
    if label_path and Path(label_path).exists():
        label_nii = nib.load(label_path)
        label_data = label_nii.get_fdata()
        result['label'] = label_data
        result['label_nii'] = label_nii

    return result

def preprocess_image(image_data, window_level=40, window_width=400):
    """Apply CT window/level preprocessing"""

    # Apply windowing (common for CT liver imaging)
    lower = window_level - window_width/2
    upper = window_level + window_width/2

    # Clip and normalize
    windowed = np.clip(image_data, lower, upper)
    normalized = (windowed - lower) / (upper - lower)

    return normalized

def preprocess_for_deeplab(image_slice, target_size=(512, 512)):
    """Preprocess a single 2D slice for DeepLab input"""

    # Resize to target size
    resized = cv2.resize(image_slice, target_size, interpolation=cv2.INTER_LINEAR)

    # Convert to 3-channel (DeepLab expects RGB input)
    rgb_image = np.stack([resized, resized, resized], axis=-1)

    # Normalize to ImageNet statistics (DeepLab pre-training)
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    normalized = (rgb_image - mean) / std

    # Convert to tensor (C, H, W)
    tensor = torch.from_numpy(normalized).float().permute(2, 0, 1)

    return tensor, resized

def preprocess_label(label_slice, target_size=(512, 512)):
    """Preprocess label for DeepLab training"""

    # Resize label using nearest neighbor to preserve class values
    resized = cv2.resize(label_slice.astype(np.float32), target_size,
                        interpolation=cv2.INTER_NEAREST)

    return torch.from_numpy(resized).long()

def identify_liver_parts(label_data):
    """Identify different parts of liver segmentation"""

    unique_labels = np.unique(label_data)
    print(f"üìä Found labels: {unique_labels}")

    # For Task03_Liver: 0=background, 1=liver, 2=liver tumors
    parts = {
        0: {'name': 'Background', 'color': 'rgba(0,0,0,0)'},
        1: {'name': 'Liver Parenchyma', 'color': 'rgba(165,42,42,0.7)'},  # Brown
        2: {'name': 'Liver Tumors', 'color': 'rgba(255,0,0,0.9)'}         # Red
    }

    # Add vessel/bile duct segmentation if we find additional structures
    if len(unique_labels) > 3:
        parts[3] = {'name': 'Vessels/Bile Ducts', 'color': 'rgba(0,255,255,0.6)'}  # Cyan

    return parts, unique_labels

# ============================================================================
# STEP 2: Load DeepLab Model
# ============================================================================

def load_deeplab_model(num_classes=3, pretrained=True):
    """Load pre-trained DeepLabV3+ model"""

    print("ü§ñ Loading DeepLabV3 with ResNet-101 backbone...")

    # Load pre-trained DeepLabV3
    model = models.deeplabv3_resnet101(pretrained=pretrained)

    # Modify classifier for our number of classes
    # DeepLabV3 has a classifier with an output layer we need to modify
    in_channels = model.classifier[4].in_channels
    model.classifier[4] = nn.Conv2d(in_channels, num_classes, kernel_size=1)

    # Also modify the auxiliary classifier if it exists
    if hasattr(model, 'aux_classifier'):
        in_channels_aux = model.aux_classifier[4].in_channels
        model.aux_classifier[4] = nn.Conv2d(in_channels_aux, num_classes, kernel_size=1)

    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    print(f"‚úÖ Model loaded on: {device}")
    print(f"   Number of classes: {num_classes}")
    print(f"   Input size: (3, H, W) - RGB images")

    return model, device

# Load DeepLab model
deeplab_model, device = load_deeplab_model(num_classes=3)

# Save model info
model_info = {
    'model_type': 'deeplabv3_resnet101',
    'num_classes': 3,
    'input_size': [512, 512],
    'device': str(device),
    'pretrained': True
}

with open(directories['models'] / 'model_config.json', 'w') as f:
    json.dump(model_info, f, indent=2)

# ============================================================================
# STEP 3: Load and Visualize Sample Data
# ============================================================================

def load_sample_case(dataset_path, case_index=0):
    """Load a sample case for demonstration"""

    images_dir = dataset_path / "imagesTr"
    labels_dir = dataset_path / "labelsTr"

    # Filter out files starting with '._'
    image_files = sorted([f for f in images_dir.glob("*.nii.gz") if not f.name.startswith('._')])
    label_files = sorted([f for f in labels_dir.glob("*.nii.gz") if not f.name.startswith('._')])

    if not image_files or not label_files:
        print("‚ùå No image or label files found!")
        return None

    # Select case
    if case_index >= len(image_files):
        case_index = 0

    image_path = image_files[case_index]
    label_path = label_files[case_index]

    print(f"üìÅ Loading case {case_index}: {image_path.name}")

    # Load data
    data = load_nifti_data(image_path, label_path)

    # Preprocess
    data['image_processed'] = preprocess_image(data['image'])

    # Identify liver parts
    data['parts'], data['unique_labels'] = identify_liver_parts(data['label'])

    # Print info
    print(f"   üìä Image shape: {data['image'].shape}")
    print(f"   üìä Spacing: {data['spacing']}")
    print(f"   üìä Value range: {data['image'].min():.1f} to {data['image'].max():.1f}")
    print(f"   üéØ Labels found: {data['unique_labels']}")

    return data

# Load sample case
sample_data = load_sample_case(dataset_path, case_index=0)

# ============================================================================
# STEP 4: Test DeepLab on Sample Slice
# ============================================================================

def test_deeplab_inference(model, device, image_slice):
    """Test DeepLab inference on a sample slice"""

    print("üî¨ Testing DeepLab inference on sample slice...")

    # Preprocess
    input_tensor, _ = preprocess_for_deeplab(image_slice)
    input_batch = input_tensor.unsqueeze(0).to(device)

    # Inference
    model.eval()
    with torch.no_grad():
        output = model(input_batch)['out']
        prediction = output.argmax(1).squeeze().cpu().numpy()

    print(f"‚úÖ Inference successful!")
    print(f"   Input shape: {input_batch.shape}")
    print(f"   Output shape: {output.shape}")
    print(f"   Prediction shape: {prediction.shape}")
    print(f"   Predicted classes: {np.unique(prediction)}")

    return prediction

# Test on middle slice
if sample_data:
    mid_slice = sample_data['image_processed'][:, :, sample_data['image_processed'].shape[2]//2]
    test_prediction = test_deeplab_inference(deeplab_model, device, mid_slice)

# ============================================================================
# STEP 5: 2D Slice Visualization with DeepLab Prediction
# ============================================================================

def visualize_slices_with_prediction(data, model, device, slice_indices=None):
    """Visualize 2D slices with liver segmentation and DeepLab prediction"""

    if data is None:
        return

    image = data['image_processed']
    label = data['label']
    parts = data['parts']

    # Select slices to show
    if slice_indices is None:
        depth = image.shape[2]
        slice_indices = [depth//4, depth//2, 3*depth//4]

    fig, axes = plt.subplots(3, 4, figsize=(20, 15))

    for i, slice_idx in enumerate(slice_indices):
        # Get slices
        img_slice = image[:, :, slice_idx]
        lbl_slice = label[:, :, slice_idx]

        # Get DeepLab prediction (before fine-tuning)
        with torch.no_grad():
            input_tensor, _ = preprocess_for_deeplab(img_slice)
            input_batch = input_tensor.unsqueeze(0).to(device)
            model.eval()
            output = model(input_batch)['out']
            pred_slice = output.argmax(1).squeeze().cpu().numpy()

        # Original image
        axes[i, 0].imshow(img_slice.T, cmap='gray', origin='lower')
        axes[i, 0].set_title(f'CT Image - Slice {slice_idx}')
        axes[i, 0].axis('off')

        # Ground truth overlay
        axes[i, 1].imshow(img_slice.T, cmap='gray', origin='lower')
        for label_val, part_info in parts.items():
            if label_val == 0:
                continue
            mask = (lbl_slice == label_val)
            if np.any(mask):
                rgb_vals = part_info['color'].replace('rgba(', '').replace(')', '').split(',')[:3]
                rgb_color = [float(x)/255 for x in rgb_vals]
                axes[i, 1].contour(mask.T, colors=[rgb_color], linewidths=2, origin='lower')
        axes[i, 1].set_title(f'Ground Truth - Slice {slice_idx}')
        axes[i, 1].axis('off')

        # Ground truth mask
        colored_label = np.zeros((*lbl_slice.shape, 3))
        for label_val, part_info in parts.items():
            if label_val == 0:
                continue
            mask = (lbl_slice == label_val)
            if np.any(mask):
                if label_val == 1:
                    colored_label[mask] = [0.6, 0.2, 0.2]
                elif label_val == 2:
                    colored_label[mask] = [1.0, 0.0, 0.0]
        axes[i, 2].imshow(colored_label.transpose(1, 0, 2), origin='lower')
        axes[i, 2].set_title(f'GT Mask - Slice {slice_idx}')
        axes[i, 2].axis('off')

        # DeepLab prediction (pre-training)
        colored_pred = np.zeros((*pred_slice.shape, 3))
        colored_pred[pred_slice == 1] = [0.6, 0.2, 0.2]
        colored_pred[pred_slice == 2] = [1.0, 0.0, 0.0]
        # Correct the transpose operation
        axes[i, 3].imshow(colored_pred.transpose(1, 0, 2), origin='lower')
        axes[i, 3].set_title(f'DeepLab (Pre-trained) - Slice {slice_idx}')
        axes[i, 3].axis('off')

    plt.suptitle('Before Fine-tuning: DeepLab needs training on medical data', fontsize=14, y=1.00)
    plt.tight_layout()
    plt.savefig(directories['visualizations'] / 'sample_slices_with_prediction.png', dpi=150, bbox_inches='tight')
    plt.show()

    # Print statistics
    print(f"\nüìà Ground Truth Segmentation Statistics:")
    for label_val, part_info in parts.items():
        if label_val == 0:
            continue
        mask = (label == label_val)
        volume = np.sum(mask) * np.prod(data['spacing'])
        percentage = (np.sum(mask) / label.size) * 100
        print(f"   {part_info['name']}: {volume/1000:.1f} cm¬≥ ({percentage:.2f}%)")

# Visualize with predictions
if sample_data:
    visualize_slices_with_prediction(sample_data, deeplab_model, device)

# ============================================================================
# STEP 6: 3D Preview
# ============================================================================

def create_3d_preview(data, downsample_factor=4):
    """Create a simple 3D preview of the liver segmentation"""

    if data is None:
        return

    image = data['image_processed']
    label = data['label']

    # Downsample for faster processing
    label_small = label[::downsample_factor, ::downsample_factor, ::downsample_factor]

    print(f"üé≤ Creating 3D preview (downsampled to {label_small.shape})")

    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Liver Volume', 'Tumor Volume'),
        specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]]
    )

    # Liver coordinates
    liver_coords = np.where(label_small == 1)
    if len(liver_coords[0]) > 0:
        sample_size = min(5000, len(liver_coords[0]))
        indices = np.random.choice(len(liver_coords[0]), sample_size, replace=False)
        x, y, z = [liver_coords[i][indices] for i in range(3)]

        fig.add_trace(
            go.Scatter3d(
                x=x, y=y, z=z,
                mode='markers',
                marker=dict(size=2, color='brown', opacity=0.6),
                name='Liver',
                showlegend=True
            ),
            row=1, col=1
        )

    # Tumor coordinates
    tumor_coords = np.where(label_small == 2)
    if len(tumor_coords[0]) > 0:
        x_t, y_t, z_t = tumor_coords
        fig.add_trace(
            go.Scatter3d(
                x=x_t, y=y_t, z=z_t,
                mode='markers',
                marker=dict(size=3, color='red', opacity=0.8),
                name='Tumors',
                showlegend=True
            ),
            row=1, col=2
        )

    fig.update_layout(
        title="3D Liver Segmentation Preview",
        scene=dict(aspectmode='data'),
        scene2=dict(aspectmode='data'),
        height=600
    )

    fig.show()

# Create 3D preview
if sample_data:
    create_3d_preview(sample_data)

# ============================================================================
# STEP 7: Save Preprocessed Data
# ============================================================================

def save_sample_data(data, save_path):
    """Save preprocessed sample data"""

    if data is None:
        return

    np.savez_compressed(
        save_path / 'sample_data.npz',
        image=data['image'],
        image_processed=data['image_processed'],
        label=data['label'],
        spacing=data['spacing'],
        unique_labels=data['unique_labels']
    )

    metadata = {
        'parts': data['parts'],
        'shape': list(data['image'].shape),
        'spacing': [float(s) for s in data['spacing']],
        'unique_labels': data['unique_labels'].tolist(),
        'model': 'deeplabv3_resnet101'
    }

    with open(save_path / 'sample_metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)

    print(f"üíæ Sample data saved to: {save_path}")

# Save data
if sample_data:
    save_sample_data(sample_data, directories['results'])

print(f"\nüéâ Part 2 Complete!")
print(f"‚úÖ Sample data loaded and visualized")
print(f"‚úÖ DeepLab model loaded and tested")
print(f"‚úÖ Pre-trained model shows random predictions (needs fine-tuning)")
print(f"üìÅ Visualizations saved to: {directories['visualizations']}")
print(f"\nüéØ Next: Run Part 3 - Fine-tuning DeepLab on Liver Data")

# Part 3: Fine-tuning DeepLab on Liver Dataset
# Run after Part 2

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import cv2
from pathlib import Path
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

print("üöÄ Part 3: Fine-tuning DeepLab on Liver Data")
print("="*40)

# Check GPU availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üñ•Ô∏è Using device: {device}")

# Load paths and data
with open('/content/liver_segmentation/paths.json', 'r') as f:
    paths_info = json.load(f)

directories = {k: Path(v) for k, v in paths_info['directories'].items()}
dataset_path = Path(paths_info['dataset_path'])

# Load sample data
sample_data_path = directories['results'] / 'sample_data.npz'
if sample_data_path.exists():
    print("üìÇ Loading preprocessed sample data...")
    loaded_data = np.load(sample_data_path)
    sample_image = loaded_data['image_processed']
    sample_label = loaded_data['label']
    spacing = loaded_data['spacing']
    print(f"‚úÖ Loaded data shape: {sample_image.shape}")
else:
    print("‚ùå No preprocessed data found. Run Part 2 first!")
    sample_image = sample_label = spacing = None

# ============================================================================
# STEP 1: Create Custom Dataset for DeepLab Training
# ============================================================================

class LiverDataset(Dataset):
    """Custom Dataset for liver CT scans"""

    def __init__(self, image_3d, label_3d, target_size=(256, 256),
                 min_liver_pixels=500, transform=None):
        """
        Args:
            image_3d: 3D preprocessed CT volume (H, W, D)
            label_3d: 3D label volume (H, W, D)
            target_size: Target size for resizing
            min_liver_pixels: Minimum liver pixels to include slice
            transform: Optional transforms
        """
        self.target_size = target_size
        self.transform = transform

        # Extract valid slices (with sufficient liver content)
        self.slices = []
        for z in range(image_3d.shape[2]):
            liver_pixels = np.sum(label_3d[:, :, z] > 0)
            if liver_pixels >= min_liver_pixels:
                self.slices.append({
                    'image': image_3d[:, :, z],
                    'label': label_3d[:, :, z],
                    'slice_idx': z
                })

        print(f"   Created dataset with {len(self.slices)} valid slices")

    def __len__(self):
        return len(self.slices)

    def __getitem__(self, idx):
        slice_data = self.slices[idx]
        image = slice_data['image']
        label = slice_data['label']

        # Resize
        image_resized = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LINEAR)
        label_resized = cv2.resize(label.astype(np.float32), self.target_size,
                                   interpolation=cv2.INTER_NEAREST)

        # Convert to 3-channel RGB
        image_rgb = np.stack([image_resized, image_resized, image_resized], axis=-1)

        # Normalize with ImageNet statistics
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image_normalized = (image_rgb - mean) / std

        # Convert to tensors (C, H, W)
        image_tensor = torch.from_numpy(image_normalized).float().permute(2, 0, 1)
        label_tensor = torch.from_numpy(label_resized).long()

        return image_tensor, label_tensor, slice_data['slice_idx']

# ============================================================================
# STEP 2: Load DeepLab Model
# ============================================================================

def load_deeplab_for_training(num_classes=3, pretrained=True):
    """Load DeepLabV3 model for fine-tuning"""

    print("ü§ñ Loading DeepLabV3 model for training...")

    import torchvision.models.segmentation as models

    # Load pre-trained model
    model = models.deeplabv3_resnet101(pretrained=pretrained)

    # Modify classifier for our classes
    in_channels = model.classifier[4].in_channels
    model.classifier[4] = nn.Conv2d(in_channels, num_classes, kernel_size=1)

    # Modify auxiliary classifier
    if hasattr(model, 'aux_classifier'):
        in_channels_aux = model.aux_classifier[4].in_channels
        model.aux_classifier[4] = nn.Conv2d(in_channels_aux, num_classes, kernel_size=1)

    model = model.to(device)
    print(f"‚úÖ Model loaded on {device}")

    return model

# Load model
deeplab_model = load_deeplab_for_training(num_classes=3, pretrained=True)

# ============================================================================
# STEP 3: Training Setup
# ============================================================================

def calculate_class_weights(label_3d):
    """Calculate class weights for handling class imbalance"""

    unique, counts = np.unique(label_3d, return_counts=True)
    total = label_3d.size

    weights = []
    for i in range(3):  # 0: background, 1: liver, 2: tumor
        if i in unique:
            weight = total / (len(unique) * counts[unique == i][0])
            weights.append(weight)
        else:
            weights.append(1.0)

    # Normalize weights
    weights = np.array(weights)
    weights = weights / weights.sum() * len(weights)

    print(f"üìä Class weights: {weights}")
    return torch.FloatTensor(weights).to(device)

class DiceLoss(nn.Module):
    """Dice loss for segmentation"""

    def __init__(self, smooth=1.0):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, pred, target, num_classes=3):
        pred = torch.softmax(pred, dim=1)

        dice_sum = 0
        for c in range(num_classes):
            pred_c = pred[:, c, :, :]
            target_c = (target == c).float()

            intersection = (pred_c * target_c).sum()
            union = pred_c.sum() + target_c.sum()

            dice = (2. * intersection + self.smooth) / (union + self.smooth)
            dice_sum += dice

        return 1 - dice_sum / num_classes

class CombinedLoss(nn.Module):
    """Combined Cross Entropy and Dice Loss"""

    def __init__(self, weight=None, ce_weight=0.5, dice_weight=0.5):
        super(CombinedLoss, self).__init__()
        self.ce_loss = nn.CrossEntropyLoss(weight=weight)
        self.dice_loss = DiceLoss()
        self.ce_weight = ce_weight
        self.dice_weight = dice_weight

    def forward(self, pred, target):
        ce = self.ce_loss(pred, target)
        dice = self.dice_loss(pred, target)
        return self.ce_weight * ce + self.dice_weight * dice

# Setup training components
if sample_image is not None:
# Create dataset
    train_dataset = LiverDataset(sample_image, sample_label, target_size=(256, 256))
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,
                             num_workers=0, drop_last=True)  # Drop last incomplete batch

    # Calculate class weights
    class_weights = calculate_class_weights(sample_label)

    # Setup loss and optimizer
    criterion = CombinedLoss(weight=class_weights, ce_weight=0.5, dice_weight=0.5)
    optimizer = optim.Adam(deeplab_model.parameters(), lr=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

# ============================================================================
# STEP 4: Training Function
# ============================================================================

def train_epoch(model, dataloader, criterion, optimizer, device):
    """Train for one epoch"""

    model.train()
    total_loss = 0
    num_batches = 0

    pbar = tqdm(dataloader, desc="Training")
    for images, labels, _ in pbar:
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        optimizer.zero_grad()
        outputs = model(images)['out']

        # Calculate loss
        loss = criterion(outputs, labels)

        # Backward pass
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        num_batches += 1

        pbar.set_postfix({'loss': f'{loss.item():.4f}'})

    return total_loss / num_batches

def evaluate(model, dataloader, criterion, device):
    """Evaluate model"""

    model.eval()
    total_loss = 0
    num_batches = 0

    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels, _ in tqdm(dataloader, desc="Evaluating"):
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)['out']
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            num_batches += 1

            # Get predictions
            preds = outputs.argmax(1)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    return total_loss / num_batches, np.concatenate(all_preds), np.concatenate(all_labels)

# ============================================================================
# STEP 5: Train the Model
# ============================================================================

def train_deeplab(model, train_loader, criterion, optimizer, scheduler,
                  num_epochs=10, checkpoint_dir=None):
    """Full training loop"""

    print(f"üèãÔ∏è Starting training for {num_epochs} epochs...")

    history = {
        'train_loss': [],
        'val_loss': []
    }

    best_loss = float('inf')

    for epoch in range(num_epochs):
        print(f"\nüìÖ Epoch {epoch+1}/{num_epochs}")

        # Train
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
        history['train_loss'].append(train_loss)

        # Note: In real scenario, you'd have separate validation set
        # For now, we'll use training loss
        val_loss = train_loss
        history['val_loss'].append(val_loss)

        # Learning rate scheduling
        scheduler.step(val_loss)
        current_lr = optimizer.param_groups[0]['lr']

        print(f"   Train Loss: {train_loss:.4f}")
        print(f"   Learning Rate: {current_lr:.6f}")

        # Save best model
        if val_loss < best_loss and checkpoint_dir:
            best_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': val_loss,
            }, checkpoint_dir / 'best_model.pth')
            print(f"   üíæ Best model saved (loss: {best_loss:.4f})")

    return history

# Train the model if data is available
training_history = None
if sample_image is not None:
    training_history = train_deeplab(
        deeplab_model,
        train_loader,
        criterion,
        optimizer,
        scheduler,
        num_epochs=10,  # Adjust based on your needs
        checkpoint_dir=directories['checkpoints']
    )

# ============================================================================
# STEP 6: Visualize Training Progress
# ============================================================================

def plot_training_history(history, save_dir):
    """Plot training curves"""

    if history is None:
        return

    plt.figure(figsize=(10, 5))
    plt.plot(history['train_loss'], label='Training Loss', marker='o')
    plt.plot(history['val_loss'], label='Validation Loss', marker='s')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('DeepLab Training Progress')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_dir / 'training_history.png', dpi=150, bbox_inches='tight')
    plt.show()

    print(f"üìà Training completed!")
    print(f"   Final train loss: {history['train_loss'][-1]:.4f}")
    print(f"   Best val loss: {min(history['val_loss']):.4f}")

if training_history:
    plot_training_history(training_history, directories['results'])

# ============================================================================
# STEP 7: Inference on Sample Slices
# ============================================================================

def inference_on_slices(model, image_3d, label_3d, num_slices=5):
    """Run inference on sample slices"""

    print(f"üîç Running inference on {num_slices} slices...")

    model.eval()
    results = {}

    # Select slices with liver content
    liver_slices = []
    for z in range(image_3d.shape[2]):
        liver_area = np.sum(label_3d[:, :, z] > 0)
        if liver_area > 500:
            liver_slices.append((z, liver_area))

    liver_slices.sort(key=lambda x: x[1], reverse=True)
    selected_slices = [s[0] for s in liver_slices[:num_slices]]

    for z in tqdm(selected_slices, desc="Inference"):
        # Prepare slice
        image_slice = image_3d[:, :, z]
        label_slice = label_3d[:, :, z]

        # Resize and normalize
        image_resized = cv2.resize(image_slice, (256, 256))
        image_rgb = np.stack([image_resized, image_resized, image_resized], axis=-1)

        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image_normalized = (image_rgb - mean) / std

        # Convert to tensor
        image_tensor = torch.from_numpy(image_normalized).float().permute(2, 0, 1).unsqueeze(0)

        # Inference
        with torch.no_grad():
            output = model(image_tensor.to(device))['out']
            prediction = output.argmax(1).squeeze().cpu().numpy()

        # Resize back to original size
        prediction_resized = cv2.resize(prediction.astype(np.float32),
                                       (image_slice.shape[1], image_slice.shape[0]),
                                       interpolation=cv2.INTER_NEAREST)

        results[z] = {
            'original': image_slice,
            'ground_truth': label_slice,
            'prediction': prediction_resized
        }

    print(f"‚úÖ Inference completed on {len(results)} slices")
    return results

# Run inference
inference_results = None
if sample_image is not None:
    inference_results = inference_on_slices(deeplab_model, sample_image, sample_label, num_slices=5)

# ============================================================================
# STEP 8: Visualize Results
# ============================================================================

def visualize_results(results, save_dir):
    """Visualize segmentation results"""

    if not results:
        return

    slice_keys = list(results.keys())[:3]

    fig, axes = plt.subplots(len(slice_keys), 3, figsize=(15, 5*len(slice_keys)))
    if len(slice_keys) == 1:
        axes = axes.reshape(1, -1)

    for i, slice_z in enumerate(slice_keys):
        result = results[slice_z]

        # Original
        axes[i, 0].imshow(result['original'].T, cmap='gray', origin='lower')
        axes[i, 0].set_title(f'CT Image - Slice {slice_z}')
        axes[i, 0].axis('off')

        # Ground truth
        gt_colored = np.zeros((*result['ground_truth'].shape, 3))
        gt_colored[result['ground_truth'] == 1] = [0.6, 0.2, 0.2]  # Liver
        gt_colored[result['ground_truth'] == 2] = [1.0, 0.0, 0.0]  # Tumor
        axes[i, 1].imshow(gt_colored.transpose(1, 0, 2), origin='lower')
        axes[i, 1].set_title(f'Ground Truth - Slice {slice_z}')
        axes[i, 1].axis('off')

        # Prediction
        pred_colored = np.zeros((*result['prediction'].shape, 3))
        pred_colored[result['prediction'] == 1] = [0.6, 0.2, 0.2]
        pred_colored[result['prediction'] == 2] = [1.0, 0.0, 0.0]
        axes[i, 2].imshow(pred_colored.transpose(1, 0, 2), origin='lower')
        axes[i, 2].set_title(f'DeepLab Prediction - Slice {slice_z}')
        axes[i, 2].axis('off')

    plt.suptitle('DeepLab Fine-tuned Results', fontsize=14, y=0.995)
    plt.tight_layout()
    plt.savefig(save_dir / 'deeplab_results.png', dpi=150, bbox_inches='tight')
    plt.show()

if inference_results:
    visualize_results(inference_results, directories['results'])

# ============================================================================
# STEP 9: Save Model and Results
# ============================================================================

# Save final model
if sample_image is not None:
    torch.save({
        'model_state_dict': deeplab_model.state_dict(),
        'model_config': {
            'type': 'deeplabv3_resnet101',
            'num_classes': 3,
            'input_size': [256, 256]
        }
    }, directories['models'] / 'deeplab_finetuned.pth')

    print(f"üíæ Model saved to: {directories['models'] / 'deeplab_finetuned.pth'}")

print(f"\nüéâ Part 3 Complete!")
print(f"‚úÖ DeepLab model fine-tuned on liver data")
print(f"‚úÖ Training history and results saved")
if inference_results:
    print(f"‚úÖ Successfully processed {len(inference_results)} slices")
print(f"\nüéØ Next: Run Part 4 - Dice Score Calculation and 3D Visualization")

import torch
import torch.nn as nn
import torchvision.models.segmentation as models
import numpy as np

# Load the model definition from the previous cell
def load_deeplab_for_training(num_classes=3, pretrained=True):
    """Load DeepLabV3 model for fine-tuning"""

    print("ü§ñ Loading DeepLabV3 model for training...")

    import torchvision.models.segmentation as models

    # Load pre-trained model
    model = models.deeplabv3_resnet101(pretrained=pretrained)

    # Modify classifier for our classes
    in_channels = model.classifier[4].in_channels
    model.classifier[4] = nn.Conv2d(in_channels, num_classes, kernel_size=1)

    # Modify auxiliary classifier
    if hasattr(model, 'aux_classifier'):
        in_channels_aux = model.aux_classifier[4].in_channels
        model.aux_classifier[4] = nn.Conv2d(in_channels_aux, num_classes, kernel_size=1)

    model = model.to(torch.device("cpu")) # Use CPU for inspection
    print(f"‚úÖ Model loaded on cpu")

    return model

deeplab_model = load_deeplab_for_training(num_classes=3, pretrained=True)

# Create a dummy input tensor with the target size used in the dataset
# Using batch size 1 for easier tracking
dummy_input = torch.randn(1, 3, 256, 256) # Batch size, Channels, Height, Width

print("\nüî¨ Tracing tensor shape through the model...")

# Function to trace shapes through the model
def trace_model_shapes(model, input_tensor):
    def get_module_name(module):
        return module.__class__.__name__

    current_tensor = input_tensor
    print(f"Initial input shape: {current_tensor.shape}")

    # Iterate through the model's modules
    for name, module in model.named_children():
        print(f"\n--- Module: {name} ({get_module_name(module)}) ---")
        try:
            if isinstance(module, (nn.Sequential, models.deeplabv3.ASPP)):
                 # Recursively trace through Sequential or ASPP
                if isinstance(module, models.deeplabv3.ASPP):
                    print("  (Entering ASPP)")
                    # ASPP might process inputs differently, a simplified trace
                    for aspp_name, aspp_module in module.named_children():
                         try:
                             temp_tensor = aspp_module(current_tensor)
                             print(f"    ASPP Sub-module: {aspp_name} ({get_module_name(aspp_module)}) -> shape: {temp_tensor.shape}")
                             # We don't update current_tensor here as ASPP processes in parallel
                         except Exception as e:
                            print(f"    Error in ASPP sub-module {aspp_name}: {e}")
                            break # Exit ASPP tracing on error
                    # After ASPP, the outputs are concatenated.
                    # We can't easily simulate the concatenation output shape without running it.
                    # Let's just note the expected reduction.
                    print("  (Exiting ASPP - Output shape will be concatenation)")
                else:
                     # Handle Sequential layers individually
                     for i, sub_module in enumerate(module.children()):
                        try:
                            current_tensor = sub_module(current_tensor)
                            print(f"  Sub-module {i} ({get_module_name(sub_module)}) -> shape: {current_tensor.shape}")
                        except Exception as e:
                            print(f"  Error in sub-module {i}: {e}")
                            break # Exit Sequential tracing on error
            else:
                # Process individual layers
                current_tensor = module(current_tensor)
                print(f"  Output shape: {current_tensor.shape}")

        except Exception as e:
            print(f"Error processing module {name}: {e}")
            print("Stopping trace.")
            break # Stop tracing on the first error

# Run the trace
trace_model_shapes(deeplab_model, dummy_input)

print("\n‚úÖ Shape tracing complete. Examine the output above to find where the spatial dimensions become 1x1.")

# Part 4: 3-Part Liver Segmentation with Different Colors

import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
from skimage import measure, morphology, segmentation
from scipy import ndimage
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from scipy.spatial.distance import cdist

print("üöÄ Part 4: 3-Part Liver Segmentation Analysis")
print("="*50)

# Load data from previous steps
directories = {k: Path(v) for k, v in json.load(open('/content/liver_segmentation/paths.json'))['directories'].items()}

# Load sample data
sample_data_path = directories['results'] / 'sample_data.npz'
loaded_data = np.load(sample_data_path)
sample_image = loaded_data['image_processed']
sample_label = loaded_data['label']
spacing = loaded_data['spacing']

print(f"üìÇ Loaded data - Shape: {sample_label.shape}, Spacing: {spacing}")

# ============================================================================
# STEP 1: Divide Liver into 3 Anatomical Parts
# ============================================================================

def divide_liver_into_3_parts(liver_mask, method='anatomical'):
    """Divide liver into 3 distinct anatomical parts"""

    print(f"üî™ Dividing liver into 3 parts using {method} method...")

    if not np.any(liver_mask):
        print("‚ùå No liver tissue found!")
        return None

    # Get liver coordinates
    liver_coords = np.where(liver_mask)

    if method == 'anatomical':
        # Anatomical division based on liver anatomy
        # Right lobe, Left lobe, and Caudate/Quadrate lobes

        # Get bounding box
        min_coords = [np.min(coords) for coords in liver_coords]
        max_coords = [np.max(coords) for coords in liver_coords]

        # Calculate anatomical landmarks
        x_range = max_coords[0] - min_coords[0]
        y_range = max_coords[1] - min_coords[1]
        z_range = max_coords[2] - min_coords[2]

        # Create 3-part segmentation
        liver_3parts = np.zeros_like(liver_mask, dtype=np.uint8)

        # Part 1: Right Lobe (largest part, posterior-lateral)
        # Typically 60-65% of liver volume
        right_lobe_mask = liver_mask.copy()
        x_threshold = min_coords[0] + x_range * 0.35  # Divide at 35% from anterior

        part1_mask = liver_mask & (np.arange(liver_mask.shape[0])[:, None, None] < x_threshold)
        liver_3parts[part1_mask] = 1

        # Part 2: Left Lobe (medium part, anterior-medial)
        # Typically 25-30% of liver volume
        y_threshold = min_coords[1] + y_range * 0.6
        part2_mask = liver_mask & (np.arange(liver_mask.shape[0])[:, None, None] >= x_threshold) & \
                    (np.arange(liver_mask.shape[1])[None, :, None] < y_threshold)
        liver_3parts[part2_mask] = 2

        # Part 3: Caudate and Quadrate Lobes (smallest part, superior-posterior)
        # Typically 10-15% of liver volume
        part3_mask = liver_mask & (np.arange(liver_mask.shape[0])[:, None, None] >= x_threshold) & \
                    (np.arange(liver_mask.shape[1])[None, :, None] >= y_threshold)
        liver_3parts[part3_mask] = 3

        part_names = {
            1: 'Right Lobe',
            2: 'Left Lobe',
            3: 'Caudate & Quadrate Lobes'
        }

    elif method == 'spatial':
        # Spatial division into superior, middle, inferior thirds
        z_min, z_max = min_coords[2], max_coords[2]
        z_third = (z_max - z_min) / 3

        liver_3parts = np.zeros_like(liver_mask, dtype=np.uint8)

        # Inferior third
        part1_mask = liver_mask & (np.arange(liver_mask.shape[2])[None, None, :] < (z_min + z_third))
        liver_3parts[part1_mask] = 1

        # Middle third
        part2_mask = liver_mask & \
                    (np.arange(liver_mask.shape[2])[None, None, :] >= (z_min + z_third)) & \
                    (np.arange(liver_mask.shape[2])[None, None, :] < (z_min + 2*z_third))
        liver_3parts[part2_mask] = 2

        # Superior third
        part3_mask = liver_mask & (np.arange(liver_mask.shape[2])[None, None, :] >= (z_min + 2*z_third))
        liver_3parts[part3_mask] = 3

        part_names = {
            1: 'Inferior Third',
            2: 'Middle Third',
            3: 'Superior Third'
        }

    # Calculate volumes for each part
    part_volumes = {}
    for part_id in [1, 2, 3]:
        part_mask = (liver_3parts == part_id)
        volume_mm3 = np.sum(part_mask) * np.prod(spacing)
        volume_cm3 = volume_mm3 / 1000
        part_volumes[part_id] = volume_cm3

        print(f"   Part {part_id} ({part_names[part_id]}): {volume_cm3:.1f} cm¬≥")

    return liver_3parts, part_names, part_volumes

# Create 3-part liver segmentation
liver_mask = (sample_label == 1)  # Extract only liver tissue (excluding tumors)
liver_3parts, part_names, part_volumes = divide_liver_into_3_parts(liver_mask, method='anatomical')

# Also include tumors as a separate entity
if liver_3parts is not None:
    # Add tumors as part 4 for analysis (but we'll focus on the 3 liver parts)
    tumor_mask = (sample_label == 2)
    liver_3parts[tumor_mask] = 4
    part_names[4] = 'Liver Tumors'
    if np.any(tumor_mask):
        tumor_volume = np.sum(tumor_mask) * np.prod(spacing) / 1000
        part_volumes[4] = tumor_volume
        print(f"   Part 4 (Tumors): {tumor_volume:.1f} cm¬≥")

# ============================================================================
# STEP 2: Visualize 3-Part Segmentation
# ============================================================================

def visualize_3part_segmentation(original_image, liver_3parts, part_names, slice_indices=None):
    """Visualize the 3-part liver segmentation"""

    if liver_3parts is None:
        return

    # Define colors for each part
    colors = {
        1: {'color': [0.8, 0.2, 0.2], 'name': 'Right Lobe', 'rgb': 'red'},        # Red
        2: {'color': [0.2, 0.8, 0.2], 'name': 'Left Lobe', 'rgb': 'green'},       # Green
        3: {'color': [0.2, 0.2, 0.8], 'name': 'Caudate/Quadrate', 'rgb': 'blue'}, # Blue
        4: {'color': [0.8, 0.8, 0.2], 'name': 'Tumors', 'rgb': 'yellow'}          # Yellow
    }

    # Select slices
    if slice_indices is None:
        depth = original_image.shape[2]
        slice_indices = [depth//4, depth//2, 3*depth//4]

    fig, axes = plt.subplots(len(slice_indices), 4, figsize=(20, 5*len(slice_indices)))
    if len(slice_indices) == 1:
        axes = axes.reshape(1, -1)

    for i, slice_idx in enumerate(slice_indices):
        img_slice = original_image[:, :, slice_idx]
        seg_slice = liver_3parts[:, :, slice_idx]

        # Original image
        axes[i, 0].imshow(img_slice.T, cmap='gray', origin='lower')
        axes[i, 0].set_title(f'Original CT - Slice {slice_idx}')
        axes[i, 0].axis('off')

        # Segmentation overlay
        axes[i, 1].imshow(img_slice.T, cmap='gray', origin='lower')
        for part_id, color_info in colors.items():
            if part_id > 3:  # Skip tumors in main liver visualization
                continue
            mask = (seg_slice == part_id)
            if np.any(mask):
                axes[i, 1].contour(mask.T, colors=[color_info['color']],
                                 linewidths=3, origin='lower', alpha=0.8)

        axes[i, 1].set_title(f'3-Part Liver Segmentation - Slice {slice_idx}')
        axes[i, 1].axis('off')

        # Pure segmentation (colored)
        colored_seg = np.zeros((*seg_slice.shape, 3))
        for part_id, color_info in colors.items():
            if part_id > 3:  # Skip tumors
                continue
            mask = (seg_slice == part_id)
            colored_seg[mask] = color_info['color']

        axes[i, 2].imshow(colored_seg.transpose(1, 0, 2), origin='lower')
        axes[i, 2].set_title(f'Color-Coded Parts - Slice {slice_idx}')
        axes[i, 2].axis('off')

        # Individual parts breakdown
        axes[i, 3].imshow(img_slice.T, cmap='gray', origin='lower', alpha=0.5)

        # Show each part with different transparency
        for part_id, color_info in colors.items():
            if part_id > 3:
                continue
            mask = (seg_slice == part_id)
            if np.any(mask):
                colored_part = np.zeros((*mask.shape, 4))  # RGBA
                colored_part[mask] = [*color_info['color'], 0.7]  # 70% opacity
                axes[i, 3].imshow(colored_part.transpose(1, 0, 2), origin='lower')

        axes[i, 3].set_title(f'Layered Visualization - Slice {slice_idx}')
        axes[i, 3].axis('off')

    # Add legend
    legend_elements = []
    for part_id in [1, 2, 3]:
        color_info = colors[part_id]
        legend_elements.append(plt.Line2D([0], [0], color=color_info['color'],
                                        lw=4, label=f'Part {part_id}: {part_names[part_id]}'))

    fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02),
              ncol=3, fontsize=12)

    plt.tight_layout()
    plt.savefig(directories['visualizations'] / '3_part_liver_segmentation.png',
                dpi=150, bbox_inches='tight')
    plt.show()

    # Print statistics
    print(f"\nüìä 3-Part Liver Statistics:")
    total_liver_volume = sum(part_volumes[i] for i in [1, 2, 3])
    for part_id in [1, 2, 3]:
        volume = part_volumes[part_id]
        percentage = (volume / total_liver_volume) * 100
        print(f"   {part_names[part_id]}: {volume:.1f} cm¬≥ ({percentage:.1f}%)")

# Visualize 3-part segmentation
if liver_3parts is not None:
    visualize_3part_segmentation(sample_image, liver_3parts, part_names)

# ============================================================================
# STEP 3: Dice Score Calculation for 3 Parts
# ============================================================================

def calculate_dice_score(pred_mask, true_mask, smooth=1e-6):
    """Calculate Dice Similarity Coefficient"""
    pred_flat = pred_mask.flatten()
    true_flat = true_mask.flatten()
    intersection = np.sum(pred_flat * true_flat)
    dice = (2.0 * intersection + smooth) / (np.sum(pred_flat) + np.sum(true_flat) + smooth)
    return dice

def create_simulated_3part_predictions(liver_3parts, noise_levels=[0.05, 0.15, 0.25]):
    """Create simulated predictions for the 3-part liver segmentation"""

    predictions = {}

    for i, noise_level in enumerate(noise_levels):
        pred = liver_3parts.copy().astype(int)

        # Add realistic segmentation errors
        for part_id in [1, 2, 3]:
            part_mask = (liver_3parts == part_id)

            # Random noise
            noise = np.random.rand(*pred.shape) < noise_level

            # Type 1: Misclassify some voxels to adjacent parts
            if part_id < 3:
                # Some of current part becomes next part
                misclass_mask = part_mask & noise
                pred[misclass_mask] = part_id + 1

            # Type 2: Some voxels lost to background
            lost_mask = part_mask & (np.random.rand(*pred.shape) < noise_level/2)
            pred[lost_mask] = 0

            # Type 3: Some background becomes this part
            bg_mask = (liver_3parts == 0) & noise & (np.random.rand(*pred.shape) < noise_level/3)
            pred[bg_mask] = part_id

        predictions[f'SAM_Method_{i+1}'] = pred

    return predictions

# Create simulated predictions for 3-part segmentation
if liver_3parts is not None:
    print("üé≤ Creating simulated 3-part predictions...")
    sim_predictions_3part = create_simulated_3part_predictions(liver_3parts)

    # Calculate Dice scores for each part
    print("üìà Calculating Dice scores for 3-part segmentation...")

    dice_results_3part = {}
    for method_name, pred in sim_predictions_3part.items():
        dice_results_3part[method_name] = {}

        for part_id in [1, 2, 3]:
            true_mask = (liver_3parts == part_id)
            pred_mask = (pred == part_id)

            dice_score = calculate_dice_score(pred_mask, true_mask)
            dice_results_3part[method_name][part_names[part_id]] = dice_score

            print(f"   {method_name} - {part_names[part_id]}: Dice = {dice_score:.3f}")

# ============================================================================
# STEP 4: Extract 3D Surfaces for Each Part
# ============================================================================

def extract_3part_surfaces(liver_3parts, part_names, spacing):
    """Extract 3D surfaces for each of the 3 liver parts"""

    print("üé® Extracting 3D surfaces for each liver part...")

    surfaces = {}

    # Define colors for 3D visualization
    part_colors = {
        1: {'color': 'red', 'opacity': 0.8},      # Right Lobe
        2: {'color': 'green', 'opacity': 0.8},    # Left Lobe
        3: {'color': 'blue', 'opacity': 0.8},     # Caudate/Quadrate
        4: {'color': 'yellow', 'opacity': 0.9}    # Tumors
    }

    for part_id in [1, 2, 3, 4]:  # Include tumors
        if part_id not in part_names:
            continue

        print(f"   Extracting surface for {part_names[part_id]}...")

        # Extract mask for this part
        mask = (liver_3parts == part_id).astype(np.uint8)

        if not np.any(mask):
            print(f"   ‚ö†Ô∏è No voxels found for part {part_id}")
            continue

        # Smooth the mask
        mask = morphology.binary_closing(mask, morphology.ball(2))
        mask = morphology.binary_opening(mask, morphology.ball(1))
        mask_smooth = ndimage.gaussian_filter(mask.astype(float), sigma=1.5)

        try:
            # Extract surface
            vertices, faces, normals, values = measure.marching_cubes(
                mask_smooth,
                level=0.5,
                spacing=spacing,
                allow_degenerate=False
            )

            # Calculate properties
            volume_cm3 = np.sum(mask) * np.prod(spacing) / 1000
            surface_area_cm2 = measure.mesh_surface_area(vertices, faces) / 100

            surfaces[part_id] = {
                'vertices': vertices,
                'faces': faces,
                'normals': normals,
                'name': part_names[part_id],
                'color': part_colors[part_id]['color'],
                'opacity': part_colors[part_id]['opacity'],
                'volume_cm3': volume_cm3,
                'surface_area_cm2': surface_area_cm2
            }

            print(f"   ‚úÖ {part_names[part_id]}:")
            print(f"      Vertices: {len(vertices)}, Faces: {len(faces)}")
            print(f"      Volume: {volume_cm3:.1f} cm¬≥")
            print(f"      Surface Area: {surface_area_cm2:.1f} cm¬≤")

        except Exception as e:
            print(f"   ‚ùå Error extracting part {part_id}: {e}")
            continue

    return surfaces

# Extract 3D surfaces
if liver_3parts is not None:
    liver_3part_surfaces = extract_3part_surfaces(liver_3parts, part_names, spacing)

# ============================================================================
# STEP 5: Create Interactive 3D Visualization with 3 Parts
# ============================================================================

def create_3part_interactive_visualization(surfaces, save_dir):
    """Create interactive 3D visualization for the 3-part liver"""

    if not surfaces:
        print("‚ùå No surfaces to visualize")
        return None

    print("üé® Creating interactive 3-part liver visualization...")

    # Create figure
    fig = go.Figure()

    # Add each part as a separate trace
    for part_id, surface_data in surfaces.items():
        vertices = surface_data['vertices']
        faces = surface_data['faces']

        fig.add_trace(
            go.Mesh3d(
                x=vertices[:, 0],
                y=vertices[:, 1],
                z=vertices[:, 2],
                i=faces[:, 0],
                j=faces[:, 1],
                k=faces[:, 2],
                name=surface_data['name'],
                color=surface_data['color'],
                opacity=surface_data['opacity'],
                visible=True,  # All parts visible by default
                lighting=dict(ambient=0.3, diffuse=0.8, specular=0.2),
                lightposition=dict(x=50, y=100, z=150)
            )
        )

    # Update layout
    fig.update_layout(
        title="Interactive 3-Part Liver Segmentation",
        scene=dict(
            aspectmode='data',
            camera=dict(
                eye=dict(x=1.8, y=1.8, z=1.8),
                center=dict(x=0, y=0, z=0)
            ),
            xaxis=dict(title='X (mm)', showbackground=True, backgroundcolor="rgb(230, 230, 250)"),
            yaxis=dict(title='Y (mm)', showbackground=True, backgroundcolor="rgb(250, 230, 230)"),
            zaxis=dict(title='Z (mm)', showbackground=True, backgroundcolor="rgb(230, 250, 230)")
        ),
        width=1000,
        height=800,
        margin=dict(r=20, b=10, l=10, t=40)
    )

    # Add control buttons
    part_buttons = []

    # Individual part buttons
    for i, (part_id, surface_data) in enumerate(surfaces.items()):
        visible = [False] * len(surfaces)
        visible[i] = True
        part_buttons.append(
            dict(
                label=f"Show {surface_data['name']}",
                method="update",
                args=[{"visible": visible}]
            )
        )

    # Combination buttons
    part_buttons.extend([
        dict(
            label="Show All 3 Liver Parts",
            method="update",
            args=[{"visible": [True if i < 3 else False for i in range(len(surfaces))]}]
        ),
        dict(
            label="Show All (Including Tumors)",
            method="update",
            args=[{"visible": [True] * len(surfaces)}]
        ),
        dict(
            label="Hide All",
            method="update",
            args=[{"visible": [False] * len(surfaces)}]
        )
    ])

    fig.update_layout(
        updatemenus=[
            dict(
                type="dropdown",
                direction="down",
                showactive=True,
                x=0.02,
                y=1.0,
                buttons=part_buttons
            )
        ]
    )

    # Add annotation with part information
    annotation_text = "Liver Parts:<br>"
    for part_id, surface_data in surfaces.items():
        if part_id <= 3:  # Only liver parts
            annotation_text += f"‚Ä¢ {surface_data['name']}: {surface_data['volume_cm3']:.1f} cm¬≥<br>"

    fig.add_annotation(
        x=0.02, y=0.98,
        xref="paper", yref="paper",
        text=annotation_text,
        showarrow=False,
        bgcolor="rgba(255,255,255,0.8)",
        bordercolor="black",
        borderwidth=1,
        font=dict(size=10)
    )

    # Show and save
    fig.show()
    fig.write_html(str(save_dir / 'interactive_3part_liver.html'))

    print(f"üíæ Interactive 3-part visualization saved!")
    return fig

# Create interactive visualization
if liver_3parts is not None and liver_3part_surfaces:
    interactive_3part_fig = create_3part_interactive_visualization(
        liver_3part_surfaces, directories['visualizations']
    )

# ============================================================================
# STEP 6: Save 3-Part Results
# ============================================================================

if liver_3parts is not None:
    # Save the 3-part segmentation
    np.savez_compressed(
        directories['results'] / 'liver_3part_segmentation.npz',
        liver_3parts=liver_3parts,
        original_image=sample_image,
        part_volumes=list(part_volumes.values()),
        spacing=spacing
    )

    # Save part names and results
    results_3part = {
        'part_names': part_names,
        'part_volumes_cm3': {str(k): float(v) for k, v in part_volumes.items()},
        'dice_scores': dice_results_3part if 'dice_results_3part' in locals() else {},
        'total_liver_volume_cm3': float(sum(part_volumes[i] for i in [1, 2, 3])),
        'surface_data': {
            str(part_id): {
                'volume_cm3': float(surf_data['volume_cm3']),
                'surface_area_cm2': float(surf_data['surface_area_cm2']),
                'num_vertices': len(surf_data['vertices']),
                'num_faces': len(surf_data['faces'])
            } for part_id, surf_data in liver_3part_surfaces.items()
        } if 'liver_3part_surfaces' in locals() else {}
    }

    with open(directories['results'] / '3part_liver_results.json', 'w') as f:
        json.dump(results_3part, f, indent=2)

print(f"\nüéâ Part 4 Complete - 3-Part Liver Segmentation!")
print(f"‚úÖ Liver divided into 3 distinct anatomical parts:")
if liver_3parts is not None:
    for part_id in [1, 2, 3]:
        print(f"   Part {part_id}: {part_names[part_id]} - {part_volumes[part_id]:.1f} cm¬≥")
print(f"‚úÖ Interactive 3D visualization with color-coded parts created")
print(f"‚úÖ Dice scores calculated for each part separately")
print(f"‚úÖ 3D surfaces extracted with different colors")
print(f"\nüéØ Next: Run Part 5 - Interactive Control Panel for Color/Opacity Control")

# Part 5: Interactive Control Panel with Color/Opacity Controls
# Run after Part 4

import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import ipywidgets as widgets
from IPython.display import display, HTML
import plotly.colors as pc
from plotly.offline import iplot

print("üöÄ Part 5: Interactive Control Panel for 3D Liver Visualization")
print("="*60)

# Load data from previous steps
directories = {k: Path(v) for k, v in json.load(open('/content/liver_segmentation/paths.json'))['directories'].items()}

# Load 3-part segmentation data
seg_data_path = directories['results'] / 'liver_3part_segmentation.npz'
if seg_data_path.exists():
    seg_data = np.load(seg_data_path)
    liver_3parts = seg_data['liver_3parts']
    spacing = seg_data['spacing']
    print("‚úÖ Loaded 3-part liver segmentation data")
else:
    print("‚ùå 3-part segmentation data not found. Run Part 4 first!")
    liver_3parts = spacing = None

# Load results
results_path = directories['results'] / '3part_liver_results.json'
if results_path.exists():
    with open(results_path, 'r') as f:
        results_3part = json.load(f)
    part_names = results_3part['part_names']
    part_volumes = results_3part['part_volumes_cm3']
    print("‚úÖ Loaded 3-part results")
else:
    print("‚ùå Results not found. Run Part 4 first!")
    part_names = part_volumes = None

# ============================================================================
# STEP 1: Enhanced 3D Surface Extraction with Better Quality
# ============================================================================

def extract_high_quality_surfaces(liver_3parts, spacing, smoothing_iterations=3):
    """Extract high-quality 3D surfaces for interactive visualization"""

    print("üé® Extracting high-quality 3D surfaces...")

    from skimage import measure, morphology
    from scipy import ndimage

    surfaces = {}

    # Default color scheme
    default_colors = {
        1: {'color': '#FF4444', 'name': 'Right Lobe'},      # Bright Red
        2: {'color': '#44FF44', 'name': 'Left Lobe'},       # Bright Green
        3: {'color': '#4444FF', 'name': 'Caudate/Quadrate'}, # Bright Blue
        4: {'color': '#FFFF44', 'name': 'Tumors'}           # Bright Yellow
    }

    for part_id in [1, 2, 3, 4]:
        if not np.any(liver_3parts == part_id):
            continue

        print(f"   Processing Part {part_id}: {default_colors[part_id]['name']}...")

        # Extract mask
        mask = (liver_3parts == part_id).astype(np.uint8)

        # Enhanced smoothing
        mask = morphology.binary_closing(mask, morphology.ball(3))
        mask = morphology.binary_opening(mask, morphology.ball(2))

        # Multiple Gaussian smoothing iterations
        mask_smooth = mask.astype(float)
        for _ in range(smoothing_iterations):
            mask_smooth = ndimage.gaussian_filter(mask_smooth, sigma=1.0)

        try:
            # Extract surface with higher resolution
            vertices, faces, normals, values = measure.marching_cubes(
                mask_smooth,
                level=0.3,  # Lower threshold for smoother surface
                spacing=spacing,
                allow_degenerate=False,
                step_size=1  # Higher resolution
            )

            # Simplify mesh if too dense (optional)
            if len(faces) > 50000:
                # Simple decimation by taking every nth face
                step = len(faces) // 30000
                faces = faces[::step]

            # Calculate properties
            volume_cm3 = np.sum(mask) * np.prod(spacing) / 1000
            surface_area_cm2 = measure.mesh_surface_area(vertices, faces) / 100

            surfaces[part_id] = {
                'vertices': vertices,
                'faces': faces,
                'normals': normals,
                'name': default_colors[part_id]['name'],
                'color': default_colors[part_id]['color'],
                'opacity': 0.8,
                'visible': True,
                'volume_cm3': volume_cm3,
                'surface_area_cm2': surface_area_cm2
            }

            print(f"      ‚úÖ {len(vertices)} vertices, {len(faces)} faces")

        except Exception as e:
            print(f"      ‚ùå Error: {e}")
            continue

    return surfaces

# Extract high-quality surfaces
if liver_3parts is not None:
    hq_surfaces = extract_high_quality_surfaces(liver_3parts, spacing)
else:
    hq_surfaces = {}

# ============================================================================
# STEP 2: Interactive Control Panel Class
# ============================================================================

class LiverVisualizationController:
    def __init__(self, surfaces):
        self.surfaces = surfaces
        self.fig = None
        self.current_colors = {}
        self.current_opacities = {}
        self.current_visibility = {}

        # Initialize current settings
        for part_id, surface in surfaces.items():
            self.current_colors[part_id] = surface['color']
            self.current_opacities[part_id] = surface['opacity']
            self.current_visibility[part_id] = surface['visible']

        self.setup_widgets()
        self.create_initial_plot()

    def setup_widgets(self):
        """Create interactive widgets for controlling visualization"""

        print("üéõÔ∏è Setting up interactive control panel...")

        # Color pickers for each part
        self.color_pickers = {}
        self.opacity_sliders = {}
        self.visibility_checkboxes = {}

        # Predefined color options
        color_options = [
            '#FF4444', '#44FF44', '#4444FF', '#FFFF44',  # Bright colors
            '#FF8800', '#8800FF', '#00FFFF', '#FF00FF',  # Vibrant colors
            '#994444', '#449944', '#444499', '#999944',  # Darker colors
            '#CC6666', '#66CC66', '#6666CC', '#CCCC66'   # Softer colors
        ]

        control_widgets = []

        for part_id, surface in self.surfaces.items():
            part_name = surface['name']

            # Title for this part
            title = widgets.HTML(f"<h4 style='color: {surface['color']};'>ü´Ä {part_name}</h4>")

            # Color picker
            color_picker = widgets.Dropdown(
                options=[(f'Color {i+1}', color) for i, color in enumerate(color_options)],
                value=surface['color'],
                description='Color:',
                style={'description_width': '60px'},
                layout=widgets.Layout(width='200px')
            )
            color_picker.part_id = part_id
            color_picker.observe(self.on_color_change, names='value')
            self.color_pickers[part_id] = color_picker

            # Opacity slider
            opacity_slider = widgets.FloatSlider(
                value=surface['opacity'],
                min=0.0,
                max=1.0,
                step=0.1,
                description='Opacity:',
                style={'description_width': '60px'},
                layout=widgets.Layout(width='300px')
            )
            opacity_slider.part_id = part_id
            opacity_slider.observe(self.on_opacity_change, names='value')
            self.opacity_sliders[part_id] = opacity_slider

            # Visibility checkbox
            visibility_checkbox = widgets.Checkbox(
                value=surface['visible'],
                description='Visible',
                style={'description_width': '60px'},
                layout=widgets.Layout(width='100px')
            )
            visibility_checkbox.part_id = part_id
            visibility_checkbox.observe(self.on_visibility_change, names='value')
            self.visibility_checkboxes[part_id] = visibility_checkbox

            # Volume info
            volume_info = widgets.HTML(
                f"<small>Volume: {surface['volume_cm3']:.1f} cm¬≥</small>"
            )

            # Group controls for this part
            part_controls = widgets.VBox([
                title,
                widgets.HBox([color_picker, opacity_slider, visibility_checkbox]),
                volume_info,
                widgets.HTML("<hr>")
            ])

            control_widgets.append(part_controls)

        # Global controls
        global_title = widgets.HTML("<h3>üéÆ Global Controls</h3>")

        # Show/Hide all buttons
        show_all_btn = widgets.Button(
            description='Show All',
            button_style='success',
            layout=widgets.Layout(width='100px')
        )
        show_all_btn.on_click(self.show_all)

        hide_all_btn = widgets.Button(
            description='Hide All',
            button_style='danger',
            layout=widgets.Layout(width='100px')
        )
        hide_all_btn.on_click(self.hide_all)

        # Reset button
        reset_btn = widgets.Button(
            description='Reset All',
            button_style='warning',
            layout=widgets.Layout(width='100px')
        )
        reset_btn.on_click(self.reset_all)

        # Preset buttons
        preset_title = widgets.HTML("<h4>üé® Color Presets</h4>")

        preset1_btn = widgets.Button(description='Medical', button_style='info')
        preset1_btn.on_click(lambda b: self.apply_preset('medical'))

        preset2_btn = widgets.Button(description='Rainbow', button_style='info')
        preset2_btn.on_click(lambda b: self.apply_preset('rainbow'))

        preset3_btn = widgets.Button(description='Pastel', button_style='info')
        preset3_btn.on_click(lambda b: self.apply_preset('pastel'))

        # Global opacity slider
        global_opacity = widgets.FloatSlider(
            value=0.8,
            min=0.0,
            max=1.0,
            step=0.1,
            description='Global Opacity:',
            style={'description_width': '100px'},
            layout=widgets.Layout(width='300px')
        )
        global_opacity.observe(self.on_global_opacity_change, names='value')

        # Combine all widgets
        global_controls = widgets.VBox([
            global_title,
            widgets.HBox([show_all_btn, hide_all_btn, reset_btn]),
            preset_title,
            widgets.HBox([preset1_btn, preset2_btn, preset3_btn]),
            global_opacity,
            widgets.HTML("<hr><hr>")
        ])

        # Main control panel
        self.control_panel = widgets.VBox([
            widgets.HTML("<h2>ü´Ä Liver Visualization Controller</h2>"),
            global_controls
        ] + control_widgets)

    def create_initial_plot(self):
        """Create the initial 3D plot"""

        self.fig = go.FigureWidget()

        # Add each surface
        for part_id, surface in self.surfaces.items():
            vertices = surface['vertices']
            faces = surface['faces']

            trace = go.Mesh3d(
                x=vertices[:, 0],
                y=vertices[:, 1],
                z=vertices[:, 2],
                i=faces[:, 0],
                j=faces[:, 1],
                k=faces[:, 2],
                name=surface['name'],
                color=surface['color'],
                opacity=surface['opacity'],
                visible=surface['visible'],
                lighting=dict(
                    ambient=0.4,
                    diffuse=0.7,
                    specular=0.3,
                    roughness=0.1
                ),
                lightposition=dict(x=50, y=100, z=150),
                hovertemplate=f"<b>{surface['name']}</b><br>" +
                             f"Volume: {surface['volume_cm3']:.1f} cm¬≥<br>" +
                             f"Surface Area: {surface['surface_area_cm2']:.1f} cm¬≤<br>" +
                             "<extra></extra>"
            )

            self.fig.add_trace(trace)

        # Update layout
        self.fig.update_layout(
            title="Interactive 3D Liver Visualization Controller",
            scene=dict(
                aspectmode='data',
                camera=dict(
                    eye=dict(x=2, y=2, z=2),
                    center=dict(x=0, y=0, z=0)
                ),
                xaxis=dict(title='X (mm)', showbackground=True),
                yaxis=dict(title='Y (mm)', showbackground=True),
                zaxis=dict(title='Z (mm)', showbackground=True)
            ),
            width=900,
            height=700,
            margin=dict(r=20, b=10, l=10, t=60)
        )

    def on_color_change(self, change):
        """Handle color picker changes"""
        part_id = change['owner'].part_id
        new_color = change['new']

        self.current_colors[part_id] = new_color

        # Update the plot
        trace_idx = list(self.surfaces.keys()).index(part_id)
        with self.fig.batch_update():
            self.fig.data[trace_idx].color = new_color

    def on_opacity_change(self, change):
        """Handle opacity slider changes"""
        part_id = change['owner'].part_id
        new_opacity = change['new']

        self.current_opacities[part_id] = new_opacity

        # Update the plot
        trace_idx = list(self.surfaces.keys()).index(part_id)
        with self.fig.batch_update():
            self.fig.data[trace_idx].opacity = new_opacity

    def on_visibility_change(self, change):
        """Handle visibility checkbox changes"""
        part_id = change['owner'].part_id
        new_visibility = change['new']

        self.current_visibility[part_id] = new_visibility

        # Update the plot
        trace_idx = list(self.surfaces.keys()).index(part_id)
        with self.fig.batch_update():
            self.fig.data[trace_idx].visible = new_visibility

    def on_global_opacity_change(self, change):
        """Handle global opacity changes"""
        new_opacity = change['new']

        # Update all opacities
        for part_id in self.surfaces.keys():
            self.current_opacities[part_id] = new_opacity
            self.opacity_sliders[part_id].value = new_opacity

            trace_idx = list(self.surfaces.keys()).index(part_id)
            with self.fig.batch_update():
                self.fig.data[trace_idx].opacity = new_opacity

    def show_all(self, button):
        """Show all parts"""
        for part_id in self.surfaces.keys():
            self.visibility_checkboxes[part_id].value = True

    def hide_all(self, button):
        """Hide all parts"""
        for part_id in self.surfaces.keys():
            self.visibility_checkboxes[part_id].value = False

    def reset_all(self, button):
        """Reset all settings to default"""
        for part_id, surface in self.surfaces.items():
            self.color_pickers[part_id].value = surface['color']
            self.opacity_sliders[part_id].value = surface['opacity']
            self.visibility_checkboxes[part_id].value = surface['visible']

    def apply_preset(self, preset_name):
        """Apply color presets"""

        presets = {
            'medical': {
                1: '#8B0000',  # Dark Red
                2: '#006400',  # Dark Green
                3: '#000080',  # Navy Blue
                4: '#FF8C00'   # Dark Orange
            },
            'rainbow': {
                1: '#FF0000',  # Red
                2: '#00FF00',  # Green
                3: '#0000FF',  # Blue
                4: '#FFFF00'   # Yellow
            },
            'pastel': {
                1: '#FFB6C1',  # Light Pink
                2: '#98FB98',  # Pale Green
                3: '#87CEEB',  # Sky Blue
                4: '#F0E68C'   # Khaki
            }
        }

        if preset_name in presets:
            for part_id, color in presets[preset_name].items():
                if part_id in self.surfaces:
                    self.color_pickers[part_id].value = color

    def display(self):
        """Display the controller and plot"""

        # Create layout with controller and plot side by side
        layout = widgets.HBox([
            self.control_panel,
            widgets.VBox([
                widgets.HTML("<h3>üé® Real-time 3D Visualization</h3>"),
                self.fig
            ])
        ])

        display(layout)

        # Instructions
        instructions = widgets.HTML("""
        <div style='background-color: #f0f8ff; padding: 15px; border-radius: 10px; margin: 10px;'>
        <h4>üéÆ How to Use the Interactive Controller:</h4>
        <ul>
        <li><b>Color:</b> Select different colors for each liver part from dropdown</li>
        <li><b>Opacity:</b> Adjust transparency (0 = transparent, 1 = opaque)</li>
        <li><b>Visibility:</b> Show/hide individual parts with checkboxes</li>
        <li><b>Global Controls:</b> Show all, hide all, or reset to defaults</li>
        <li><b>Presets:</b> Apply predefined color schemes</li>
        <li><b>3D Navigation:</b> Click and drag to rotate, scroll to zoom</li>
        </ul>
        </div>
        """)

        display(instructions)

# ============================================================================
# STEP 3: Advanced Visualization Options
# ============================================================================

def create_comparison_view(surfaces, save_dir):
    """Create side-by-side comparison views"""

    print("üîç Creating comparison visualization...")

    # Create subplots
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('All Parts', 'Individual Parts', 'Cross-Section View', 'Statistics'),
        specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}],
               [{'type': 'scatter3d'}, {'type': 'bar'}]],
        vertical_spacing=0.08,
        horizontal_spacing=0.05
    )

    # Plot 1: All parts together
    for part_id, surface in surfaces.items():
        vertices = surface['vertices']
        faces = surface['faces']

        fig.add_trace(
            go.Mesh3d(
                x=vertices[:, 0], y=vertices[:, 1], z=vertices[:, 2],
                i=faces[:, 0], j=faces[:, 1], k=faces[:, 2],
                name=surface['name'],
                color=surface['color'],
                opacity=0.7,
                showlegend=True
            ),
            row=1, col=1
        )

    # Plot 2: Individual parts (cycling through)
    for i, (part_id, surface) in enumerate(surfaces.items()):
        vertices = surface['vertices']
        faces = surface['faces']

        fig.add_trace(
            go.Mesh3d(
                x=vertices[:, 0], y=vertices[:, 1], z=vertices[:, 2],
                i=faces[:, 0], j=faces[:, 1], k=faces[:, 2],
                name=f"Solo {surface['name']}",
                color=surface['color'],
                opacity=0.9,
                visible=(i == 0),  # Only first one visible initially
                showlegend=False
            ),
            row=1, col=2
        )

    # Plot 3: Cross-section (simplified point cloud)
    z_slice = liver_3parts.shape[2] // 2
    slice_data = liver_3parts[:, :, z_slice]

    for part_id, surface in surfaces.items():
        if part_id > 3:  # Skip tumors for cleaner view
            continue

        coords = np.where(slice_data == part_id)
        if len(coords[0]) > 0:
            # Sample points for visualization
            sample_size = min(1000, len(coords[0]))
            indices = np.random.choice(len(coords[0]), sample_size, replace=False)

            fig.add_trace(
                go.Scatter3d(
                    x=coords[0][indices] * spacing[0],
                    y=coords[1][indices] * spacing[1],
                    z=np.full(sample_size, z_slice * spacing[2]),
                    mode='markers',
                    marker=dict(size=3, color=surface['color'], opacity=0.8),
                    name=f"Cross-section {surface['name']}",
                    showlegend=False
                ),
                row=2, col=1
            )

    # Plot 4: Volume statistics
    volumes = [surface['volume_cm3'] for surface in surfaces.values()]
    names = [surface['name'] for surface in surfaces.values()]
    colors_bar = [surface['color'] for surface in surfaces.values()]

    fig.add_trace(
        go.Bar(
            x=names,
            y=volumes,
            marker_color=colors_bar,
            name='Volume (cm¬≥)',
            showlegend=False,
            text=[f"{v:.1f} cm¬≥" for v in volumes],
            textposition='auto'
        ),
        row=2, col=2
    )

    # Update layout
    fig.update_layout(
        title="Comprehensive Liver Analysis Dashboard",
        height=800,
        scene=dict(aspectmode='data'),
        scene2=dict(aspectmode='data'),
        scene3=dict(aspectmode='data')
    )

    # Add buttons for cycling through individual parts in plot 2
    part_buttons = []
    for i, (part_id, surface) in enumerate(surfaces.items()):
        visible_list = [True] * len(surfaces)  # Plot 1 always visible
        visible_list.extend([False] * len(surfaces))  # Plot 2 - all hidden
        visible_list[len(surfaces) + i] = True  # Show only this part in plot 2
        visible_list.extend([True] * (len(surfaces) * 2))  # Plots 3&4 visible

        part_buttons.append(
            dict(
                label=f"Show {surface['name']} Solo",
                method="update",
                args=[{"visible": visible_list}]
            )
        )

    fig.update_layout(
        updatemenus=[
            dict(
                type="dropdown",
                direction="down",
                showactive=True,
                x=0.7, y=1.0,
                buttons=part_buttons
            )
        ]
    )

    fig.show()
    fig.write_html(str(save_dir / 'liver_comparison_dashboard.html'))

    return fig

# ============================================================================
# STEP 4: Initialize and Display Interactive Controller
# ============================================================================

if hq_surfaces:
    print("\nüéõÔ∏è Initializing Interactive Control Panel...")

    # Create the controller
    liver_controller = LiverVisualizationController(hq_surfaces)

    # Display the interactive interface
    print("üé® Launching Interactive Visualization Controller...")
    liver_controller.display()

    # Create comparison dashboard
    comparison_fig = create_comparison_view(hq_surfaces, directories['visualizations'])

    # Save the controller setup for later use
    controller_settings = {
        'initial_colors': {str(k): v['color'] for k, v in hq_surfaces.items()},
        'initial_opacities': {str(k): v['opacity'] for k, v in hq_surfaces.items()},
        'part_volumes': {str(k): float(v['volume_cm3']) for k, v in hq_surfaces.items()}, # Convert float64 to float
        'surface_areas': {str(k): float(v['surface_area_cm2']) for k, v in hq_surfaces.items()} # Convert float32 to float
    }

    with open(directories['results'] / 'controller_settings.json', 'w') as f:
        json.dump(controller_settings, f, indent=2)

    print(f"üíæ Controller settings saved to: {directories['results'] / 'controller_settings.json'}")


    print(f"\nüéâ Part 5 Complete!")
    print(f"‚úÖ Interactive control panel launched with full functionality")
    print(f"‚úÖ Real-time color, opacity, and visibility controls")
    print(f"‚úÖ Multiple visualization presets available")
    print(f"‚úÖ Comparison dashboard created")
    print(f"üíæ All settings and dashboards saved to: {directories['visualizations']}")

    # Display usage tips
    display(widgets.HTML("""
    <div style='background-color: #e6ffe6; padding: 15px; border-radius: 10px; margin: 20px 0;'>
    <h3>üéØ Interactive Features Available:</h3>
    <ul>
    <li><b>Real-time Controls:</b> Change colors, opacity, and visibility instantly</li>
    <li><b>Color Presets:</b> Medical, Rainbow, and Pastel color schemes</li>
    <li><b>3D Navigation:</b> Rotate, zoom, and pan the 3D model</li>
    <li><b>Individual Part Analysis:</b> Focus on specific liver regions</li>
    <li><b>Volume Information:</b> Hover over parts to see detailed metrics</li>
    <li><b>Export Options:</b> All visualizations saved as HTML files</li>
    </ul>
    <p><b>üéÆ Try experimenting with different settings to explore your liver segmentation!</b></p>
    </div>
    """))

else:
    print("‚ùå No surface data available. Please run Part 4 first!")

print(f"\nüèÅ Complete Liver Segmentation Pipeline Finished!")
print(f"üìä Summary of all generated files:")
print(f"   - 3D Interactive Controller: interactive_3part_liver.html")
print(f"   - Comparison Dashboard: liver_comparison_dashboard.html")
print(f"   - Dice Score Analysis: dice_comparison.html (Note: Dice score calculation is in Part 4, visualization might need a separate step or be incorporated into the dashboard)")
print(f"   - All numerical results: 3part_liver_results.json")
print(f"   - Controller settings: controller_settings.json")