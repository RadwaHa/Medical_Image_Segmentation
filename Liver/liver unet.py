# -*- coding: utf-8 -*-
"""liver seg

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17h8OUmYY0tiDM1_r1f_mqfrPghc1dPqr
"""

# Cell 1 - إعداد البيئة و mount Google Drive
# شغّل هذه الخلية أولاً

# تثبيت مكتبات إن احتاجت
!pip install nibabel --quiet
!pip install scikit-image --quiet
!pip install plotly --quiet
!pip install matplotlib --quiet

# Mount Google Drive لو بدك تحفظ/تقرا من Drive
from google.colab import drive
drive.mount('/content/drive')

import os
print("Working dir:", os.getcwd())
import tensorflow as tf

# Cell 2 - تحميل وفك الـ tar
!wget -q "https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar" -O /content/Task03_Liver.tar

# فك الضغط
!mkdir -p /content/Task03_Liver
!tar -xf /content/Task03_Liver.tar -C /content/Task03_Liver
!ls -lh /content/Task03_Liver
# تحقق من المحتويات باستخدام بايثون
import os
print("=== Contents of Task03_Liver ===")
import tensorflow as tf
nii_files = []
for root, dirs, files in os.walk("/content/Task03_Liver"):
    for file in files:
        if file.endswith(".nii.gz"):
            full_path = os.path.join(root, file)
            nii_files.append(full_path)
            if len(nii_files) <= 5:  # عرض أول 5 ملفات فقط
                print(f"📄 {full_path}")

print(f"\n✅ Total .nii.gz files found: {len(nii_files)}")

# إذا ما في ملفات، شوف شو موجود
if len(nii_files) == 0:
    print("\n🔍 Searching for any files...")
    all_files = []
    for root, dirs, files in os.walk("/content/Task03_Liver"):
        for file in files:
            all_files.append(os.path.join(root, file))
            if len(all_files) <= 10:
                print(f"📁 {os.path.join(root, file)}")

    print(f"\nTotal files found: {len(all_files)}")

# Cell 3 - إعداد المسارات والهايبرباراميترز
class Config:
    ROOT = "/content/Task03_Liver"

    # المسارات الصحيحة - حسب هيكلة الملفات الي طلعت
    IMAGES_TR = os.path.join(ROOT, "Task03_Liver", "imagesTr")  # لأن الملفات تحت Task03_Liver/
    LABELS_TR = os.path.join(ROOT, "Task03_Liver", "labelsTr")  # نفس الشيء للabels

    IMAGE_HEIGHT = 240
    IMAGE_WIDTH = 240
    NUM_CLASSES = 4
    BATCH_SIZE = 8
    EPOCHS = 100
    LEARNING_RATE = 1e-4
    OUTPUT_DIR = "/content/drive/MyDrive/Seg3Data_liver_results"

import os
os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

# تحقق من المسارات الجديدة
print("🔍 Checking adjusted paths...")
print(f"IMAGES_TR: {Config.IMAGES_TR}")
print(f"IMAGES_TR exists: {os.path.exists(Config.IMAGES_TR)}")
print(f"LABELS_TR: {Config.LABELS_TR}")
print(f"LABELS_TR exists: {os.path.exists(Config.LABELS_TR)}")

# إذا لسا labelsTr مش موجود، شوف وين الملفات
if not os.path.exists(Config.LABELS_TR):
    print("\n🔍 Searching for label files...")
    for root, dirs, files in os.walk("/content/Task03_Liver"):
        if "label" in root.lower():
            print(f"Found label-related directory: {root}")
            nii_files = [f for f in files if f.endswith('.nii.gz')]
            if nii_files:
                print(f"  Contains {len(nii_files)} .nii.gz files")

# ==============================
# Cell 4 - Data Loader & Preprocessing (FIXED)
# ==============================
import numpy as np
import nibabel as nib
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
import glob
import cv2

def load_nifti(path):
    """Load NIfTI file and return data"""
    try:
        img = nib.load(path)
        data = img.get_fdata()
        return data
    except Exception as e:
        print(f"❌ Error loading {path}: {e}")
        return None

# تحميل المسارات
image_paths = sorted(glob.glob(os.path.join(Config.IMAGES_TR, "*.nii.gz")))
label_paths = sorted(glob.glob(os.path.join(Config.LABELS_TR, "*.nii.gz")))

print(f"📁 Found {len(image_paths)} images and {len(label_paths)} masks")

if not image_paths or not label_paths:
    print("❌ No files found! Check paths above.")
else:
    print(f"✅ First image: {os.path.basename(image_paths[0])}")
    print(f"✅ First mask: {os.path.basename(label_paths[0])}")

def preprocess(img, mask, target_size=(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH)):
    """Preprocess single slice"""
    if img is None or mask is None:
        return None, None

    # نأخذ الشريحة الوسطى
    if len(img.shape) == 3:  # إذا 3D
        mid = img.shape[2] // 2
        img_slice = img[:, :, mid]
        mask_slice = mask[:, :, mid]
    else:  # إذا 2D
        img_slice = img
        mask_slice = mask

    # Normalize الصورة
    img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

    # Resize
    img_slice = cv2.resize(img_slice, target_size, interpolation=cv2.INTER_LINEAR)
    mask_slice = cv2.resize(mask_slice, target_size, interpolation=cv2.INTER_NEAREST)

    # Expand dimensions
    img_slice = np.expand_dims(img_slice, axis=-1)  # (H, W, 1)

    # Convert mask to categorical
    mask_slice = mask_slice.astype(np.uint8)
    # تأكد إنه الأرقام ضمن المدى الصحيح
    mask_slice = np.clip(mask_slice, 0, Config.NUM_CLASSES-1)
    mask_slice = to_categorical(mask_slice, num_classes=Config.NUM_CLASSES)

    return img_slice, mask_slice

# إنشاء X و Y
X, Y = [], []
success_count = 0

# خذ عدد أقل عشان التجربة (10-20)
for i, (img_path, mask_path) in enumerate(zip(image_paths[:20], label_paths[:20])):
    print(f"🔄 Processing {i+1}/20: {os.path.basename(img_path)}")

    try:
        # تحميل البيانات
        img_data = load_nifti(img_path)
        mask_data = load_nifti(mask_path)

        if img_data is not None and mask_data is not None:
            # معالجة البيانات
            img_processed, mask_processed = preprocess(img_data, mask_data)

            if img_processed is not None and mask_processed is not None:
                X.append(img_processed)
                Y.append(mask_processed)
                success_count += 1
                print(f"   ✅ Success - img: {img_processed.shape}, mask: {mask_processed.shape}")
            else:
                print(f"   ❌ Preprocessing failed")
        else:
            print(f"   ❌ Loading failed")

    except Exception as e:
        print(f"   ❌ Error: {e}")

# تحويل ل numpy arrays
if X and Y:
    X = np.array(X)
    Y = np.array(Y)
    print(f"\n🎉 SUCCESS: Created X: {X.shape}, Y: {Y.shape}")
    print(f"📊 X range: [{X.min():.3f}, {X.max():.3f}]")
    print(f"📊 Y unique values: {np.unique(np.argmax(Y, axis=-1))}")
else:
    print("\n❌ FAILED: No data processed!")
    # استخدم بيانات تجريبية
    print("🔄 Creating sample data for testing...")
    X = np.random.rand(20, Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1).astype(np.float32)
    Y_categorical = np.random.randint(0, Config.NUM_CLASSES, (20, Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH))
    Y = to_categorical(Y_categorical, num_classes=Config.NUM_CLASSES)
    print(f"📊 Sample data - X: {X.shape}, Y: {Y.shape}")

# ==============================
# Cell 5 - U-Net Model
# ==============================
from tensorflow.keras import layers, models

def build_unet(input_shape=(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1), num_classes=Config.NUM_CLASSES):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2,2))(c1)

    c2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2,2))(c2)

    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2,2))(c3)

    c4 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling2D((2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u5)
    c5 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c5)

    u6 = layers.UpSampling2D((2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(c6)

    u7 = layers.UpSampling2D((2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(c7)

    outputs = layers.Conv2D(num_classes, (1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

model = build_unet()
model.compile(optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
              loss="categorical_crossentropy",
              metrics=["accuracy"])
model.summary()

# ضيف هاد الكود في خلية جديدة قبل الخلية 6

print("🔍 === DEBUGGING DATA FLOW ===")

# 1. تحقق من الخلية 2
print("1. Checking Cell 2 (Data Download)...")
import os
if os.path.exists("/content/Task03_Liver"):
    nii_files = []
    for root, dirs, files in os.walk("/content/Task03_Liver"):
        for file in files:
            if file.endswith(".nii.gz"):
                nii_files.append(os.path.join(root, file))
    print(f"   Found {len(nii_files)} .nii.gz files")
    if nii_files:
        print(f"   First 3 files: {nii_files[:3]}")
else:
    print("   ❌ Task03_Liver directory not found!")

# 2. تحقق من الخلية 4
print("\n2. Checking Cell 4 (Data Processing)...")
print(f"   X exists: {'X' in locals()}")
print(f"   Y exists: {'Y' in locals()}")

if 'X' in locals():
    print(f"   X shape: {X.shape if hasattr(X, 'shape') else 'No shape'}")
    print(f"   X type: {type(X)}")

if 'Y' in locals():
    print(f"   Y shape: {Y.shape if hasattr(Y, 'shape') else 'No shape'}")
    print(f"   Y type: {type(Y)}")

# 3. تحقق من المسارات
print("\n3. Checking Paths...")
print(f"   IMAGES_TR: {Config.IMAGES_TR}")
print(f"   IMAGES_TR exists: {os.path.exists(Config.IMAGES_TR)}")
print(f"   LABELS_TR: {Config.LABELS_TR}")
print(f"   LABELS_TR exists: {os.path.exists(Config.LABELS_TR)}")

# 4. إذا X و Y فاضيين، جرب نعملهم من جديد
if 'X' not in locals() or (hasattr(X, 'shape') and X.shape[0] == 0):
    print("\n🔄 Attempting to recreate X and Y...")

    import glob
    import nibabel as nib
    import numpy as np
    import cv2
    from tensorflow.keras.utils import to_categorical

    # جرب تحميل البيانات يدوياً
    image_paths = sorted(glob.glob(os.path.join(Config.IMAGES_TR, "*.nii.gz")))
    label_paths = sorted(glob.glob(os.path.join(Config.LABELS_TR, "*.nii.gz")))

    print(f"   Found {len(image_paths)} images, {len(label_paths)} masks")

    if image_paths and label_paths:
        X_temp, Y_temp = [], []

        for i, (img_path, mask_path) in enumerate(zip(image_paths[:5], label_paths[:5])):  # أول 5 فقط للتجربة
            try:
                print(f"   Processing {i+1}: {os.path.basename(img_path)}")

                # تحميل البيانات
                img = nib.load(img_path).get_fdata()
                mask = nib.load(mask_path).get_fdata()

                # معالجة شريحة واحدة
                mid = img.shape[2] // 2
                img_slice = img[:, :, mid]
                mask_slice = mask[:, :, mid]

                # Normalize
                img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

                # Resize
                img_slice = cv2.resize(img_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH))
                mask_slice = cv2.resize(mask_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH), interpolation=cv2.INTER_NEAREST)

                # Expand dims
                img_slice = np.expand_dims(img_slice, axis=-1)
                mask_slice = to_categorical(mask_slice.astype(np.uint8), num_classes=Config.NUM_CLASSES)

                X_temp.append(img_slice)
                Y_temp.append(mask_slice)

            except Exception as e:
                print(f"   ❌ Error processing {img_path}: {e}")

        if X_temp:
            X = np.array(X_temp)
            Y = np.array(Y_temp)
            print(f"   ✅ Created X: {X.shape}, Y: {Y.shape}")
        else:
            print("   ❌ Failed to create X and Y")

# ==============================
# Cell 7 - Training
# ==============================
history = model.fit(
    X, Y,
    validation_split=0.2,
    batch_size=Config.BATCH_SIZE,
    epochs=5   # للتجربة (زوديها لاحقاً)
)

# Cell 8 - بناء U-Net 2D (مشتق من كودك الأصل)
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose
from tensorflow.keras.layers import concatenate, BatchNormalization, Activation
from tensorflow.keras.models import Model

def build_unet_2d(h, w, channels, num_classes):
    inputs = Input((h, w, channels))
    # Encoder
    conv1 = Conv2D(32, (3,3), padding='same', activation='relu')(inputs)
    conv1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv1)
    pool1 = MaxPooling2D()(conv1)

    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(pool1)
    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(conv2)
    pool2 = MaxPooling2D()(conv2)

    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(pool2)
    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(conv3)
    pool3 = MaxPooling2D()(conv3)

    conv4 = Conv2D(256, (3,3), padding='same', activation='relu')(pool3)
    conv4 = Conv2D(256, (3,3), padding='same', activation='relu')(conv4)

    # Decoder
    up3 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv4)
    up3 = concatenate([up3, conv3])
    conv5 = Conv2D(128, (3,3), padding='same', activation='relu')(up3)
    conv5 = Conv2D(128, (3,3), padding='same', activation='relu')(conv5)

    up2 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(conv5)
    up2 = concatenate([up2, conv2])
    conv6 = Conv2D(64, (3,3), padding='same', activation='relu')(up2)
    conv6 = Conv2D(64, (3,3), padding='same', activation='relu')(conv6)

    up1 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(conv6)
    up1 = concatenate([up1, conv1])
    conv7 = Conv2D(32, (3,3), padding='same', activation='relu')(up1)
    conv7 = Conv2D(32, (3,3), padding='same', activation='relu')(conv7)

    out = Conv2D(num_classes, (1,1), activation='softmax')(conv7)
    model = Model(inputs=inputs, outputs=out)
    return model

model = build_unet_2d(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1, Config.NUM_CLASSES)
model.compile(optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
              loss='categorical_crossentropy',
              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=Config.NUM_CLASSES)])
model.summary()

# Cell 8.1 - Slice Generator
# هذا الكلاس بيساعدنا نحمل البيانات على شكل شرائح
import glob
import os
import tensorflow as tf
import numpy as np
import nibabel as nib
import cv2
from tensorflow.keras.utils import to_categorical

class SliceGenerator(tf.keras.utils.Sequence):
    def __init__(self, file_indices, batch_size, num_classes, img_height, img_width, shuffle=True):
        self.file_indices = file_indices
        self.batch_size = batch_size
        self.num_classes = num_classes
        self.img_height = img_height
        self.img_width = img_width
        self.shuffle = shuffle
        self.on_epoch_end() # Shuffle initially

        # مسارات الملفات (تأكد إنها صحيحة)
        self.image_paths = sorted(glob.glob(os.path.join(Config.IMAGES_TR, "*.nii.gz")))
        self.label_paths = sorted(glob.glob(os.path.join(Config.LABELS_TR, "*.nii.gz")))


    def __len__(self):
        # عدد الباتشات في كل epoch
        return int(np.floor(len(self.file_indices) / self.batch_size))

    def __getitem__(self, index):
        # جلب باتش من البيانات
        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        batch_file_indices = [self.file_indices[k] for k in indices]

        X, Y = self.__data_generation(batch_file_indices)
        return X, Y

    def on_epoch_end(self):
        # خلط الملفات بعد كل epoch إذا shuffle = True
        self.indices = np.arange(len(self.file_indices))
        if self.shuffle == True:
            np.random.shuffle(self.indices)

    def __data_generation(self, batch_file_indices):
        # توليد البيانات للباتش
        X_batch = np.empty((self.batch_size, self.img_height, self.img_width, 1))
        Y_batch = np.empty((self.batch_size, self.img_height, self.img_width, self.num_classes))

        for i, file_idx in enumerate(batch_file_indices):
            try:
                img_path = self.image_paths[file_idx]
                mask_path = self.label_paths[file_idx]

                # تحميل البيانات
                img_data = nib.load(img_path).get_fdata()
                mask_data = nib.load(mask_path).get_fdata()

                # معالجة شريحة واحدة (الوسطى)
                if len(img_data.shape) == 3:
                    mid = img_data.shape[2] // 2
                    img_slice = img_data[:, :, mid]
                    mask_slice = mask_data[:, :, mid]
                else:
                    img_slice = img_data
                    mask_slice = mask_data

                # Normalize الصورة
                img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

                # Resize
                img_slice = cv2.resize(img_slice, (self.img_width, self.img_height), interpolation=cv2.INTER_LINEAR)
                mask_slice = cv2.resize(mask_slice, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)

                # Expand dimensions
                X_batch[i,] = np.expand_dims(img_slice, axis=-1)

                # Convert mask to categorical
                mask_slice = mask_slice.astype(np.uint8)
                 # تأكد إنه الأرقام ضمن المدى الصحيح
                mask_slice = np.clip(mask_slice, 0, self.num_classes-1)
                Y_batch[i,] = to_categorical(mask_slice, num_classes=self.num_classes)

            except Exception as e:
                print(f"❌ Error loading/processing file index {file_idx}: {e}")
                # Handle error: could load dummy data or skip
                # For simplicity, we'll fill with zeros for now
                X_batch[i,] = np.zeros((self.img_height, self.img_width, 1))
                Y_batch[i,] = np.zeros((self.img_height, self.img_width, self.num_classes))


        return X_batch, Y_batch

# Cell 8.5 - استخدام الملفات الناجحة المعروفة

# الملفات الي عرفنا إنها شغالة
successful_files_indices = []
successful_filenames = ['liver_100.nii.gz', 'liver_101.nii.gz', 'liver_102.nii.gz',
                       'liver_105.nii.gz', 'liver_110.nii.gz']

for i, img_path in enumerate(image_paths):
    if any(filename in img_path for filename in successful_filenames):
        successful_files_indices.append(i)

print(f"🎯 Using {len(successful_files_indices)} known successful files")

if len(successful_files_indices) >= 4:
    train_idx, val_idx = train_test_split(
        successful_files_indices,
        test_size=0.2,
        random_state=42,
        shuffle=True
    )
    print(f"📊 Train: {len(train_idx)} files, Val: {len(val_idx)} files")
else:
    print("❌ Not enough successful files, using sample data...")
    # بيانات تجريبية
    train_idx, val_idx = [0, 1, 2], [3, 4]

print("🔍 Testing generator...")
test_batch_X, test_batch_Y = train_gen[0]
print(f"✅ Generator test - X: {test_batch_X.shape}, Y: {test_batch_Y.shape}")
print(f"📊 X range: [{test_batch_X.min():.3f}, {test_batch_X.max():.3f}]")
print(f"📊 Y unique classes: {np.unique(np.argmax(test_batch_Y, axis=-1))}")

# إذا كلشي تمام، اكمل التدريب
print("🚀 Starting training with generator...")

# Cell 9 - استخدام البيانات مباشرة (بدون Generator) - المعدل

print("🚀 Using direct data without generator...")

# أولاً: أنشئ X و Y من الملفات الناجحة مباشرة
X, Y = [], []

for filename in ['liver_100.nii.gz', 'liver_101.nii.gz', 'liver_102.nii.gz', 'liver_105.nii.gz', 'liver_110.nii.gz']:
    img_path = os.path.join(Config.IMAGES_TR, filename)
    mask_path = os.path.join(Config.LABELS_TR, filename)

    print(f"📁 Loading {filename}...")

    try:
        img_data = nib.load(img_path).get_fdata()
        mask_data = nib.load(mask_path).get_fdata()

        # خذ شريحة واحدة من المنتصف
        mid = img_data.shape[2] // 2
        img_slice = img_data[:, :, mid]
        mask_slice = mask_data[:, :, mid]

        # Normalize
        img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

        # Resize
        img_slice = cv2.resize(img_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH))
        mask_slice = cv2.resize(mask_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH), interpolation=cv2.INTER_NEAREST)

        # Expand dimensions
        img_slice = np.expand_dims(img_slice, axis=-1)
        mask_slice = to_categorical(mask_slice.astype(np.uint8), num_classes=Config.NUM_CLASSES)

        X.append(img_slice)
        Y.append(mask_slice)
        print(f"   ✅ Success")

    except Exception as e:
        print(f"   ❌ Error: {e}")

X = np.array(X)
Y = np.array(Y)

print(f"🎯 Final dataset - X: {X.shape}, Y: {Y.shape}")

# التدريب المباشر
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)
]

history = model.fit(
    X, Y,
    validation_split=0.2,
    batch_size=min(Config.BATCH_SIZE, len(X)),  # تأكد إنه batch size لا يزيد عن عدد العينات
    epochs=Config.EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# حفظ الموديل - الحلول البديلة
try:
    # الحل 1: جرب .keras format
    model.save('/content/final_unet_liver.keras')
    print("✅ Model saved as .keras format!")

    # إذا بدك تحمله ل Drive
    from google.colab import files
    files.download('/content/final_unet_liver.keras')
    print("✅ Model downloaded to your computer!")

except Exception as e:
    print(f"❌ Error saving .keras: {e}")

    try:
        # الحل 2: جرب حفظ في Drive مباشرة
        model.save('/content/drive/MyDrive/final_unet_liver.keras')
        print("✅ Model saved directly to Google Drive!")
    except Exception as e2:
        print(f"❌ Error saving to Drive: {e2}")

        # الحل 3: نظف الذاكرة وجرب مرة ثانية
        import gc
        gc.collect()
        model.save('/content/final_unet_liver.h5')
        print("✅ Model saved after memory cleanup!")

print("🎉 Training completed successfully!")

# Cell 10 - اختبار سريع على بعض الشرائح وعرض
import matplotlib.pyplot as plt
import numpy as np
from skimage.transform import resize

def predict_slice_mask(model, img3d, slice_idx):
    """تنبؤ بالmask لشريحة معينة"""
    img = img3d[:,:,slice_idx]
    img_r = resize(img, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH), preserve_range=True, order=1)
    X = np.expand_dims(img_r, axis=(0, -1))

    # Normalize
    X = (X - np.min(X)) / (np.max(X) - np.min(X) + 1e-8)

    pred = model.predict(X, verbose=0)
    pred_mask = np.argmax(pred[0], axis=-1)
    return pred_mask

# استخدام الملفات الناجحة مباشرة
successful_files = ['liver_100.nii.gz', 'liver_101.nii.gz', 'liver_102.nii.gz']

for filename in successful_files[:1]:  # جرب أول ملف فقط
    try:
        img_path = os.path.join(Config.IMAGES_TR, filename)
        mask_path = os.path.join(Config.LABELS_TR, filename)

        print(f"🔍 Testing on {filename}...")

        # تحميل البيانات
        img3d = nib.load(img_path).get_fdata()
        lbl3d = nib.load(mask_path).get_fdata()

        # اختر 3 شرائح من مناطق مختلفة
        num_slices = img3d.shape[2]
        slices_to_show = [
            num_slices // 4,      # أول الربع
            num_slices // 2,      # المنتصف
            3 * num_slices // 4   # آخر الربع
        ]

        # إنشاء plots
        fig, axes = plt.subplots(len(slices_to_show), 4, figsize=(16, 4*len(slices_to_show)))

        for i, slice_idx in enumerate(slices_to_show):
            # التنبؤ
            pred_mask = predict_slice_mask(model, img3d, slice_idx)
            gt_mask = lbl3d[:,:,slice_idx]

            # الصورة الأصلية (normalized)
            img_slice = img3d[:,:,slice_idx]
            img_norm = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

            # 1. الصورة الأصلية
            axes[i, 0].imshow(img_norm, cmap='gray')
            axes[i, 0].set_title(f"Slice {slice_idx}\nOriginal Image")
            axes[i, 0].axis('off')

            # 2. الـ Ground Truth
            axes[i, 1].imshow(gt_mask, cmap='jet', vmin=0, vmax=Config.NUM_CLASSES-1)
            axes[i, 1].set_title("Ground Truth")
            axes[i, 1].axis('off')

            # 3. التنبؤ
            axes[i, 2].imshow(pred_mask, cmap='jet', vmin=0, vmax=Config.NUM_CLASSES-1)
            axes[i, 2].set_title("Prediction")
            axes[i, 2].axis('off')

            # 4. Overlay
            axes[i, 3].imshow(img_norm, cmap='gray')
            axes[i, 3].imshow(pred_mask, cmap='jet', alpha=0.5, vmin=0, vmax=Config.NUM_CLASSES-1)
            axes[i, 3].set_title("Overlay")
            axes[i, 3].axis('off')

        plt.suptitle(f"Results for {filename}", fontsize=16, y=0.98)
        plt.tight_layout()
        plt.show()

        # حساب metrics بسيطة
        print(f"📊 Quick evaluation for {filename}:")
        for slice_idx in slices_to_show:
            pred_mask = predict_slice_mask(model, img3d, slice_idx)
            gt_mask = lbl3d[:,:,slice_idx]

            # Resize الـ GT ليتطابق مع الـ prediction
            gt_resized = resize(gt_mask, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH),
                              preserve_range=True, order=0, anti_aliasing=False)

            accuracy = np.mean(pred_mask == gt_resized)
            print(f"  Slice {slice_idx}: Accuracy = {accuracy:.3f}")

    except Exception as e:
        print(f"❌ Error processing {filename}: {e}")
        continue

print("✅ Testing completed!")

# Cell 11 - تحقق قبل الرسم
print("🔍 Checking prediction volume...")

# استخدم بيانات حقيقية أولاً
if 'img3d' not in locals():
    # حمل بيانات جديدة إذا مش موجودة
    filename = 'liver_100.nii.gz'
    img_path = os.path.join(Config.IMAGES_TR, filename)
    img3d = nib.load(img_path).get_fdata()
    print(f"✅ Loaded {filename} - shape: {img3d.shape}")

# أنشئ volume تنبؤات
start, end = 0, min(img3d.shape[2], 32)  # عدد أقل لتسريع
pred_vol = np.zeros((Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, end-start), dtype=np.uint8)

print(f"🔄 Generating predictions for slices {start} to {end}...")
for i, s in enumerate(range(start, end)):
    pred_vol[:,:,i] = predict_slice_mask(model, img3d, s)

# تحقق من المحتويات
unique_vals = np.unique(pred_vol)
print(f"📊 Unique values in pred_vol: {unique_vals}")
print(f"📊 Class distribution: {np.bincount(pred_vol.flatten())}")

if 1 not in unique_vals:
    print("❌ No liver (class 1) detected in predictions!")
    print("💡 Trying class 2 (tumor) instead...")
    target_class = 2
else:
    target_class = 1

# Cell 11 - تحليل أداء الموديل الحالي (المعدل)
print("🔍 Analyzing current model performance...")

# 1. تحقق من توزيع الأصناف في البيانات الأصلية
print("\n📊 Class distribution in GROUND TRUTH:")
for i in range(len(Y)):
    unique, counts = np.unique(np.argmax(Y[i], axis=-1), return_counts=True)
    print(f"Sample {i}: {dict(zip(unique, counts))}")

# 2. تنبؤات الموديل على بيانات التدريب
predictions = model.predict(X, verbose=0)
pred_classes = np.argmax(predictions, axis=-1)

print("\n📊 Class distribution in PREDICTIONS:")
for i in range(len(predictions)):
    unique, counts = np.unique(pred_classes[i], return_counts=True)
    print(f"Sample {i}: {dict(zip(unique, counts))}")

# 3. حساب metrics مفصلة لكل صنف
from sklearn.metrics import classification_report

y_true_flat = np.argmax(Y, axis=-1).flatten()
y_pred_flat = pred_classes.flatten()

# اكتشف عدد الأصناف الفعلي
actual_classes = np.unique(y_true_flat)
print(f"\n🎯 Actual classes found: {actual_classes}")

print("\n🎯 Detailed Classification Report:")
print(classification_report(y_true_flat, y_pred_flat,
                          target_names=['Background', 'Liver', 'Tumor'][:len(actual_classes)],
                          labels=actual_classes))

# 4. عرض visual comparison
fig, axes = plt.subplots(3, 4, figsize=(16, 12))

for i in range(min(3, len(X))):  # أول 3 عينات أو أقل
    # الصورة الأصلية
    axes[i, 0].imshow(X[i, :, :, 0], cmap='gray')
    axes[i, 0].set_title(f'Sample {i+1}\nInput Image')
    axes[i, 0].axis('off')

    # Ground Truth
    true_mask = np.argmax(Y[i], axis=-1)
    axes[i, 1].imshow(true_mask, cmap='jet', vmin=0, vmax=2)  # max = 2 لأن في 3 classes فقط
    axes[i, 1].set_title('Ground Truth')
    axes[i, 1].axis('off')

    # Prediction
    pred_mask = pred_classes[i]
    axes[i, 2].imshow(pred_mask, cmap='jet', vmin=0, vmax=2)
    axes[i, 2].set_title('Model Prediction')
    axes[i, 2].axis('off')

    # Difference (الأخطاء)
    diff = np.abs(true_mask - pred_mask)
    axes[i, 3].imshow(diff, cmap='hot', vmin=0, vmax=2)
    axes[i, 3].set_title('Difference\n(Errors)')
    axes[i, 3].axis('off')

# إخفاء الصفوف الفاضية إذا عدد العينات أقل من 3
for i in range(len(X), 3):
    for j in range(4):
        axes[i, j].set_visible(False)

plt.suptitle('Model Performance Analysis - Current Results', fontsize=16, y=0.95)
plt.tight_layout()
plt.show()

# 5. تحليل النتائج
print("\n🔍 ANALYSIS RESULTS:")
print("• Ground Truth: Samples 0-2 كلها خلفية فقط")
print("• Ground Truth: Sample 3 فيه كبد (class 1)")
print("• Ground Truth: Sample 4 فيه كبد (class 1) وورم (class 2)")
print("• Predictions: كل العينات = خلفية فقط (class 0)")

print("\n💡 CONCLUSIONS:")
print("✅ الموديل شغال - لكنه overfitting على class 0 (الخلفية)")
print("❌ ما بقدر يتوقع الكبد أو الأورام - دقة 0% لهذه الأصناف")
print("📈 الـ accuracy العالي (95.2%) misleading - لأنه فقط بسبب الخلفية")

print("\n🚀 RECOMMENDATIONS:")
print("1. استخدام class weights لموازنة الأصناف")
print("2. تجربة loss functions مختلفة (Dice loss, Focal loss)")
print("3. جمع المزيد من البيانات المتوازنة")
print("4. استخدام data augmentation")

# Cell 11 - تصور 2D متقدم بدل 3D
print("🎨 Advanced 2D Visualization")

# خذ العينة الي فيها كبد وورم (sample 4)
sample_idx = 4

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# الصف الأول: تحليل مفصل
img = X[sample_idx, :, :, 0]
true_mask = np.argmax(Y[sample_idx], axis=-1)
pred_mask = pred_classes[sample_idx]

# 1. الصورة الأصلية + Ground Truth overlay
axes[0, 0].imshow(img, cmap='gray')
axes[0, 0].imshow(np.ma.masked_where(true_mask == 0, true_mask),
                  cmap='jet', alpha=0.7, vmin=0, vmax=2)
axes[0, 0].set_title('Input + Ground Truth Overlay')
axes[0, 0].axis('off')

# 2. الصورة الأصلية + Prediction overlay
axes[0, 1].imshow(img, cmap='gray')
axes[0, 1].imshow(np.ma.masked_where(pred_mask == 0, pred_mask),
                  cmap='jet', alpha=0.7, vmin=0, vmax=2)
axes[0, 1].set_title('Input + Prediction Overlay')
axes[0, 1].axis('off')

# 3. المقارنة الجانبية
axes[0, 2].imshow(true_mask, cmap='jet', vmin=0, vmax=2)
axes[0, 2].set_title('Ground Truth Only')
axes[0, 2].axis('off')

# الصف الثاني: إحصائيات
# 4. توزيع المساحات
class_names = ['Background', 'Liver', 'Tumor']
class_pixels = [np.sum(true_mask == i) for i in range(3)]

axes[1, 0].bar(class_names, class_pixels, color=['gray', 'red', 'blue'])
axes[1, 0].set_title('Pixel Distribution per Class')
axes[1, 0].set_ylabel('Number of Pixels')

# 5. مخطط الدقة لكل class
accuracy_per_class = []
for i in range(3):
    if np.sum(true_mask == i) > 0:
        acc = np.mean(pred_mask[true_mask == i] == i)
    else:
        acc = 0
    accuracy_per_class.append(acc)

axes[1, 1].bar(class_names, accuracy_per_class, color=['gray', 'red', 'blue'])
axes[1, 1].set_title('Accuracy per Class')
axes[1, 1].set_ylabel('Accuracy')
axes[1, 1].set_ylim(0, 1)

# 6. نص التحليل
analysis_text = f"""
Analysis Results:

• Background: {class_pixels[0]} pixels ({class_pixels[0]/57600*100:.1f}%)
• Liver: {class_pixels[1]} pixels ({class_pixels[1]/57600*100:.1f}%)
• Tumor: {class_pixels[2]} pixels ({class_pixels[2]/57600*100:.1f}%)

Model Performance:
• Background Accuracy: {accuracy_per_class[0]:.3f}
• Liver Accuracy: {accuracy_per_class[1]:.3f}
• Tumor Accuracy: {accuracy_per_class[2]:.3f}

Issue: Model only predicts background!
"""

axes[1, 2].text(0.1, 0.9, analysis_text, transform=axes[1, 2].transAxes,
                fontsize=10, verticalalignment='top', family='monospace')
axes[1, 2].set_title('Detailed Analysis')
axes[1, 2].axis('off')

plt.suptitle('Advanced 2D Analysis - Sample 4 (Liver + Tumor)', fontsize=16)
plt.tight_layout()
plt.show()

# Cell 12 - 3D Visualization بسيطة
print("🎨 Creating simple 3D visualization...")

# استخدم sample 4 لأن فيه كل الأصناف (0, 1, 2)
sample_idx = 4  # العينة الي فيها كبد وورم

# خذ الـ ground truth من sample 4
true_mask_3d = np.argmax(Y[sample_idx], axis=-1)

# أنشئ volume صغير للعرض
volume_3d = np.zeros((Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 10), dtype=np.uint8)

# كرر نفس الـ mask على عدة شرائح
for i in range(10):
    volume_3d[:, :, i] = true_mask_3d

print(f"📊 3D volume shape: {volume_3d.shape}")
print(f"📊 Unique classes in volume: {np.unique(volume_3d)}")

try:
    from skimage import measure
    from mpl_toolkits.mplot3d.art3d import Poly3DCollection

    # جرب ترسم class 1 (الكبد)
    if 1 in np.unique(volume_3d):
        print("🔄 Creating 3D surface for liver (class 1)...")
        verts, faces, normals, values = measure.marching_cubes(
            (volume_3d == 1).astype(np.float32),
            level=0.5
        )

        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='3d')
        mesh = Poly3DCollection(verts[faces], alpha=0.7, edgecolor='k')
        mesh.set_facecolor([1, 0, 0])  # أحمر للكبد
        ax.add_collection3d(mesh)

        ax.set_xlim(0, volume_3d.shape[0])
        ax.set_ylim(0, volume_3d.shape[1])
        ax.set_zlim(0, volume_3d.shape[2])
        ax.set_title('3D Liver Surface (Ground Truth)')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')

        plt.show()
        print("✅ 3D visualization created!")

    else:
        print("❌ No liver found for 3D visualization")

except Exception as e:
    print(f"❌ 3D visualization failed: {e}")
    print("💡 Showing 2D version instead...")

    # عرض 2D بديل
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(X[sample_idx, :, :, 0], cmap='gray')
    plt.title('Input Image')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(true_mask_3d, cmap='jet')
    plt.title('Ground Truth Mask')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(pred_classes[sample_idx], cmap='jet')
    plt.title('Model Prediction')
    plt.axis('off')

    plt.suptitle('2D Visualization (Sample 4)')
    plt.tight_layout()
    plt.show()

!pip install nibabel --quiet
!pip install scikit-image --quiet
!pip install plotly --quiet
!pip install ipywidgets --quiet
!pip install pyvista --quiet
!pip install trimesh --quiet

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import nibabel as nib
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
import glob
import cv2
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from skimage import measure
import warnings
warnings.filterwarnings('ignore')

print("✅ All libraries loaded successfully!")
print("Working dir:", os.getcwd())

!wget -c "https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar" -O /content/Task03_Liver.tar
!mkdir -p /content/Task03_Liver
!tar -xvf /content/Task03_Liver.tar -C /content/Task03_Liver
!ls -lh /content/Task03_Liver

class Config3D:
    ROOT = "/content/Task03_Liver"
    IMAGES_TR = os.path.join(ROOT, "imagesTr")
    LABELS_TR = os.path.join(ROOT, "labelsTr")

    # 3D Parameters - محسّنة للجودة
    DEPTH = 96           # زدنا الـ depth
    IMAGE_HEIGHT = 160   # زدنا الـ resolution
    IMAGE_WIDTH = 160
    NUM_CLASSES = 3      # 0-background, 1-liver, 2-tumor

    BATCH_SIZE = 2
    EPOCHS = 40
    LEARNING_RATE = 1e-4
    OUTPUT_DIR = "/content/drive/MyDrive/Liver_3D_Advanced"

os.makedirs(Config3D.OUTPUT_DIR, exist_ok=True)
print("✅ Config ready!")

def load_nifti(path):
    img = nib.load(path)
    return img.get_fdata()

def preprocess_3d_advanced(img, mask, target_shape=(Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH)):
    """
    معالجة متقدمة للـ 3D volume مع الحفاظ على التفاصيل
    """
    original_depth = img.shape[2]

    # نختار المنطقة اللي فيها الكبد (مش بس النص)
    # نبحث عن أول وآخر slice فيها liver
    nonzero_slices = np.where(np.any(mask > 0, axis=(0, 1)))[0]

    if len(nonzero_slices) > 0:
        start_slice = max(0, nonzero_slices[0] - 10)
        end_slice = min(original_depth, nonzero_slices[-1] + 10)
    else:
        start_slice = max(0, (original_depth - target_shape[0]) // 2)
        end_slice = start_slice + target_shape[0]

    # استخراج الـ volume
    img3d = img[:, :, start_slice:end_slice]
    mask3d = mask[:, :, start_slice:end_slice]

    # Resize بشكل متقدم
    img_resized = np.zeros(target_shape)
    mask_resized = np.zeros(target_shape)

    # نستخدم interpolation لكل الـ slices
    depth_ratio = img3d.shape[2] / target_shape[0]

    for i in range(target_shape[0]):
        src_idx = int(i * depth_ratio)
        if src_idx < img3d.shape[2]:
            img_resized[i] = cv2.resize(
                img3d[:,:,src_idx],
                (target_shape[2], target_shape[1]),
                interpolation=cv2.INTER_CUBIC  # أفضل من LINEAR
            )
            mask_resized[i] = cv2.resize(
                mask3d[:,:,src_idx],
                (target_shape[2], target_shape[1]),
                interpolation=cv2.INTER_NEAREST
            )

    # Normalize with contrast enhancement
    img_resized = (img_resized - np.min(img_resized)) / (np.max(img_resized) - np.min(img_resized) + 1e-8)

    # Contrast stretching
    p2, p98 = np.percentile(img_resized, (2, 98))
    img_resized = np.clip((img_resized - p2) / (p98 - p2), 0, 1)

    img_resized = np.expand_dims(img_resized, axis=-1)
    mask_resized = to_categorical(mask_resized.astype(np.uint8), num_classes=Config3D.NUM_CLASSES)

    return img_resized, mask_resized

image_paths = sorted(glob.glob(os.path.join(Config3D.IMAGES_TR, "*.nii.gz")))
label_paths = sorted(glob.glob(os.path.join(Config3D.LABELS_TR, "*.nii.gz")))

print(f"Total samples available: {len(image_paths)}")
print("Loading 3D data...")

X_3d, Y_3d = [], []
for ip, lp in zip(image_paths[:20], label_paths[:20]):
    print(f"Processing: {os.path.basename(ip)}")
    img, mask = load_nifti(ip), load_nifti(lp)
    xi, yi = preprocess_3d_advanced(img, mask)
    X_3d.append(xi)
    Y_3d.append(yi)

X_3d = np.array(X_3d)
Y_3d = np.array(Y_3d)
print(f"\n✅ 3D Data loaded: {X_3d.shape}, {Y_3d.shape}")

from tensorflow.keras import layers, models

def build_unet_3d_enhanced(input_shape=(Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH, 1),
                          num_classes=Config3D.NUM_CLASSES):
    """
    3D U-Net محسّن مع Batch Normalization و Dropout
    """
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)
    c1 = layers.BatchNormalization()(c1)
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c1)
    c1 = layers.BatchNormalization()(c1)
    p1 = layers.MaxPooling3D((2,2,2))(c1)
    p1 = layers.Dropout(0.1)(p1)

    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(p1)
    c2 = layers.BatchNormalization()(c2)
    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c2)
    c2 = layers.BatchNormalization()(c2)
    p2 = layers.MaxPooling3D((2,2,2))(c2)
    p2 = layers.Dropout(0.2)(p2)

    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(p2)
    c3 = layers.BatchNormalization()(c3)
    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c3)
    c3 = layers.BatchNormalization()(c3)
    p3 = layers.MaxPooling3D((2,2,2))(c3)
    p3 = layers.Dropout(0.3)(p3)

    # Bottleneck
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(p3)
    c4 = layers.BatchNormalization()(c4)
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c4)
    c4 = layers.BatchNormalization()(c4)
    c4 = layers.Dropout(0.4)(c4)

    # Decoder
    u5 = layers.UpSampling3D((2,2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(u5)
    c5 = layers.BatchNormalization()(c5)
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c5)
    c5 = layers.BatchNormalization()(c5)

    u6 = layers.UpSampling3D((2,2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(u6)
    c6 = layers.BatchNormalization()(c6)
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c6)
    c6 = layers.BatchNormalization()(c6)

    u7 = layers.UpSampling3D((2,2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(u7)
    c7 = layers.BatchNormalization()(c7)
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c7)
    c7 = layers.BatchNormalization()(c7)

    outputs = layers.Conv3D(num_classes, (1,1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

model_3d = build_unet_3d_enhanced()
model_3d.compile(
    optimizer=tf.keras.optimizers.Adam(Config3D.LEARNING_RATE),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
print("\n3D U-Net Enhanced Model:")
model_3d.summary()

import os

class Config:
    IMAGE_HEIGHT = 128
    IMAGE_WIDTH = 128
    DEPTH = 64            # فقط إذا ستستخدم 3D
    NUM_CLASSES = 3       # عدد الفئات
    LEARNING_RATE = 1e-3
    BATCH_SIZE = 4
    EPOCHS = 50
    OUTPUT_DIR = "./output"

# إنشاء مجلد الإخراج إذا لم يكن موجوداً
os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

from tensorflow.keras import layers, models

def build_unet_3d(input_shape=(Config.DEPTH, Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1),
                  num_classes=Config.NUM_CLASSES):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling3D((2,2,2))(c1)

    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling3D((2,2,2))(c2)

    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling3D((2,2,2))(c3)

    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling3D((2,2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(u5)
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c5)

    u6 = layers.UpSampling3D((2,2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(u6)
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c6)

    u7 = layers.UpSampling3D((2,2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(u7)
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c7)

    outputs = layers.Conv3D(num_classes, (1,1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

model_3d = build_unet_3d()
model_3d.compile(optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
                 loss="categorical_crossentropy",
                 metrics=["accuracy"])
model_3d.summary()

def create_advanced_3d_visualization(volume, mask, pred_mask, title_prefix=""):
    """
    3D visualization متقدم مع multiple views وتفاعل كامل
    """
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('True Segmentation - 3D View', 'Predicted Segmentation - 3D View',
                       'Volume Rendering - Liver', 'Volume Rendering - Tumor'),
        specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}],
               [{'type': 'scatter3d'}, {'type': 'scatter3d'}]],
        vertical_spacing=0.1,
        horizontal_spacing=0.1
    )

    # Function to create mesh from mask
    def create_mesh_trace(mask_data, class_id, color, name, opacity=0.6):
        mask_class = (mask_data == class_id).astype(float)
        if np.sum(mask_class) > 50:
            try:
                verts, faces, normals, _ = measure.marching_cubes(mask_class, level=0.5, step_size=2)
                x, y, z = verts.T
                i, j, k = faces.T

                return go.Mesh3d(
                    x=x, y=y, z=z,
                    i=i, j=j, k=k,
                    color=color,
                    opacity=opacity,
                    name=name,
                    flatshading=False,
                    lighting=dict(ambient=0.5, diffuse=0.8, specular=0.2, roughness=0.5),
                    lightposition=dict(x=100, y=200, z=300)
                )
            except:
                return None
        return None

    # Row 1, Col 1: True Segmentation
    liver_true = create_mesh_trace(mask, 1, 'red', 'Liver (True)', 0.5)
    tumor_true = create_mesh_trace(mask, 2, 'lime', 'Tumor (True)', 0.8)

    if liver_true:
        fig.add_trace(liver_true, row=1, col=1)
    if tumor_true:
        fig.add_trace(tumor_true, row=1, col=1)

    # Row 1, Col 2: Predicted Segmentation
    liver_pred = create_mesh_trace(pred_mask, 1, 'orangered', 'Liver (Pred)', 0.5)
    tumor_pred = create_mesh_trace(pred_mask, 2, 'green', 'Tumor (Pred)', 0.8)

    if liver_pred:
        fig.add_trace(liver_pred, row=1, col=2)
    if tumor_pred:
        fig.add_trace(tumor_pred, row=1, col=2)

    # Row 2, Col 1: Liver Only (High Quality)
    liver_hq = create_mesh_trace(pred_mask, 1, 'crimson', 'Liver (HQ)', 0.7)
    if liver_hq:
        fig.add_trace(liver_hq, row=2, col=1)

    # Row 2, Col 2: Tumor Only (High Quality)
    tumor_hq = create_mesh_trace(pred_mask, 2, 'springgreen', 'Tumor (HQ)', 0.9)
    if tumor_hq:
        fig.add_trace(tumor_hq, row=2, col=2)

    # Update layout for all subplots
    scene_dict = dict(
        xaxis=dict(showgrid=True, gridcolor='lightgray', title='X'),
        yaxis=dict(showgrid=True, gridcolor='lightgray', title='Y'),
        zaxis=dict(showgrid=True, gridcolor='lightgray', title='Z'),
        bgcolor='rgb(240, 240, 240)',
        camera=dict(
            eye=dict(x=1.5, y=1.5, z=1.5),
            center=dict(x=0, y=0, z=0)
        ),
        aspectmode='data'
    )

    fig.update_layout(
        scene=scene_dict,
        scene2=scene_dict,
        scene3=scene_dict,
        scene4=scene_dict,
        title=f"{title_prefix} - Advanced 3D Segmentation Visualization",
        showlegend=True,
        width=1400,
        height=1200,
        font=dict(size=12)
    )

    # Save interactive HTML
    output_path = os.path.join(Config3D.OUTPUT_DIR, f'{title_prefix}_advanced_3d.html')
    fig.write_html(output_path)
    fig.show()

    print(f"✅ Advanced 3D visualization saved: {output_path}")
    return fig

# Cell 9 - VOLUMETRIC RENDERING with Slices
def create_volumetric_view_with_slices(volume, mask, pred_mask, sample_id=0):
    """
    عرض volumetric مع slices في الاتجاهات الثلاثة
    """
    depth, height, width = volume.shape

    # اختيار slices من النص
    mid_d, mid_h, mid_w = depth//2, height//2, width//2

    fig = make_subplots(
        rows=2, cols=3,
        subplot_titles=('Axial View', 'Coronal View', 'Sagittal View',
                       'Axial Mask', 'Coronal Mask', 'Sagittal Mask'),
        specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}, {'type': 'heatmap'}],
               [{'type': 'heatmap'}, {'type': 'heatmap'}, {'type': 'heatmap'}]]
    )

    # Color mapping for masks
    def mask_to_rgb(mask_slice):
        rgb = np.zeros((*mask_slice.shape, 3))
        rgb[mask_slice == 1] = [1, 0, 0]  # Red for liver
        rgb[mask_slice == 2] = [0, 1, 0]  # Green for tumor
        return rgb

    # Row 1: Original volume slices
    fig.add_trace(go.Heatmap(z=volume[mid_d], colorscale='Gray', showscale=False), row=1, col=1)
    fig.add_trace(go.Heatmap(z=volume[:, mid_h, :], colorscale='Gray', showscale=False), row=1, col=2)
    fig.add_trace(go.Heatmap(z=volume[:, :, mid_w], colorscale='Gray', showscale=False), row=1, col=3)

    # Row 2: Predicted mask slices (as colored overlays)
    fig.add_trace(go.Heatmap(z=pred_mask[mid_d], colorscale=[[0, 'black'], [0.5, 'red'], [1, 'green']],
                            showscale=False), row=2, col=1)
    fig.add_trace(go.Heatmap(z=pred_mask[:, mid_h, :], colorscale=[[0, 'black'], [0.5, 'red'], [1, 'green']],
                            showscale=False), row=2, col=2)
    fig.add_trace(go.Heatmap(z=pred_mask[:, :, mid_w], colorscale=[[0, 'black'], [0.5, 'red'], [1, 'green']],
                            showscale=False), row=2, col=3)

    fig.update_layout(
        title=f"Sample {sample_id} - Multi-Planar Reconstruction (MPR)",
        width=1400,
        height=800,
        showlegend=False
    )

    output_path = os.path.join(Config3D.OUTPUT_DIR, f'sample_{sample_id}_mpr.html')
    fig.write_html(output_path)
    fig.show()

    print(f"✅ MPR visualization saved: {output_path}")

print("\n" + "="*60)
print("🎨 Generating Advanced 3D Visualizations...")
print("="*60)

val_idx = int(len(X_3d) * 0.8)
num_samples_viz = min(3, len(X_3d) - val_idx)

for i in range(num_samples_viz):
    sample_idx = val_idx + i
    sample_volume = X_3d[sample_idx:sample_idx+1]
    sample_mask = Y_3d[sample_idx:sample_idx+1]

    print(f"\n📊 Processing Sample {i+1}/{num_samples_viz}...")

    # Predict
    prediction_3d = model_3d.predict(sample_volume, verbose=0)

    # Convert to class labels
    pred_mask_3d = np.argmax(prediction_3d[0], axis=-1)
    true_mask_3d = np.argmax(sample_mask[0], axis=-1)
    volume_3d = sample_volume[0,:,:,:,0]

    # Advanced 3D visualization
    create_advanced_3d_visualization(volume_3d, true_mask_3d, pred_mask_3d, f"Sample_{i+1}")

    # Multi-planar reconstruction
    create_volumetric_view_with_slices(volume_3d, true_mask_3d, pred_mask_3d, i+1)

def calculate_3d_metrics(y_true, y_pred, num_classes=3):
    """
    حساب metrics متقدمة للـ 3D
    """
    metrics = {}
    class_names = ['Background', 'Liver', 'Tumor']

    for class_id in range(num_classes):
        y_true_class = (y_true == class_id).astype(np.float32)
        y_pred_class = (y_pred == class_id).astype(np.float32)

        # Dice Coefficient
        intersection = np.sum(y_true_class * y_pred_class)
        union = np.sum(y_true_class) + np.sum(y_pred_class)
        dice = (2. * intersection + 1e-7) / (union + 1e-7) if union > 0 else 0.0

        # IoU (Jaccard)
        iou = intersection / (union - intersection + 1e-7) if union > intersection else 0.0

        # Volume (in voxels)
        true_volume = np.sum(y_true_class)
        pred_volume = np.sum(y_pred_class)

        metrics[class_names[class_id]] = {
            'Dice': dice,
            'IoU': iou,
            'True Volume': int(true_volume),
            'Pred Volume': int(pred_volume),
            'Volume Error %': abs(pred_volume - true_volume) / (true_volume + 1e-7) * 100
        }

    return metrics

print("\n" + "="*60)
print("📈 3D Segmentation Metrics")
print("="*60)

all_metrics = []
for i in range(val_idx, len(X_3d)):
    sample_volume = X_3d[i:i+1]
    sample_mask = Y_3d[i:i+1]

    prediction = model_3d.predict(sample_volume, verbose=0)
    pred_mask = np.argmax(prediction[0], axis=-1)
    true_mask = np.argmax(sample_mask[0], axis=-1)

    metrics = calculate_3d_metrics(true_mask, pred_mask)
    all_metrics.append(metrics)

# Average metrics
print("\n🎯 Average Metrics Across Validation Set:")
print("-" * 60)
for class_name in ['Background', 'Liver', 'Tumor']:
    avg_dice = np.mean([m[class_name]['Dice'] for m in all_metrics])
    avg_iou = np.mean([m[class_name]['IoU'] for m in all_metrics])
    print(f"\n{class_name}:")
    print(f"  • Dice Coefficient: {avg_dice:.4f}")
    print(f"  • IoU (Jaccard):    {avg_iou:.4f}")

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# =========================
# ⿡ CONFIGURATION
# =========================
class Config3D:
    OUTPUT_DIR = "./output_3d"
    IMAGE_HEIGHT = 128
    IMAGE_WIDTH = 128
    DEPTH = 64            # عدد الشرائح ثلاثية الأبعاد
    NUM_CLASSES = 3
    LEARNING_RATE = 1e-3
    BATCH_SIZE = 2
    EPOCHS = 50

os.makedirs(Config3D.OUTPUT_DIR, exist_ok=True)

# =========================
# ⿢ BUILD 3D UNET
# =========================
def build_unet_3d(input_shape=(Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH, 1),
                  num_classes=Config3D.NUM_CLASSES):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling3D((2,2,2))(c1)

    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling3D((2,2,2))(c2)

    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling3D((2,2,2))(c3)

    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling3D((2,2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(u5)
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c5)

    u6 = layers.UpSampling3D((2,2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(u6)
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c6)

    u7 = layers.UpSampling3D((2,2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(u7)
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c7)

    outputs = layers.Conv3D(num_classes, (1,1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

# =========================
# ⿣ COMPILE MODEL
# =========================
model_3d = build_unet_3d()
model_3d.compile(
    optimizer=tf.keras.optimizers.Adam(Config3D.LEARNING_RATE),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
model_3d.summary()

# =========================
# ⿤ CALLBACKS
# =========================
checkpoint = ModelCheckpoint(
    os.path.join(Config3D.OUTPUT_DIR, 'best_model_3d.h5'),
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

# =========================
# ⿥ TRAINING (مثال ببيانات عشوائية)
# =========================
X = np.random.rand(10, Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH, 1)
Y = np.random.randint(0, Config3D.NUM_CLASSES,
                      size=(10, Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH))
Y = tf.keras.utils.to_categorical(Y, num_classes=Config3D.NUM_CLASSES)

history_3d = model_3d.fit(
    X, Y,
    validation_split=0.2,
    batch_size=Config3D.BATCH_SIZE,
    epochs=Config3D.EPOCHS,
    callbacks=[checkpoint, early_stop, reduce_lr],
    verbose=1
)

# =========================
# ⿦ PLOT TRAINING HISTORY
# =========================
def plot_training_history(history):
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    axes[0].plot(history.history['loss'], 'b-', linewidth=2, label='Train Loss')
    axes[0].plot(history.history['val_loss'], 'r-', linewidth=2, label='Val Loss')
    axes[0].set_title('3D Model Loss', fontsize=16, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)

    axes[1].plot(history.history['accuracy'], 'b-', linewidth=2, label='Train Acc')
    axes[1].plot(history.history['val_accuracy'], 'r-', linewidth=2, label='Val Acc')
    axes[1].set_title('3D Model Accuracy', fontsize=16, fontweight='bold')
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy', fontsize=12)
    axes[1].legend(fontsize=11)
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(Config3D.OUTPUT_DIR, 'training_history_3d.png'), dpi=200, bbox_inches='tight')
    plt.show()

plot_training_history(history_3d)

# =========================
# ⿧ SUMMARY OUTPUT
# =========================
print("\n" + "="*70)
print("🎉 ADVANCED 3D SEGMENTATION COMPLETE!")
print("="*70)
print(f"\n📂 All results saved to: {Config3D.OUTPUT_DIR}")
print("\n📋 Generated Files:")
print("  ✓ best_model_3d.h5 - Trained 3D model")
print("  ✓ training_history_3d.png - Training curves")
print("\n💡 Open the output folder لمشاهدة النتائج")
print("="*70)