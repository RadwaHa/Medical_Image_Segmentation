# -*- coding: utf-8 -*-
"""liver seg

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17h8OUmYY0tiDM1_r1f_mqfrPghc1dPqr
"""

# Cell 1 - Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ùˆ mount Google Drive
# Ø´ØºÙ‘Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹

# ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø§Øª Ø¥Ù† Ø§Ø­ØªØ§Ø¬Øª
!pip install nibabel --quiet
!pip install scikit-image --quiet
!pip install plotly --quiet
!pip install matplotlib --quiet

# Mount Google Drive Ù„Ùˆ Ø¨Ø¯Ùƒ ØªØ­ÙØ¸/ØªÙ‚Ø±Ø§ Ù…Ù† Drive
from google.colab import drive
drive.mount('/content/drive')

import os
print("Working dir:", os.getcwd())
import tensorflow as tf

# Cell 2 - ØªØ­Ù…ÙŠÙ„ ÙˆÙÙƒ Ø§Ù„Ù€ tar
!wget -q "https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar" -O /content/Task03_Liver.tar

# ÙÙƒ Ø§Ù„Ø¶ØºØ·
!mkdir -p /content/Task03_Liver
!tar -xf /content/Task03_Liver.tar -C /content/Task03_Liver
!ls -lh /content/Task03_Liver
# ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§ÙŠØ«ÙˆÙ†
import os
print("=== Contents of Task03_Liver ===")
import tensorflow as tf
nii_files = []
for root, dirs, files in os.walk("/content/Task03_Liver"):
    for file in files:
        if file.endswith(".nii.gz"):
            full_path = os.path.join(root, file)
            nii_files.append(full_path)
            if len(nii_files) <= 5:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ù…Ù„ÙØ§Øª ÙÙ‚Ø·
                print(f"ğŸ“„ {full_path}")

print(f"\nâœ… Total .nii.gz files found: {len(nii_files)}")

# Ø¥Ø°Ø§ Ù…Ø§ ÙÙŠ Ù…Ù„ÙØ§ØªØŒ Ø´ÙˆÙ Ø´Ùˆ Ù…ÙˆØ¬ÙˆØ¯
if len(nii_files) == 0:
    print("\nğŸ” Searching for any files...")
    all_files = []
    for root, dirs, files in os.walk("/content/Task03_Liver"):
        for file in files:
            all_files.append(os.path.join(root, file))
            if len(all_files) <= 10:
                print(f"ğŸ“ {os.path.join(root, file)}")

    print(f"\nTotal files found: {len(all_files)}")

# Cell 3 - Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù‡Ø§ÙŠØ¨Ø±Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±Ø²
class Config:
    ROOT = "/content/Task03_Liver"

    # Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø© - Ø­Ø³Ø¨ Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙŠ Ø·Ù„Ø¹Øª
    IMAGES_TR = os.path.join(ROOT, "Task03_Liver", "imagesTr")  # Ù„Ø£Ù† Ø§Ù„Ù…Ù„ÙØ§Øª ØªØ­Øª Task03_Liver/
    LABELS_TR = os.path.join(ROOT, "Task03_Liver", "labelsTr")  # Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ Ù„Ù„abels

    IMAGE_HEIGHT = 240
    IMAGE_WIDTH = 240
    NUM_CLASSES = 4
    BATCH_SIZE = 8
    EPOCHS = 100
    LEARNING_RATE = 1e-4
    OUTPUT_DIR = "/content/drive/MyDrive/Seg3Data_liver_results"

import os
os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

# ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
print("ğŸ” Checking adjusted paths...")
print(f"IMAGES_TR: {Config.IMAGES_TR}")
print(f"IMAGES_TR exists: {os.path.exists(Config.IMAGES_TR)}")
print(f"LABELS_TR: {Config.LABELS_TR}")
print(f"LABELS_TR exists: {os.path.exists(Config.LABELS_TR)}")

# Ø¥Ø°Ø§ Ù„Ø³Ø§ labelsTr Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø´ÙˆÙ ÙˆÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª
if not os.path.exists(Config.LABELS_TR):
    print("\nğŸ” Searching for label files...")
    for root, dirs, files in os.walk("/content/Task03_Liver"):
        if "label" in root.lower():
            print(f"Found label-related directory: {root}")
            nii_files = [f for f in files if f.endswith('.nii.gz')]
            if nii_files:
                print(f"  Contains {len(nii_files)}Â .nii.gzÂ files")

# ==============================
# Cell 4 - Data Loader & Preprocessing (FIXED)
# ==============================
import numpy as np
import nibabel as nib
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
import glob
import cv2

def load_nifti(path):
    """Load NIfTI file and return data"""
    try:
        img = nib.load(path)
        data = img.get_fdata()
        return data
    except Exception as e:
        print(f"âŒ Error loading {path}: {e}")
        return None

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
image_paths = sorted(glob.glob(os.path.join(Config.IMAGES_TR, "*.nii.gz")))
label_paths = sorted(glob.glob(os.path.join(Config.LABELS_TR, "*.nii.gz")))

print(f"ğŸ“ Found {len(image_paths)} images and {len(label_paths)} masks")

if not image_paths or not label_paths:
    print("âŒ No files found! Check paths above.")
else:
    print(f"âœ… First image: {os.path.basename(image_paths[0])}")
    print(f"âœ… First mask: {os.path.basename(label_paths[0])}")

def preprocess(img, mask, target_size=(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH)):
    """Preprocess single slice"""
    if img is None or mask is None:
        return None, None

    # Ù†Ø£Ø®Ø° Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø§Ù„ÙˆØ³Ø·Ù‰
    if len(img.shape) == 3:  # Ø¥Ø°Ø§ 3D
        mid = img.shape[2] // 2
        img_slice = img[:, :, mid]
        mask_slice = mask[:, :, mid]
    else:  # Ø¥Ø°Ø§ 2D
        img_slice = img
        mask_slice = mask

    # Normalize Ø§Ù„ØµÙˆØ±Ø©
    img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

    # Resize
    img_slice = cv2.resize(img_slice, target_size, interpolation=cv2.INTER_LINEAR)
    mask_slice = cv2.resize(mask_slice, target_size, interpolation=cv2.INTER_NEAREST)

    # Expand dimensions
    img_slice = np.expand_dims(img_slice, axis=-1)  # (H, W, 1)

    # Convert mask to categorical
    mask_slice = mask_slice.astype(np.uint8)
    # ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¶Ù…Ù† Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„ØµØ­ÙŠØ­
    mask_slice = np.clip(mask_slice, 0, Config.NUM_CLASSES-1)
    mask_slice = to_categorical(mask_slice, num_classes=Config.NUM_CLASSES)

    return img_slice, mask_slice

# Ø¥Ù†Ø´Ø§Ø¡ X Ùˆ Y
X, Y = [], []
success_count = 0

# Ø®Ø° Ø¹Ø¯Ø¯ Ø£Ù‚Ù„ Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ¬Ø±Ø¨Ø© (10-20)
for i, (img_path, mask_path) in enumerate(zip(image_paths[:20], label_paths[:20])):
    print(f"ğŸ”„ Processing {i+1}/20: {os.path.basename(img_path)}")

    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        img_data = load_nifti(img_path)
        mask_data = load_nifti(mask_path)

        if img_data is not None and mask_data is not None:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            img_processed, mask_processed = preprocess(img_data, mask_data)

            if img_processed is not None and mask_processed is not None:
                X.append(img_processed)
                Y.append(mask_processed)
                success_count += 1
                print(f"   âœ… Success - img: {img_processed.shape}, mask: {mask_processed.shape}")
            else:
                print(f"   âŒ Preprocessing failed")
        else:
            print(f"   âŒ Loading failed")

    except Exception as e:
        print(f"   âŒ Error: {e}")

# ØªØ­ÙˆÙŠÙ„ Ù„ numpy arrays
if X and Y:
    X = np.array(X)
    Y = np.array(Y)
    print(f"\nğŸ‰ SUCCESS: Created X: {X.shape}, Y: {Y.shape}")
    print(f"ğŸ“Š X range: [{X.min():.3f}, {X.max():.3f}]")
    print(f"ğŸ“Š Y unique values: {np.unique(np.argmax(Y, axis=-1))}")
else:
    print("\nâŒ FAILED: No data processed!")
    # Ø§Ø³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    print("ğŸ”„ Creating sample data for testing...")
    X = np.random.rand(20, Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1).astype(np.float32)
    Y_categorical = np.random.randint(0, Config.NUM_CLASSES, (20, Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH))
    Y = to_categorical(Y_categorical, num_classes=Config.NUM_CLASSES)
    print(f"ğŸ“Š Sample data - X: {X.shape},Â Y:Â {Y.shape}")

# ==============================
# Cell 5 - U-Net Model
# ==============================
from tensorflow.keras import layers, models

def build_unet(input_shape=(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1), num_classes=Config.NUM_CLASSES):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2,2))(c1)

    c2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2,2))(c2)

    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2,2))(c3)

    c4 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling2D((2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u5)
    c5 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c5)

    u6 = layers.UpSampling2D((2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(c6)

    u7 = layers.UpSampling2D((2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(c7)

    outputs = layers.Conv2D(num_classes, (1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

model = build_unet()
model.compile(optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
              loss="categorical_crossentropy",
              metrics=["accuracy"])
model.summary()

# Ø¶ÙŠÙ Ù‡Ø§Ø¯ Ø§Ù„ÙƒÙˆØ¯ ÙÙŠ Ø®Ù„ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø®Ù„ÙŠØ© 6

print("ğŸ” === DEBUGGING DATA FLOW ===")

# 1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ù„ÙŠØ© 2
print("1. Checking Cell 2 (Data Download)...")
import os
if os.path.exists("/content/Task03_Liver"):
    nii_files = []
    for root, dirs, files in os.walk("/content/Task03_Liver"):
        for file in files:
            if file.endswith(".nii.gz"):
                nii_files.append(os.path.join(root, file))
    print(f"   Found {len(nii_files)} .nii.gz files")
    if nii_files:
        print(f"   First 3 files: {nii_files[:3]}")
else:
    print("   âŒ Task03_Liver directory not found!")

# 2. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ù„ÙŠØ© 4
print("\n2. Checking Cell 4 (Data Processing)...")
print(f"   X exists: {'X' in locals()}")
print(f"   Y exists: {'Y' in locals()}")

if 'X' in locals():
    print(f"   X shape: {X.shape if hasattr(X, 'shape') else 'No shape'}")
    print(f"   X type: {type(X)}")

if 'Y' in locals():
    print(f"   Y shape: {Y.shape if hasattr(Y, 'shape') else 'No shape'}")
    print(f"   Y type: {type(Y)}")

# 3. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
print("\n3. Checking Paths...")
print(f"   IMAGES_TR: {Config.IMAGES_TR}")
print(f"   IMAGES_TR exists: {os.path.exists(Config.IMAGES_TR)}")
print(f"   LABELS_TR: {Config.LABELS_TR}")
print(f"   LABELS_TR exists: {os.path.exists(Config.LABELS_TR)}")

# 4. Ø¥Ø°Ø§ X Ùˆ Y ÙØ§Ø¶ÙŠÙŠÙ†ØŒ Ø¬Ø±Ø¨ Ù†Ø¹Ù…Ù„Ù‡Ù… Ù…Ù† Ø¬Ø¯ÙŠØ¯
if 'X' not in locals() or (hasattr(X, 'shape') and X.shape[0] == 0):
    print("\nğŸ”„ Attempting to recreate X and Y...")

    import glob
    import nibabel as nib
    import numpy as np
    import cv2
    from tensorflow.keras.utils import to_categorical

    # Ø¬Ø±Ø¨ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØ¯ÙˆÙŠØ§Ù‹
    image_paths = sorted(glob.glob(os.path.join(Config.IMAGES_TR, "*.nii.gz")))
    label_paths = sorted(glob.glob(os.path.join(Config.LABELS_TR, "*.nii.gz")))

    print(f"   Found {len(image_paths)} images, {len(label_paths)} masks")

    if image_paths and label_paths:
        X_temp, Y_temp = [], []

        for i, (img_path, mask_path) in enumerate(zip(image_paths[:5], label_paths[:5])):  # Ø£ÙˆÙ„ 5 ÙÙ‚Ø· Ù„Ù„ØªØ¬Ø±Ø¨Ø©
            try:
                print(f"   Processing {i+1}: {os.path.basename(img_path)}")

                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                img = nib.load(img_path).get_fdata()
                mask = nib.load(mask_path).get_fdata()

                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø±ÙŠØ­Ø© ÙˆØ§Ø­Ø¯Ø©
                mid = img.shape[2] // 2
                img_slice = img[:, :, mid]
                mask_slice = mask[:, :, mid]

                # Normalize
                img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

                # Resize
                img_slice = cv2.resize(img_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH))
                mask_slice = cv2.resize(mask_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH), interpolation=cv2.INTER_NEAREST)

                # Expand dims
                img_slice = np.expand_dims(img_slice, axis=-1)
                mask_slice = to_categorical(mask_slice.astype(np.uint8), num_classes=Config.NUM_CLASSES)

                X_temp.append(img_slice)
                Y_temp.append(mask_slice)

            except Exception as e:
                print(f"   âŒ Error processing {img_path}: {e}")

        if X_temp:
            X = np.array(X_temp)
            Y = np.array(Y_temp)
            print(f"   âœ… Created X: {X.shape}, Y: {Y.shape}")
        else:
            print("   âŒ Failed to createÂ XÂ andÂ Y")

# ==============================
# Cell 7 - Training
# ==============================
history = model.fit(
    X, Y,
    validation_split=0.2,
    batch_size=Config.BATCH_SIZE,
    epochs=5   # Ù„Ù„ØªØ¬Ø±Ø¨Ø© (Ø²ÙˆØ¯ÙŠÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹)
)

# Cell 8 - Ø¨Ù†Ø§Ø¡ U-Net 2D (Ù…Ø´ØªÙ‚ Ù…Ù† ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„)
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose
from tensorflow.keras.layers import concatenate, BatchNormalization, Activation
from tensorflow.keras.models import Model

def build_unet_2d(h, w, channels, num_classes):
    inputs = Input((h, w, channels))
    # Encoder
    conv1 = Conv2D(32, (3,3), padding='same', activation='relu')(inputs)
    conv1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv1)
    pool1 = MaxPooling2D()(conv1)

    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(pool1)
    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(conv2)
    pool2 = MaxPooling2D()(conv2)

    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(pool2)
    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(conv3)
    pool3 = MaxPooling2D()(conv3)

    conv4 = Conv2D(256, (3,3), padding='same', activation='relu')(pool3)
    conv4 = Conv2D(256, (3,3), padding='same', activation='relu')(conv4)

    # Decoder
    up3 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv4)
    up3 = concatenate([up3, conv3])
    conv5 = Conv2D(128, (3,3), padding='same', activation='relu')(up3)
    conv5 = Conv2D(128, (3,3), padding='same', activation='relu')(conv5)

    up2 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(conv5)
    up2 = concatenate([up2, conv2])
    conv6 = Conv2D(64, (3,3), padding='same', activation='relu')(up2)
    conv6 = Conv2D(64, (3,3), padding='same', activation='relu')(conv6)

    up1 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(conv6)
    up1 = concatenate([up1, conv1])
    conv7 = Conv2D(32, (3,3), padding='same', activation='relu')(up1)
    conv7 = Conv2D(32, (3,3), padding='same', activation='relu')(conv7)

    out = Conv2D(num_classes, (1,1), activation='softmax')(conv7)
    model = Model(inputs=inputs, outputs=out)
    return model

model = build_unet_2d(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1, Config.NUM_CLASSES)
model.compile(optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
              loss='categorical_crossentropy',
              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=Config.NUM_CLASSES)])
model.summary()

# Cell 8.1 - Slice Generator
# Ù‡Ø°Ø§ Ø§Ù„ÙƒÙ„Ø§Ø³ Ø¨ÙŠØ³Ø§Ø¹Ø¯Ù†Ø§ Ù†Ø­Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ø´Ø±Ø§Ø¦Ø­
import glob
import os
import tensorflow as tf
import numpy as np
import nibabel as nib
import cv2
from tensorflow.keras.utils import to_categorical

class SliceGenerator(tf.keras.utils.Sequence):
    def __init__(self, file_indices, batch_size, num_classes, img_height, img_width, shuffle=True):
        self.file_indices = file_indices
        self.batch_size = batch_size
        self.num_classes = num_classes
        self.img_height = img_height
        self.img_width = img_width
        self.shuffle = shuffle
        self.on_epoch_end() # Shuffle initially

        # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª (ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡Ø§ ØµØ­ÙŠØ­Ø©)
        self.image_paths = sorted(glob.glob(os.path.join(Config.IMAGES_TR, "*.nii.gz")))
        self.label_paths = sorted(glob.glob(os.path.join(Config.LABELS_TR, "*.nii.gz")))


    def __len__(self):
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø¨Ø§ØªØ´Ø§Øª ÙÙŠ ÙƒÙ„ epoch
        return int(np.floor(len(self.file_indices) / self.batch_size))

    def __getitem__(self, index):
        # Ø¬Ù„Ø¨ Ø¨Ø§ØªØ´ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]
        batch_file_indices = [self.file_indices[k] for k in indices]

        X, Y = self.__data_generation(batch_file_indices)
        return X, Y

    def on_epoch_end(self):
        # Ø®Ù„Ø· Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯ ÙƒÙ„ epoch Ø¥Ø°Ø§ shuffle = True
        self.indices = np.arange(len(self.file_indices))
        if self.shuffle == True:
            np.random.shuffle(self.indices)

    def __data_generation(self, batch_file_indices):
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¨Ø§ØªØ´
        X_batch = np.empty((self.batch_size, self.img_height, self.img_width, 1))
        Y_batch = np.empty((self.batch_size, self.img_height, self.img_width, self.num_classes))

        for i, file_idx in enumerate(batch_file_indices):
            try:
                img_path = self.image_paths[file_idx]
                mask_path = self.label_paths[file_idx]

                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                img_data = nib.load(img_path).get_fdata()
                mask_data = nib.load(mask_path).get_fdata()

                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø±ÙŠØ­Ø© ÙˆØ§Ø­Ø¯Ø© (Ø§Ù„ÙˆØ³Ø·Ù‰)
                if len(img_data.shape) == 3:
                    mid = img_data.shape[2] // 2
                    img_slice = img_data[:, :, mid]
                    mask_slice = mask_data[:, :, mid]
                else:
                    img_slice = img_data
                    mask_slice = mask_data

                # Normalize Ø§Ù„ØµÙˆØ±Ø©
                img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

                # Resize
                img_slice = cv2.resize(img_slice, (self.img_width, self.img_height), interpolation=cv2.INTER_LINEAR)
                mask_slice = cv2.resize(mask_slice, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)

                # Expand dimensions
                X_batch[i,] = np.expand_dims(img_slice, axis=-1)

                # Convert mask to categorical
                mask_slice = mask_slice.astype(np.uint8)
                 # ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¶Ù…Ù† Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„ØµØ­ÙŠØ­
                mask_slice = np.clip(mask_slice, 0, self.num_classes-1)
                Y_batch[i,] = to_categorical(mask_slice, num_classes=self.num_classes)

            except Exception as e:
                print(f"âŒ Error loading/processing file index {file_idx}: {e}")
                # Handle error: could load dummy data or skip
                # For simplicity, we'll fill with zeros for now
                X_batch[i,] = np.zeros((self.img_height, self.img_width, 1))
                Y_batch[i,] = np.zeros((self.img_height, self.img_width, self.num_classes))


        return X_batch, Y_batch

# Cell 8.5 - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©

# Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙŠ Ø¹Ø±ÙÙ†Ø§ Ø¥Ù†Ù‡Ø§ Ø´ØºØ§Ù„Ø©
successful_files_indices = []
successful_filenames = ['liver_100.nii.gz', 'liver_101.nii.gz', 'liver_102.nii.gz',
                       'liver_105.nii.gz', 'liver_110.nii.gz']

for i, img_path in enumerate(image_paths):
    if any(filename in img_path for filename in successful_filenames):
        successful_files_indices.append(i)

print(f"ğŸ¯ Using {len(successful_files_indices)} known successful files")

if len(successful_files_indices) >= 4:
    train_idx, val_idx = train_test_split(
        successful_files_indices,
        test_size=0.2,
        random_state=42,
        shuffle=True
    )
    print(f"ğŸ“Š Train: {len(train_idx)} files, Val: {len(val_idx)} files")
else:
    print("âŒ Not enough successful files, using sample data...")
    # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    train_idx, val_idx = [0, 1, 2], [3, 4]

print("ğŸ” Testing generator...")
test_batch_X, test_batch_Y = train_gen[0]
print(f"âœ… Generator test - X: {test_batch_X.shape}, Y: {test_batch_Y.shape}")
print(f"ğŸ“Š X range: [{test_batch_X.min():.3f}, {test_batch_X.max():.3f}]")
print(f"ğŸ“Š Y unique classes: {np.unique(np.argmax(test_batch_Y, axis=-1))}")

# Ø¥Ø°Ø§ ÙƒÙ„Ø´ÙŠ ØªÙ…Ø§Ù…ØŒ Ø§ÙƒÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
print("ğŸš€ Starting training withÂ generator...")

# Cell 9 - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø© (Ø¨Ø¯ÙˆÙ† Generator) - Ø§Ù„Ù…Ø¹Ø¯Ù„

print("ğŸš€ Using direct data without generator...")

# Ø£ÙˆÙ„Ø§Ù‹: Ø£Ù†Ø´Ø¦ X Ùˆ Y Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
X, Y = [], []

for filename in ['liver_100.nii.gz', 'liver_101.nii.gz', 'liver_102.nii.gz', 'liver_105.nii.gz', 'liver_110.nii.gz']:
    img_path = os.path.join(Config.IMAGES_TR, filename)
    mask_path = os.path.join(Config.LABELS_TR, filename)

    print(f"ğŸ“ Loading {filename}...")

    try:
        img_data = nib.load(img_path).get_fdata()
        mask_data = nib.load(mask_path).get_fdata()

        # Ø®Ø° Ø´Ø±ÙŠØ­Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ù†ØªØµÙ
        mid = img_data.shape[2] // 2
        img_slice = img_data[:, :, mid]
        mask_slice = mask_data[:, :, mid]

        # Normalize
        img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

        # Resize
        img_slice = cv2.resize(img_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH))
        mask_slice = cv2.resize(mask_slice, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH), interpolation=cv2.INTER_NEAREST)

        # Expand dimensions
        img_slice = np.expand_dims(img_slice, axis=-1)
        mask_slice = to_categorical(mask_slice.astype(np.uint8), num_classes=Config.NUM_CLASSES)

        X.append(img_slice)
        Y.append(mask_slice)
        print(f"   âœ… Success")

    except Exception as e:
        print(f"   âŒ Error: {e}")

X = np.array(X)
Y = np.array(Y)

print(f"ğŸ¯ Final dataset - X: {X.shape}, Y: {Y.shape}")

# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)
]

history = model.fit(
    X, Y,
    validation_split=0.2,
    batch_size=min(Config.BATCH_SIZE, len(X)),  # ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ batch size Ù„Ø§ ÙŠØ²ÙŠØ¯ Ø¹Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª
    epochs=Config.EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ - Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø©
try:
    # Ø§Ù„Ø­Ù„ 1: Ø¬Ø±Ø¨ .keras format
    model.save('/content/final_unet_liver.keras')
    print("âœ… Model saved as .keras format!")

    # Ø¥Ø°Ø§ Ø¨Ø¯Ùƒ ØªØ­Ù…Ù„Ù‡ Ù„ Drive
    from google.colab import files
    files.download('/content/final_unet_liver.keras')
    print("âœ… Model downloaded to your computer!")

except Exception as e:
    print(f"âŒ Error saving .keras: {e}")

    try:
        # Ø§Ù„Ø­Ù„ 2: Ø¬Ø±Ø¨ Ø­ÙØ¸ ÙÙŠ Drive Ù…Ø¨Ø§Ø´Ø±Ø©
        model.save('/content/drive/MyDrive/final_unet_liver.keras')
        print("âœ… Model saved directly to Google Drive!")
    except Exception as e2:
        print(f"âŒ Error saving to Drive: {e2}")

        # Ø§Ù„Ø­Ù„ 3: Ù†Ø¸Ù Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ¬Ø±Ø¨ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©
        import gc
        gc.collect()
        model.save('/content/final_unet_liver.h5')
        print("âœ… Model saved after memory cleanup!")

print("ğŸ‰ Training completedÂ successfully!")

# Cell 10 - Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ ÙˆØ¹Ø±Ø¶
import matplotlib.pyplot as plt
import numpy as np
from skimage.transform import resize

def predict_slice_mask(model, img3d, slice_idx):
    """ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„mask Ù„Ø´Ø±ÙŠØ­Ø© Ù…Ø¹ÙŠÙ†Ø©"""
    img = img3d[:,:,slice_idx]
    img_r = resize(img, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH), preserve_range=True, order=1)
    X = np.expand_dims(img_r, axis=(0, -1))

    # Normalize
    X = (X - np.min(X)) / (np.max(X) - np.min(X) + 1e-8)

    pred = model.predict(X, verbose=0)
    pred_mask = np.argmax(pred[0], axis=-1)
    return pred_mask

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
successful_files = ['liver_100.nii.gz', 'liver_101.nii.gz', 'liver_102.nii.gz']

for filename in successful_files[:1]:  # Ø¬Ø±Ø¨ Ø£ÙˆÙ„ Ù…Ù„Ù ÙÙ‚Ø·
    try:
        img_path = os.path.join(Config.IMAGES_TR, filename)
        mask_path = os.path.join(Config.LABELS_TR, filename)

        print(f"ğŸ” Testing on {filename}...")

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        img3d = nib.load(img_path).get_fdata()
        lbl3d = nib.load(mask_path).get_fdata()

        # Ø§Ø®ØªØ± 3 Ø´Ø±Ø§Ø¦Ø­ Ù…Ù† Ù…Ù†Ø§Ø·Ù‚ Ù…Ø®ØªÙ„ÙØ©
        num_slices = img3d.shape[2]
        slices_to_show = [
            num_slices // 4,      # Ø£ÙˆÙ„ Ø§Ù„Ø±Ø¨Ø¹
            num_slices // 2,      # Ø§Ù„Ù…Ù†ØªØµÙ
            3 * num_slices // 4   # Ø¢Ø®Ø± Ø§Ù„Ø±Ø¨Ø¹
        ]

        # Ø¥Ù†Ø´Ø§Ø¡ plots
        fig, axes = plt.subplots(len(slices_to_show), 4, figsize=(16, 4*len(slices_to_show)))

        for i, slice_idx in enumerate(slices_to_show):
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            pred_mask = predict_slice_mask(model, img3d, slice_idx)
            gt_mask = lbl3d[:,:,slice_idx]

            # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (normalized)
            img_slice = img3d[:,:,slice_idx]
            img_norm = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-8)

            # 1. Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            axes[i, 0].imshow(img_norm, cmap='gray')
            axes[i, 0].set_title(f"Slice {slice_idx}\nOriginal Image")
            axes[i, 0].axis('off')

            # 2. Ø§Ù„Ù€ Ground Truth
            axes[i, 1].imshow(gt_mask, cmap='jet', vmin=0, vmax=Config.NUM_CLASSES-1)
            axes[i, 1].set_title("Ground Truth")
            axes[i, 1].axis('off')

            # 3. Ø§Ù„ØªÙ†Ø¨Ø¤
            axes[i, 2].imshow(pred_mask, cmap='jet', vmin=0, vmax=Config.NUM_CLASSES-1)
            axes[i, 2].set_title("Prediction")
            axes[i, 2].axis('off')

            # 4. Overlay
            axes[i, 3].imshow(img_norm, cmap='gray')
            axes[i, 3].imshow(pred_mask, cmap='jet', alpha=0.5, vmin=0, vmax=Config.NUM_CLASSES-1)
            axes[i, 3].set_title("Overlay")
            axes[i, 3].axis('off')

        plt.suptitle(f"Results for {filename}", fontsize=16, y=0.98)
        plt.tight_layout()
        plt.show()

        # Ø­Ø³Ø§Ø¨ metrics Ø¨Ø³ÙŠØ·Ø©
        print(f"ğŸ“Š Quick evaluation for {filename}:")
        for slice_idx in slices_to_show:
            pred_mask = predict_slice_mask(model, img3d, slice_idx)
            gt_mask = lbl3d[:,:,slice_idx]

            # Resize Ø§Ù„Ù€ GT Ù„ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù€ prediction
            gt_resized = resize(gt_mask, (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH),
                              preserve_range=True, order=0, anti_aliasing=False)

            accuracy = np.mean(pred_mask == gt_resized)
            print(f"  Slice {slice_idx}: Accuracy = {accuracy:.3f}")

    except Exception as e:
        print(f"âŒ Error processing {filename}: {e}")
        continue

print("âœ… TestingÂ completed!")

# Cell 11 - ØªØ­Ù‚Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø±Ø³Ù…
print("ğŸ” Checking prediction volume...")

# Ø§Ø³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
if 'img3d' not in locals():
    # Ø­Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ø°Ø§ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯Ø©
    filename = 'liver_100.nii.gz'
    img_path = os.path.join(Config.IMAGES_TR, filename)
    img3d = nib.load(img_path).get_fdata()
    print(f"âœ… Loaded {filename} - shape: {img3d.shape}")

# Ø£Ù†Ø´Ø¦ volume ØªÙ†Ø¨Ø¤Ø§Øª
start, end = 0, min(img3d.shape[2], 32)  # Ø¹Ø¯Ø¯ Ø£Ù‚Ù„ Ù„ØªØ³Ø±ÙŠØ¹
pred_vol = np.zeros((Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, end-start), dtype=np.uint8)

print(f"ğŸ”„ Generating predictions for slices {start} to {end}...")
for i, s in enumerate(range(start, end)):
    pred_vol[:,:,i] = predict_slice_mask(model, img3d, s)

# ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª
unique_vals = np.unique(pred_vol)
print(f"ğŸ“Š Unique values in pred_vol: {unique_vals}")
print(f"ğŸ“Š Class distribution: {np.bincount(pred_vol.flatten())}")

if 1 not in unique_vals:
    print("âŒ No liver (class 1) detected in predictions!")
    print("ğŸ’¡ Trying class 2 (tumor) instead...")
    target_class = 2
else:
    target_class = 1

# Cell 11 - ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø§Ù„Ù…Ø¹Ø¯Ù„)
print("ğŸ” Analyzing current model performance...")

# 1. ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£ØµÙ†Ø§Ù ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
print("\nğŸ“Š Class distribution in GROUND TRUTH:")
for i in range(len(Y)):
    unique, counts = np.unique(np.argmax(Y[i], axis=-1), return_counts=True)
    print(f"Sample {i}: {dict(zip(unique, counts))}")

# 2. ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
predictions = model.predict(X, verbose=0)
pred_classes = np.argmax(predictions, axis=-1)

print("\nğŸ“Š Class distribution in PREDICTIONS:")
for i in range(len(predictions)):
    unique, counts = np.unique(pred_classes[i], return_counts=True)
    print(f"Sample {i}: {dict(zip(unique, counts))}")

# 3. Ø­Ø³Ø§Ø¨ metrics Ù…ÙØµÙ„Ø© Ù„ÙƒÙ„ ØµÙ†Ù
from sklearn.metrics import classification_report

y_true_flat = np.argmax(Y, axis=-1).flatten()
y_pred_flat = pred_classes.flatten()

# Ø§ÙƒØªØ´Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£ØµÙ†Ø§Ù Ø§Ù„ÙØ¹Ù„ÙŠ
actual_classes = np.unique(y_true_flat)
print(f"\nğŸ¯ Actual classes found: {actual_classes}")

print("\nğŸ¯ Detailed Classification Report:")
print(classification_report(y_true_flat, y_pred_flat,
                          target_names=['Background', 'Liver', 'Tumor'][:len(actual_classes)],
                          labels=actual_classes))

# 4. Ø¹Ø±Ø¶ visual comparison
fig, axes = plt.subplots(3, 4, figsize=(16, 12))

for i in range(min(3, len(X))):  # Ø£ÙˆÙ„ 3 Ø¹ÙŠÙ†Ø§Øª Ø£Ùˆ Ø£Ù‚Ù„
    # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    axes[i, 0].imshow(X[i, :, :, 0], cmap='gray')
    axes[i, 0].set_title(f'Sample {i+1}\nInput Image')
    axes[i, 0].axis('off')

    # Ground Truth
    true_mask = np.argmax(Y[i], axis=-1)
    axes[i, 1].imshow(true_mask, cmap='jet', vmin=0, vmax=2)  # max = 2 Ù„Ø£Ù† ÙÙŠ 3 classes ÙÙ‚Ø·
    axes[i, 1].set_title('Ground Truth')
    axes[i, 1].axis('off')

    # Prediction
    pred_mask = pred_classes[i]
    axes[i, 2].imshow(pred_mask, cmap='jet', vmin=0, vmax=2)
    axes[i, 2].set_title('Model Prediction')
    axes[i, 2].axis('off')

    # Difference (Ø§Ù„Ø£Ø®Ø·Ø§Ø¡)
    diff = np.abs(true_mask - pred_mask)
    axes[i, 3].imshow(diff, cmap='hot', vmin=0, vmax=2)
    axes[i, 3].set_title('Difference\n(Errors)')
    axes[i, 3].axis('off')

# Ø¥Ø®ÙØ§Ø¡ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø£Ù‚Ù„ Ù…Ù† 3
for i in range(len(X), 3):
    for j in range(4):
        axes[i, j].set_visible(False)

plt.suptitle('Model Performance Analysis - Current Results', fontsize=16, y=0.95)
plt.tight_layout()
plt.show()

# 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
print("\nğŸ” ANALYSIS RESULTS:")
print("â€¢ Ground Truth: Samples 0-2 ÙƒÙ„Ù‡Ø§ Ø®Ù„ÙÙŠØ© ÙÙ‚Ø·")
print("â€¢ Ground Truth: Sample 3 ÙÙŠÙ‡ ÙƒØ¨Ø¯ (class 1)")
print("â€¢ Ground Truth: Sample 4 ÙÙŠÙ‡ ÙƒØ¨Ø¯ (class 1) ÙˆÙˆØ±Ù… (class 2)")
print("â€¢ Predictions: ÙƒÙ„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª = Ø®Ù„ÙÙŠØ© ÙÙ‚Ø· (class 0)")

print("\nğŸ’¡ CONCLUSIONS:")
print("âœ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø´ØºØ§Ù„ - Ù„ÙƒÙ†Ù‡ overfitting Ø¹Ù„Ù‰ class 0 (Ø§Ù„Ø®Ù„ÙÙŠØ©)")
print("âŒ Ù…Ø§ Ø¨Ù‚Ø¯Ø± ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒØ¨Ø¯ Ø£Ùˆ Ø§Ù„Ø£ÙˆØ±Ø§Ù… - Ø¯Ù‚Ø© 0% Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø£ØµÙ†Ø§Ù")
print("ğŸ“ˆ Ø§Ù„Ù€ accuracy Ø§Ù„Ø¹Ø§Ù„ÙŠ (95.2%) misleading - Ù„Ø£Ù†Ù‡ ÙÙ‚Ø· Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø®Ù„ÙÙŠØ©")

print("\nğŸš€ RECOMMENDATIONS:")
print("1. Ø§Ø³ØªØ®Ø¯Ø§Ù… class weights Ù„Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ø£ØµÙ†Ø§Ù")
print("2. ØªØ¬Ø±Ø¨Ø© loss functions Ù…Ø®ØªÙ„ÙØ© (Dice loss, Focal loss)")
print("3. Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø©")
print("4. Ø§Ø³ØªØ®Ø¯Ø§Ù… dataÂ augmentation")

# Cell 11 - ØªØµÙˆØ± 2D Ù…ØªÙ‚Ø¯Ù… Ø¨Ø¯Ù„ 3D
print("ğŸ¨ Advanced 2D Visualization")

# Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø© Ø§Ù„ÙŠ ÙÙŠÙ‡Ø§ ÙƒØ¨Ø¯ ÙˆÙˆØ±Ù… (sample 4)
sample_idx = 4

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„: ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„
img = X[sample_idx, :, :, 0]
true_mask = np.argmax(Y[sample_idx], axis=-1)
pred_mask = pred_classes[sample_idx]

# 1. Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© + Ground Truth overlay
axes[0, 0].imshow(img, cmap='gray')
axes[0, 0].imshow(np.ma.masked_where(true_mask == 0, true_mask),
                  cmap='jet', alpha=0.7, vmin=0, vmax=2)
axes[0, 0].set_title('Input + Ground Truth Overlay')
axes[0, 0].axis('off')

# 2. Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© + Prediction overlay
axes[0, 1].imshow(img, cmap='gray')
axes[0, 1].imshow(np.ma.masked_where(pred_mask == 0, pred_mask),
                  cmap='jet', alpha=0.7, vmin=0, vmax=2)
axes[0, 1].set_title('Input + Prediction Overlay')
axes[0, 1].axis('off')

# 3. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
axes[0, 2].imshow(true_mask, cmap='jet', vmin=0, vmax=2)
axes[0, 2].set_title('Ground Truth Only')
axes[0, 2].axis('off')

# Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
# 4. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø­Ø§Øª
class_names = ['Background', 'Liver', 'Tumor']
class_pixels = [np.sum(true_mask == i) for i in range(3)]

axes[1, 0].bar(class_names, class_pixels, color=['gray', 'red', 'blue'])
axes[1, 0].set_title('Pixel Distribution per Class')
axes[1, 0].set_ylabel('Number of Pixels')

# 5. Ù…Ø®Ø·Ø· Ø§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ„ class
accuracy_per_class = []
for i in range(3):
    if np.sum(true_mask == i) > 0:
        acc = np.mean(pred_mask[true_mask == i] == i)
    else:
        acc = 0
    accuracy_per_class.append(acc)

axes[1, 1].bar(class_names, accuracy_per_class, color=['gray', 'red', 'blue'])
axes[1, 1].set_title('Accuracy per Class')
axes[1, 1].set_ylabel('Accuracy')
axes[1, 1].set_ylim(0, 1)

# 6. Ù†Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„
analysis_text = f"""
Analysis Results:

â€¢ Background: {class_pixels[0]} pixels ({class_pixels[0]/57600*100:.1f}%)
â€¢ Liver: {class_pixels[1]} pixels ({class_pixels[1]/57600*100:.1f}%)
â€¢ Tumor: {class_pixels[2]} pixels ({class_pixels[2]/57600*100:.1f}%)

Model Performance:
â€¢ Background Accuracy: {accuracy_per_class[0]:.3f}
â€¢ Liver Accuracy: {accuracy_per_class[1]:.3f}
â€¢ Tumor Accuracy: {accuracy_per_class[2]:.3f}

Issue: Model only predicts background!
"""

axes[1, 2].text(0.1, 0.9, analysis_text, transform=axes[1, 2].transAxes,
                fontsize=10, verticalalignment='top', family='monospace')
axes[1, 2].set_title('Detailed Analysis')
axes[1, 2].axis('off')

plt.suptitle('Advanced 2D Analysis - Sample 4 (Liver + Tumor)', fontsize=16)
plt.tight_layout()
plt.show()

# Cell 12 - 3D Visualization Ø¨Ø³ÙŠØ·Ø©
print("ğŸ¨ Creating simple 3D visualization...")

# Ø§Ø³ØªØ®Ø¯Ù… sample 4 Ù„Ø£Ù† ÙÙŠÙ‡ ÙƒÙ„ Ø§Ù„Ø£ØµÙ†Ø§Ù (0, 1, 2)
sample_idx = 4  # Ø§Ù„Ø¹ÙŠÙ†Ø© Ø§Ù„ÙŠ ÙÙŠÙ‡Ø§ ÙƒØ¨Ø¯ ÙˆÙˆØ±Ù…

# Ø®Ø° Ø§Ù„Ù€ ground truth Ù…Ù† sample 4
true_mask_3d = np.argmax(Y[sample_idx], axis=-1)

# Ø£Ù†Ø´Ø¦ volume ØµØºÙŠØ± Ù„Ù„Ø¹Ø±Ø¶
volume_3d = np.zeros((Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 10), dtype=np.uint8)

# ÙƒØ±Ø± Ù†ÙØ³ Ø§Ù„Ù€ mask Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø´Ø±Ø§Ø¦Ø­
for i in range(10):
    volume_3d[:, :, i] = true_mask_3d

print(f"ğŸ“Š 3D volume shape: {volume_3d.shape}")
print(f"ğŸ“Š Unique classes in volume: {np.unique(volume_3d)}")

try:
    from skimage import measure
    from mpl_toolkits.mplot3d.art3d import Poly3DCollection

    # Ø¬Ø±Ø¨ ØªØ±Ø³Ù… class 1 (Ø§Ù„ÙƒØ¨Ø¯)
    if 1 in np.unique(volume_3d):
        print("ğŸ”„ Creating 3D surface for liver (class 1)...")
        verts, faces, normals, values = measure.marching_cubes(
            (volume_3d == 1).astype(np.float32),
            level=0.5
        )

        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='3d')
        mesh = Poly3DCollection(verts[faces], alpha=0.7, edgecolor='k')
        mesh.set_facecolor([1, 0, 0])  # Ø£Ø­Ù…Ø± Ù„Ù„ÙƒØ¨Ø¯
        ax.add_collection3d(mesh)

        ax.set_xlim(0, volume_3d.shape[0])
        ax.set_ylim(0, volume_3d.shape[1])
        ax.set_zlim(0, volume_3d.shape[2])
        ax.set_title('3D Liver Surface (Ground Truth)')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')

        plt.show()
        print("âœ… 3D visualization created!")

    else:
        print("âŒ No liver found for 3D visualization")

except Exception as e:
    print(f"âŒ 3D visualization failed: {e}")
    print("ğŸ’¡ Showing 2D version instead...")

    # Ø¹Ø±Ø¶ 2D Ø¨Ø¯ÙŠÙ„
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(X[sample_idx, :, :, 0], cmap='gray')
    plt.title('Input Image')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(true_mask_3d, cmap='jet')
    plt.title('Ground Truth Mask')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(pred_classes[sample_idx], cmap='jet')
    plt.title('Model Prediction')
    plt.axis('off')

    plt.suptitle('2D Visualization (Sample 4)')
    plt.tight_layout()
    plt.show()

!pip install nibabel --quiet
!pip install scikit-image --quiet
!pip install plotly --quiet
!pip install ipywidgets --quiet
!pip install pyvista --quiet
!pip install trimesh --quiet

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import nibabel as nib
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
import glob
import cv2
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from skimage import measure
import warnings
warnings.filterwarnings('ignore')

print("âœ… All libraries loaded successfully!")
print("Working dir:", os.getcwd())

!wget -c "https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar" -O /content/Task03_Liver.tar
!mkdir -p /content/Task03_Liver
!tar -xvf /content/Task03_Liver.tar -C /content/Task03_Liver
!ls -lh /content/Task03_Liver

class Config3D:
    ROOT = "/content/Task03_Liver"
    IMAGES_TR = os.path.join(ROOT, "imagesTr")
    LABELS_TR = os.path.join(ROOT, "labelsTr")

    # 3D Parameters - Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„Ø¬ÙˆØ¯Ø©
    DEPTH = 96           # Ø²Ø¯Ù†Ø§ Ø§Ù„Ù€ depth
    IMAGE_HEIGHT = 160   # Ø²Ø¯Ù†Ø§ Ø§Ù„Ù€ resolution
    IMAGE_WIDTH = 160
    NUM_CLASSES = 3      # 0-background, 1-liver, 2-tumor

    BATCH_SIZE = 2
    EPOCHS = 40
    LEARNING_RATE = 1e-4
    OUTPUT_DIR = "/content/drive/MyDrive/Liver_3D_Advanced"

os.makedirs(Config3D.OUTPUT_DIR, exist_ok=True)
print("âœ… Config ready!")

def load_nifti(path):
    img = nib.load(path)
    return img.get_fdata()

def preprocess_3d_advanced(img, mask, target_shape=(Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH)):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù€ 3D volume Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„
    """
    original_depth = img.shape[2]

    # Ù†Ø®ØªØ§Ø± Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„ÙƒØ¨Ø¯ (Ù…Ø´ Ø¨Ø³ Ø§Ù„Ù†Øµ)
    # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ ÙˆØ¢Ø®Ø± slice ÙÙŠÙ‡Ø§ liver
    nonzero_slices = np.where(np.any(mask > 0, axis=(0, 1)))[0]

    if len(nonzero_slices) > 0:
        start_slice = max(0, nonzero_slices[0] - 10)
        end_slice = min(original_depth, nonzero_slices[-1] + 10)
    else:
        start_slice = max(0, (original_depth - target_shape[0]) // 2)
        end_slice = start_slice + target_shape[0]

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ volume
    img3d = img[:, :, start_slice:end_slice]
    mask3d = mask[:, :, start_slice:end_slice]

    # Resize Ø¨Ø´ÙƒÙ„ Ù…ØªÙ‚Ø¯Ù…
    img_resized = np.zeros(target_shape)
    mask_resized = np.zeros(target_shape)

    # Ù†Ø³ØªØ®Ø¯Ù… interpolation Ù„ÙƒÙ„ Ø§Ù„Ù€ slices
    depth_ratio = img3d.shape[2] / target_shape[0]

    for i in range(target_shape[0]):
        src_idx = int(i * depth_ratio)
        if src_idx < img3d.shape[2]:
            img_resized[i] = cv2.resize(
                img3d[:,:,src_idx],
                (target_shape[2], target_shape[1]),
                interpolation=cv2.INTER_CUBIC  # Ø£ÙØ¶Ù„ Ù…Ù† LINEAR
            )
            mask_resized[i] = cv2.resize(
                mask3d[:,:,src_idx],
                (target_shape[2], target_shape[1]),
                interpolation=cv2.INTER_NEAREST
            )

    # Normalize with contrast enhancement
    img_resized = (img_resized - np.min(img_resized)) / (np.max(img_resized) - np.min(img_resized) + 1e-8)

    # Contrast stretching
    p2, p98 = np.percentile(img_resized, (2, 98))
    img_resized = np.clip((img_resized - p2) / (p98 - p2), 0, 1)

    img_resized = np.expand_dims(img_resized, axis=-1)
    mask_resized = to_categorical(mask_resized.astype(np.uint8), num_classes=Config3D.NUM_CLASSES)

    return img_resized, mask_resized

image_paths = sorted(glob.glob(os.path.join(Config3D.IMAGES_TR, "*.nii.gz")))
label_paths = sorted(glob.glob(os.path.join(Config3D.LABELS_TR, "*.nii.gz")))

print(f"Total samples available: {len(image_paths)}")
print("Loading 3D data...")

X_3d, Y_3d = [], []
for ip, lp in zip(image_paths[:20], label_paths[:20]):
    print(f"Processing: {os.path.basename(ip)}")
    img, mask = load_nifti(ip), load_nifti(lp)
    xi, yi = preprocess_3d_advanced(img, mask)
    X_3d.append(xi)
    Y_3d.append(yi)

X_3d = np.array(X_3d)
Y_3d = np.array(Y_3d)
print(f"\nâœ… 3D Data loaded: {X_3d.shape}, {Y_3d.shape}")

from tensorflow.keras import layers, models

def build_unet_3d_enhanced(input_shape=(Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH, 1),
                          num_classes=Config3D.NUM_CLASSES):
    """
    3D U-Net Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Batch Normalization Ùˆ Dropout
    """
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)
    c1 = layers.BatchNormalization()(c1)
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c1)
    c1 = layers.BatchNormalization()(c1)
    p1 = layers.MaxPooling3D((2,2,2))(c1)
    p1 = layers.Dropout(0.1)(p1)

    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(p1)
    c2 = layers.BatchNormalization()(c2)
    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c2)
    c2 = layers.BatchNormalization()(c2)
    p2 = layers.MaxPooling3D((2,2,2))(c2)
    p2 = layers.Dropout(0.2)(p2)

    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(p2)
    c3 = layers.BatchNormalization()(c3)
    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c3)
    c3 = layers.BatchNormalization()(c3)
    p3 = layers.MaxPooling3D((2,2,2))(c3)
    p3 = layers.Dropout(0.3)(p3)

    # Bottleneck
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(p3)
    c4 = layers.BatchNormalization()(c4)
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c4)
    c4 = layers.BatchNormalization()(c4)
    c4 = layers.Dropout(0.4)(c4)

    # Decoder
    u5 = layers.UpSampling3D((2,2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(u5)
    c5 = layers.BatchNormalization()(c5)
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c5)
    c5 = layers.BatchNormalization()(c5)

    u6 = layers.UpSampling3D((2,2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(u6)
    c6 = layers.BatchNormalization()(c6)
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c6)
    c6 = layers.BatchNormalization()(c6)

    u7 = layers.UpSampling3D((2,2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(u7)
    c7 = layers.BatchNormalization()(c7)
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c7)
    c7 = layers.BatchNormalization()(c7)

    outputs = layers.Conv3D(num_classes, (1,1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

model_3d = build_unet_3d_enhanced()
model_3d.compile(
    optimizer=tf.keras.optimizers.Adam(Config3D.LEARNING_RATE),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
print("\n3D U-Net Enhanced Model:")
model_3d.summary()

import os

class Config:
    IMAGE_HEIGHT = 128
    IMAGE_WIDTH = 128
    DEPTH = 64            # ÙÙ‚Ø· Ø¥Ø°Ø§ Ø³ØªØ³ØªØ®Ø¯Ù… 3D
    NUM_CLASSES = 3       # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª
    LEARNING_RATE = 1e-3
    BATCH_SIZE = 4
    EPOCHS = 50
    OUTPUT_DIR = "./output"

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

from tensorflow.keras import layers, models

def build_unet_3d(input_shape=(Config.DEPTH, Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH, 1),
                  num_classes=Config.NUM_CLASSES):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling3D((2,2,2))(c1)

    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling3D((2,2,2))(c2)

    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling3D((2,2,2))(c3)

    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling3D((2,2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(u5)
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c5)

    u6 = layers.UpSampling3D((2,2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(u6)
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c6)

    u7 = layers.UpSampling3D((2,2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(u7)
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c7)

    outputs = layers.Conv3D(num_classes, (1,1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

model_3d = build_unet_3d()
model_3d.compile(optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
                 loss="categorical_crossentropy",
                 metrics=["accuracy"])
model_3d.summary()

def create_advanced_3d_visualization(volume, mask, pred_mask, title_prefix=""):
    """
    3D visualization Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ multiple views ÙˆØªÙØ§Ø¹Ù„ ÙƒØ§Ù…Ù„
    """
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('True Segmentation - 3D View', 'Predicted Segmentation - 3D View',
                       'Volume Rendering - Liver', 'Volume Rendering - Tumor'),
        specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}],
               [{'type': 'scatter3d'}, {'type': 'scatter3d'}]],
        vertical_spacing=0.1,
        horizontal_spacing=0.1
    )

    # Function to create mesh from mask
    def create_mesh_trace(mask_data, class_id, color, name, opacity=0.6):
        mask_class = (mask_data == class_id).astype(float)
        if np.sum(mask_class) > 50:
            try:
                verts, faces, normals, _ = measure.marching_cubes(mask_class, level=0.5, step_size=2)
                x, y, z = verts.T
                i, j, k = faces.T

                return go.Mesh3d(
                    x=x, y=y, z=z,
                    i=i, j=j, k=k,
                    color=color,
                    opacity=opacity,
                    name=name,
                    flatshading=False,
                    lighting=dict(ambient=0.5, diffuse=0.8, specular=0.2, roughness=0.5),
                    lightposition=dict(x=100, y=200, z=300)
                )
            except:
                return None
        return None

    # Row 1, Col 1: True Segmentation
    liver_true = create_mesh_trace(mask, 1, 'red', 'Liver (True)', 0.5)
    tumor_true = create_mesh_trace(mask, 2, 'lime', 'Tumor (True)', 0.8)

    if liver_true:
        fig.add_trace(liver_true, row=1, col=1)
    if tumor_true:
        fig.add_trace(tumor_true, row=1, col=1)

    # Row 1, Col 2: Predicted Segmentation
    liver_pred = create_mesh_trace(pred_mask, 1, 'orangered', 'Liver (Pred)', 0.5)
    tumor_pred = create_mesh_trace(pred_mask, 2, 'green', 'Tumor (Pred)', 0.8)

    if liver_pred:
        fig.add_trace(liver_pred, row=1, col=2)
    if tumor_pred:
        fig.add_trace(tumor_pred, row=1, col=2)

    # Row 2, Col 1: Liver Only (High Quality)
    liver_hq = create_mesh_trace(pred_mask, 1, 'crimson', 'Liver (HQ)', 0.7)
    if liver_hq:
        fig.add_trace(liver_hq, row=2, col=1)

    # Row 2, Col 2: Tumor Only (High Quality)
    tumor_hq = create_mesh_trace(pred_mask, 2, 'springgreen', 'Tumor (HQ)', 0.9)
    if tumor_hq:
        fig.add_trace(tumor_hq, row=2, col=2)

    # Update layout for all subplots
    scene_dict = dict(
        xaxis=dict(showgrid=True, gridcolor='lightgray', title='X'),
        yaxis=dict(showgrid=True, gridcolor='lightgray', title='Y'),
        zaxis=dict(showgrid=True, gridcolor='lightgray', title='Z'),
        bgcolor='rgb(240, 240, 240)',
        camera=dict(
            eye=dict(x=1.5, y=1.5, z=1.5),
            center=dict(x=0, y=0, z=0)
        ),
        aspectmode='data'
    )

    fig.update_layout(
        scene=scene_dict,
        scene2=scene_dict,
        scene3=scene_dict,
        scene4=scene_dict,
        title=f"{title_prefix} - Advanced 3D Segmentation Visualization",
        showlegend=True,
        width=1400,
        height=1200,
        font=dict(size=12)
    )

    # Save interactive HTML
    output_path = os.path.join(Config3D.OUTPUT_DIR, f'{title_prefix}_advanced_3d.html')
    fig.write_html(output_path)
    fig.show()

    print(f"âœ… Advanced 3D visualization saved: {output_path}")
    return fig

# Cell 9 - VOLUMETRIC RENDERING with Slices
def create_volumetric_view_with_slices(volume, mask, pred_mask, sample_id=0):
    """
    Ø¹Ø±Ø¶ volumetric Ù…Ø¹ slices ÙÙŠ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø©
    """
    depth, height, width = volume.shape

    # Ø§Ø®ØªÙŠØ§Ø± slices Ù…Ù† Ø§Ù„Ù†Øµ
    mid_d, mid_h, mid_w = depth//2, height//2, width//2

    fig = make_subplots(
        rows=2, cols=3,
        subplot_titles=('Axial View', 'Coronal View', 'Sagittal View',
                       'Axial Mask', 'Coronal Mask', 'Sagittal Mask'),
        specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}, {'type': 'heatmap'}],
               [{'type': 'heatmap'}, {'type': 'heatmap'}, {'type': 'heatmap'}]]
    )

    # Color mapping for masks
    def mask_to_rgb(mask_slice):
        rgb = np.zeros((*mask_slice.shape, 3))
        rgb[mask_slice == 1] = [1, 0, 0]  # Red for liver
        rgb[mask_slice == 2] = [0, 1, 0]  # Green for tumor
        return rgb

    # Row 1: Original volume slices
    fig.add_trace(go.Heatmap(z=volume[mid_d], colorscale='Gray', showscale=False), row=1, col=1)
    fig.add_trace(go.Heatmap(z=volume[:, mid_h, :], colorscale='Gray', showscale=False), row=1, col=2)
    fig.add_trace(go.Heatmap(z=volume[:, :, mid_w], colorscale='Gray', showscale=False), row=1, col=3)

    # Row 2: Predicted mask slices (as colored overlays)
    fig.add_trace(go.Heatmap(z=pred_mask[mid_d], colorscale=[[0, 'black'], [0.5, 'red'], [1, 'green']],
                            showscale=False), row=2, col=1)
    fig.add_trace(go.Heatmap(z=pred_mask[:, mid_h, :], colorscale=[[0, 'black'], [0.5, 'red'], [1, 'green']],
                            showscale=False), row=2, col=2)
    fig.add_trace(go.Heatmap(z=pred_mask[:, :, mid_w], colorscale=[[0, 'black'], [0.5, 'red'], [1, 'green']],
                            showscale=False), row=2, col=3)

    fig.update_layout(
        title=f"Sample {sample_id} - Multi-Planar Reconstruction (MPR)",
        width=1400,
        height=800,
        showlegend=False
    )

    output_path = os.path.join(Config3D.OUTPUT_DIR, f'sample_{sample_id}_mpr.html')
    fig.write_html(output_path)
    fig.show()

    print(f"âœ… MPR visualization saved: {output_path}")

print("\n" + "="*60)
print("ğŸ¨ Generating Advanced 3D Visualizations...")
print("="*60)

val_idx = int(len(X_3d) * 0.8)
num_samples_viz = min(3, len(X_3d) - val_idx)

for i in range(num_samples_viz):
    sample_idx = val_idx + i
    sample_volume = X_3d[sample_idx:sample_idx+1]
    sample_mask = Y_3d[sample_idx:sample_idx+1]

    print(f"\nğŸ“Š Processing Sample {i+1}/{num_samples_viz}...")

    # Predict
    prediction_3d = model_3d.predict(sample_volume, verbose=0)

    # Convert to class labels
    pred_mask_3d = np.argmax(prediction_3d[0], axis=-1)
    true_mask_3d = np.argmax(sample_mask[0], axis=-1)
    volume_3d = sample_volume[0,:,:,:,0]

    # Advanced 3D visualization
    create_advanced_3d_visualization(volume_3d, true_mask_3d, pred_mask_3d, f"Sample_{i+1}")

    # Multi-planar reconstruction
    create_volumetric_view_with_slices(volume_3d, true_mask_3d, pred_mask_3d, i+1)

def calculate_3d_metrics(y_true, y_pred, num_classes=3):
    """
    Ø­Ø³Ø§Ø¨ metrics Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù€ 3D
    """
    metrics = {}
    class_names = ['Background', 'Liver', 'Tumor']

    for class_id in range(num_classes):
        y_true_class = (y_true == class_id).astype(np.float32)
        y_pred_class = (y_pred == class_id).astype(np.float32)

        # Dice Coefficient
        intersection = np.sum(y_true_class * y_pred_class)
        union = np.sum(y_true_class) + np.sum(y_pred_class)
        dice = (2. * intersection + 1e-7) / (union + 1e-7) if union > 0 else 0.0

        # IoU (Jaccard)
        iou = intersection / (union - intersection + 1e-7) if union > intersection else 0.0

        # Volume (in voxels)
        true_volume = np.sum(y_true_class)
        pred_volume = np.sum(y_pred_class)

        metrics[class_names[class_id]] = {
            'Dice': dice,
            'IoU': iou,
            'True Volume': int(true_volume),
            'Pred Volume': int(pred_volume),
            'Volume Error %': abs(pred_volume - true_volume) / (true_volume + 1e-7) * 100
        }

    return metrics

print("\n" + "="*60)
print("ğŸ“ˆ 3D Segmentation Metrics")
print("="*60)

all_metrics = []
for i in range(val_idx, len(X_3d)):
    sample_volume = X_3d[i:i+1]
    sample_mask = Y_3d[i:i+1]

    prediction = model_3d.predict(sample_volume, verbose=0)
    pred_mask = np.argmax(prediction[0], axis=-1)
    true_mask = np.argmax(sample_mask[0], axis=-1)

    metrics = calculate_3d_metrics(true_mask, pred_mask)
    all_metrics.append(metrics)

# Average metrics
print("\nğŸ¯ Average Metrics Across Validation Set:")
print("-" * 60)
for class_name in ['Background', 'Liver', 'Tumor']:
    avg_dice = np.mean([m[class_name]['Dice'] for m in all_metrics])
    avg_iou = np.mean([m[class_name]['IoU'] for m in all_metrics])
    print(f"\n{class_name}:")
    print(f"  â€¢ Dice Coefficient: {avg_dice:.4f}")
    print(f"  â€¢ IoU (Jaccard):    {avg_iou:.4f}")

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# =========================
# â¿¡ CONFIGURATION
# =========================
class Config3D:
    OUTPUT_DIR = "./output_3d"
    IMAGE_HEIGHT = 128
    IMAGE_WIDTH = 128
    DEPTH = 64            # Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
    NUM_CLASSES = 3
    LEARNING_RATE = 1e-3
    BATCH_SIZE = 2
    EPOCHS = 50

os.makedirs(Config3D.OUTPUT_DIR, exist_ok=True)

# =========================
# â¿¢ BUILD 3D UNET
# =========================
def build_unet_3d(input_shape=(Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH, 1),
                  num_classes=Config3D.NUM_CLASSES):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling3D((2,2,2))(c1)

    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling3D((2,2,2))(c2)

    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling3D((2,2,2))(c3)

    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling3D((2,2,2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(u5)
    c5 = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c5)

    u6 = layers.UpSampling3D((2,2,2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(u6)
    c6 = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(c6)

    u7 = layers.UpSampling3D((2,2,2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(u7)
    c7 = layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(c7)

    outputs = layers.Conv3D(num_classes, (1,1,1), activation='softmax')(c7)

    return models.Model(inputs=[inputs], outputs=[outputs])

# =========================
# â¿£ COMPILE MODEL
# =========================
model_3d = build_unet_3d()
model_3d.compile(
    optimizer=tf.keras.optimizers.Adam(Config3D.LEARNING_RATE),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
model_3d.summary()

# =========================
# â¿¤ CALLBACKS
# =========================
checkpoint = ModelCheckpoint(
    os.path.join(Config3D.OUTPUT_DIR, 'best_model_3d.h5'),
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

# =========================
# â¿¥ TRAINING (Ù…Ø«Ø§Ù„ Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©)
# =========================
X = np.random.rand(10, Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH, 1)
Y = np.random.randint(0, Config3D.NUM_CLASSES,
                      size=(10, Config3D.DEPTH, Config3D.IMAGE_HEIGHT, Config3D.IMAGE_WIDTH))
Y = tf.keras.utils.to_categorical(Y, num_classes=Config3D.NUM_CLASSES)

history_3d = model_3d.fit(
    X, Y,
    validation_split=0.2,
    batch_size=Config3D.BATCH_SIZE,
    epochs=Config3D.EPOCHS,
    callbacks=[checkpoint, early_stop, reduce_lr],
    verbose=1
)

# =========================
# â¿¦ PLOT TRAINING HISTORY
# =========================
def plot_training_history(history):
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    axes[0].plot(history.history['loss'], 'b-', linewidth=2, label='Train Loss')
    axes[0].plot(history.history['val_loss'], 'r-', linewidth=2, label='Val Loss')
    axes[0].set_title('3D Model Loss', fontsize=16, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)

    axes[1].plot(history.history['accuracy'], 'b-', linewidth=2, label='Train Acc')
    axes[1].plot(history.history['val_accuracy'], 'r-', linewidth=2, label='Val Acc')
    axes[1].set_title('3D Model Accuracy', fontsize=16, fontweight='bold')
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy', fontsize=12)
    axes[1].legend(fontsize=11)
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(Config3D.OUTPUT_DIR, 'training_history_3d.png'), dpi=200, bbox_inches='tight')
    plt.show()

plot_training_history(history_3d)

# =========================
# â¿§ SUMMARY OUTPUT
# =========================
print("\n" + "="*70)
print("ğŸ‰ ADVANCED 3D SEGMENTATION COMPLETE!")
print("="*70)
print(f"\nğŸ“‚ All results saved to: {Config3D.OUTPUT_DIR}")
print("\nğŸ“‹ Generated Files:")
print("  âœ“ best_model_3d.h5 - Trained 3D model")
print("  âœ“ training_history_3d.png - Training curves")
print("\nğŸ’¡ Open the output folder Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
print("="*70)