{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHkMneAgs2AV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ğŸ” ÙØ­Øµ ØªÙˆÙØ± GPU...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"âœ… GPU Ù…ØªØ§Ø­! Ø¹Ø¯Ø¯ GPUs: {len(gpus)}\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"   ğŸ“ {gpu}\")\n",
        "    # ØªÙØ¹ÙŠÙ„ memory growth Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ ÙƒÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ GPU Memory Growth\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªÙØ¹ÙŠÙ„ Memory Growth: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU ØºÙŠØ± Ù…ØªØ§Ø­! Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU\")\n",
        "    print(\"â— Ù„Ù„ØªÙØ¹ÙŠÙ„: Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª TensorFlow\n",
        "print(f\"\\nğŸ“¦ TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"ğŸ”§ Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "from google.colab import drive , auth\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vGxsu_5dsUxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9432cb-ca3f-457a-ef4d-efc0d483fc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ” ÙØ­Øµ ØªÙˆÙØ± GPU...\n",
            "============================================================\n",
            "âš ï¸ GPU ØºÙŠØ± Ù…ØªØ§Ø­! Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU\n",
            "â— Ù„Ù„ØªÙØ¹ÙŠÙ„: Runtime > Change runtime type > GPU\n",
            "\n",
            "ğŸ“¦ TensorFlow Version: 2.19.0\n",
            "ğŸ”§ Built with CUDA: True\n",
            "============================================================\n",
            "\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª - Ø¹Ø¯Ù„ Ù‡Ø°Ù‡ Ø­Ø³Ø¨ Ø¨ÙŠØ¦ØªÙƒ\n",
        "    DATA_DIR = \"/content/chest_ct_segmentation\"  # ØªØ£ÙƒØ¯ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø±\n",
        "    OUTPUT_DIR = \"/content/results\"\n",
        "\n",
        "    # Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø©\n",
        "    IMAGE_HEIGHT = 256\n",
        "    IMAGE_WIDTH = 256\n",
        "    NUM_CLASSES = 3  # Ø§Ù„Ø®Ù„ÙÙŠØ©ØŒ Ø§Ù„Ø±Ø¦Ø© Ø§Ù„ÙŠØ³Ø±Ù‰ØŒ Ø§Ù„Ø±Ø¦Ø© Ø§Ù„ÙŠÙ…Ù†Ù‰\n",
        "\n",
        "    # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "    EPOCHS = 50  # ØªÙ‚Ù„ÙŠÙ„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹\n",
        "    BATCH_SIZE = 8\n",
        "    LEARNING_RATE = 1e-4\n",
        "    VALIDATION_SPLIT = 0.2\n",
        "\n",
        "    # Early stopping\n",
        "    PATIENCE_EARLY_STOP = 10\n",
        "    PATIENCE_LR_REDUCE = 5\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "EwkJ1HW-tSVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    \"\"\"ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù‡Ø§ÙŠØ¨Ø± Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±Ø² ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª\"\"\"\n",
        "\n",
        "    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "    DATA_DIRS = [\n",
        "        \"/content/drive/MyDrive/Seg3Data\",\n",
        "        \"/content/drive/MyDrive/Seg3Data/seg3Data_test\",\n",
        "        \"/content/drive/MyDrive/Seg3Data/seg3Data_train2\"\n",
        "    ]\n",
        "\n",
        "    # Ø£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ modalities (Ø¨Ø¯ÙˆÙ† .nii Ø£Ùˆ .nii.gz)\n",
        "    MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "    LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "    # Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "    IMAGE_HEIGHT = 240\n",
        "    IMAGE_WIDTH = 240\n",
        "    NUM_CLASSES = 4\n",
        "\n",
        "    # Ù‡Ø§ÙŠØ¨Ø± Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±Ø²\n",
        "    EPOCHS = 150\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 1e-4\n",
        "\n",
        "    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "    RANDOM_SEED = 42\n",
        "    PATIENCE_EARLY_STOP = 20\n",
        "    PATIENCE_LR_REDUCE = 10\n",
        "\n",
        "    # Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "class MRIDataLoader:\n",
        "    \"\"\"ÙØ¦Ø© Ù„ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª MRI Ù…Ù† Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\"\"\"\n",
        "\n",
        "    def __init__(self, data_dirs, modalities, label_file):\n",
        "        self.data_dirs = data_dirs\n",
        "        self.modalities = modalities\n",
        "        self.label_file = label_file\n",
        "\n",
        "    def load_nifti(self, data_dir, filename):\n",
        "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù NIfTI Ù…Ù† Ù…Ø¬Ù„Ø¯ Ù…Ø­Ø¯Ø¯\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(data_dir, filename + '.nii'),\n",
        "            os.path.join(data_dir, filename + '.nii.gz'),\n",
        "            os.path.join(data_dir, filename)\n",
        "        ]\n",
        "\n",
        "        filepath = None\n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                filepath = path\n",
        "                break\n",
        "\n",
        "        if filepath is None:\n",
        "            raise FileNotFoundError(f\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {filename} ÙÙŠ {data_dir}\")\n",
        "\n",
        "        print(f\"    - ØªØ­Ù…ÙŠÙ„: {os.path.basename(filepath)}\")\n",
        "        nii = nib.load(filepath)\n",
        "        data = nii.get_fdata()\n",
        "        return data\n",
        "\n",
        "    def normalize_volume(self, volume):\n",
        "        \"\"\"ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (normalization)\"\"\"\n",
        "        volume = volume.astype(np.float32)\n",
        "        mean = np.mean(volume[volume > 0])\n",
        "        std = np.std(volume[volume > 0])\n",
        "        if std > 0:\n",
        "            volume = (volume - mean) / std\n",
        "        return volume\n",
        "\n",
        "    def load_data_from_folder(self, data_dir):\n",
        "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ø¬Ù„Ø¯ ÙˆØ§Ø­Ø¯\"\"\"\n",
        "        print(f\"\\n  ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯: {os.path.basename(data_dir)}\")\n",
        "\n",
        "        # ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ modalities\n",
        "        volumes = {}\n",
        "        for modality in self.modalities:\n",
        "            volume = self.load_nifti(data_dir, modality)\n",
        "            volume = self.normalize_volume(volume)\n",
        "            volumes[modality] = volume\n",
        "\n",
        "        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ labels\n",
        "        labels = self.load_nifti(data_dir, self.label_file)\n",
        "        labels = labels.astype(np.int32)\n",
        "\n",
        "        num_slices = labels.shape[2]\n",
        "        unique_labels = np.unique(labels)\n",
        "        print(f\"    âœ“ Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {labels.shape}\")\n",
        "        print(f\"    âœ“ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {num_slices}\")\n",
        "        print(f\"    âœ“ Ø§Ù„Ù€ classes: {unique_labels}\")\n",
        "\n",
        "        return volumes, labels, num_slices\n",
        "\n",
        "    def load_all_data(self):\n",
        "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        all_volumes_list = []\n",
        "        all_labels_list = []\n",
        "        all_slice_indices = []\n",
        "        folder_info = []\n",
        "\n",
        "        for folder_idx, data_dir in enumerate(self.data_dirs):\n",
        "            try:\n",
        "                volumes, labels, num_slices = self.load_data_from_folder(data_dir)\n",
        "\n",
        "                # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯\n",
        "                folder_info.append({\n",
        "                    'folder_idx': folder_idx,\n",
        "                    'path': data_dir,\n",
        "                    'num_slices': num_slices,\n",
        "                    'volumes': volumes,\n",
        "                    'labels': labels\n",
        "                })\n",
        "\n",
        "                # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ù„Ø¯\n",
        "                for slice_idx in range(num_slices):\n",
        "                    all_slice_indices.append({\n",
        "                        'folder_idx': folder_idx,\n",
        "                        'slice_idx': slice_idx\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    âš  Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯ {data_dir}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† {len(folder_info)} Ù…Ø¬Ù„Ø¯\")\n",
        "        print(f\"âœ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {len(all_slice_indices)}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return folder_info, all_slice_indices\n",
        "\n",
        "\n",
        "class MultiModalityGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generator Ù„ØªÙˆÙ„ÙŠØ¯ batches Ù…Ù† Ø§Ù„Ù€ slices Ù…Ù† Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\"\"\"\n",
        "\n",
        "    def __init__(self, folder_info, slice_indices, batch_size,\n",
        "                 num_classes, modalities, image_height, image_width, shuffle=True):\n",
        "        self.folder_info = folder_info\n",
        "        self.slice_indices = slice_indices\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.modalities = modalities\n",
        "        self.image_height = image_height\n",
        "        self.image_width = image_width\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Ø¹Ø¯Ø¯ Ø§Ù„Ù€ batches ÙÙŠ ÙƒÙ„ epoch\"\"\"\n",
        "        return int(np.ceil(len(self.slice_indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"ØªÙˆÙ„ÙŠØ¯ batch ÙˆØ§Ø­Ø¯\"\"\"\n",
        "        batch_indices = self.indices[\n",
        "            index * self.batch_size:(index + 1) * self.batch_size\n",
        "        ]\n",
        "        batch_slices = [self.slice_indices[i] for i in batch_indices]\n",
        "\n",
        "        X, y = self._generate_data(batch_slices)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Ø®Ù„Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ epoch\"\"\"\n",
        "        self.indices = np.arange(len(self.slice_indices))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def _generate_data(self, batch_slices):\n",
        "        \"\"\"ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ batch Ù…Ø¹ÙŠÙ†\"\"\"\n",
        "        num_modalities = len(self.modalities)\n",
        "\n",
        "        X = np.zeros((len(batch_slices), self.image_height,\n",
        "                      self.image_width, num_modalities), dtype=np.float32)\n",
        "        y = np.zeros((len(batch_slices), self.image_height,\n",
        "                      self.image_width), dtype=np.int32)\n",
        "\n",
        "        for i, slice_info in enumerate(batch_slices):\n",
        "            folder_idx = slice_info['folder_idx']\n",
        "            slice_idx = slice_info['slice_idx']\n",
        "\n",
        "            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨\n",
        "            folder_data = self.folder_info[folder_idx]\n",
        "            volumes = folder_data['volumes']\n",
        "            labels = folder_data['labels']\n",
        "\n",
        "            # ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ modalities\n",
        "            for j, modality in enumerate(self.modalities):\n",
        "                X[i, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "\n",
        "            y[i] = labels[:, :, slice_idx]\n",
        "\n",
        "        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù€ labels Ø¥Ù„Ù‰ one-hot encoding\n",
        "        y = to_categorical(y, num_classes=self.num_classes)\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "NRoK5QU5tKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingPipeline:\n",
        "    \"\"\"Pipeline ÙƒØ§Ù…Ù„ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        np.random.seed(config.RANDOM_SEED)\n",
        "        tf.random.set_seed(config.RANDOM_SEED)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª\"\"\"\n",
        "        loader = MRIDataLoader(\n",
        "            self.config.DATA_DIRS,\n",
        "            self.config.MODALITIES,\n",
        "            self.config.LABEL_FILE\n",
        "        )\n",
        "        folder_info, train_slices = loader.load_all_data()\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\nğŸ“Š ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
        "        print(f\"  - Training slices: {len(train_slices)}\")\n",
        "        print(f\"  - Training batches: {len(train_slices) // self.config.BATCH_SIZE}\")\n",
        "\n",
        "        return folder_info, train_slices\n",
        "\n",
        "    def create_generators(self, folder_info, train_slices):\n",
        "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ data generators\"\"\"\n",
        "        train_gen = MultiModalityGenerator(\n",
        "            folder_info, train_slices,\n",
        "            self.config.BATCH_SIZE,\n",
        "            self.config.NUM_CLASSES,\n",
        "            self.config.MODALITIES,\n",
        "            self.config.IMAGE_HEIGHT,\n",
        "            self.config.IMAGE_WIDTH,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "\n",
        "        return train_gen\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_callbacks(self):\n",
        "        \"\"\"Ø¥Ø¹Ø¯Ø§Ø¯ callbacks Ù„Ù„ØªØ¯Ø±ÙŠØ¨\"\"\"\n",
        "        from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "        callbacks = [\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(self.config.OUTPUT_DIR, 'best_model_val_loss.h5'),\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True,\n",
        "                mode='min',\n",
        "                verbose=1\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(self.config.OUTPUT_DIR, 'best_model_val_iou.h5'),\n",
        "                monitor='val_mean_io_u',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=self.config.PATIENCE_EARLY_STOP,\n",
        "                verbose=1,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=self.config.PATIENCE_LR_REDUCE,\n",
        "                verbose=1,\n",
        "                min_lr=1e-7\n",
        "            )\n",
        "        ]\n",
        "        return callbacks\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸš€ Ø¨Ø¯Ø¡ Pipeline Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # 1. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "        folder_info, train_slices = self.prepare_data()\n",
        "\n",
        "        # 2. Ø¥Ù†Ø´Ø§Ø¡ generators\n",
        "        print(\"\\nğŸ“¦ Ø¥Ù†Ø´Ø§Ø¡ Data Generators...\")\n",
        "        train_gen= self.create_generators(\n",
        "            folder_info, train_slices\n",
        "        )\n",
        "        print(\"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Generators Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "\n",
        "        model = build_unet(\n",
        "            config.IMAGE_HEIGHT,\n",
        "            config.IMAGE_WIDTH,\n",
        "            len(config.MODALITIES),\n",
        "            config.NUM_CLASSES\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=config.NUM_CLASSES)]\n",
        "        )\n",
        "        # 4. Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...\")\n",
        "        print(\"=\"*60)\n",
        "        history = model.fit(\n",
        "            train_gen,\n",
        "            epochs=self.config.EPOCHS,\n",
        "            callbacks=self.get_callbacks(),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return model, history"
      ],
      "metadata": {
        "id": "Ezf212hstL5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yj-p0wC4ga_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training the model :"
      ],
      "metadata": {
        "id": "qfFd-kHEexPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ§  MRI Multi-Folder Segmentation Pipeline\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {len(config.DATA_DIRS)}\")\n",
        "for i, folder in enumerate(config.DATA_DIRS, 1):\n",
        "    print(f\"  {i}. {folder}\")\n",
        "print(f\"\\nğŸ“Š Modalities: {config.MODALITIES}\")\n",
        "print(f\"ğŸ¯ Classes: {config.NUM_CLASSES}\")\n",
        "print(f\"ğŸ“ˆ Epochs: {config.EPOCHS}\")\n",
        "print(f\"ğŸ“¦ Batch Size: {config.BATCH_SIZE}\")\n",
        "\n",
        "pipeline = TrainingPipeline(config)\n",
        "model, history = pipeline.train()\n",
        "\n",
        "# Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
        "final_model_path = os.path.join(config.OUTPUT_DIR, 'final_model.h5')\n",
        "model.save(final_model_path)\n",
        "print(f\"\\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ: {final_model_path}\")"
      ],
      "metadata": {
        "id": "ZatiHlcPtW59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4fc7ec-fd50-4346-9fed-3fe1f48a9a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ§  MRI Multi-Folder Segmentation Pipeline\n",
            "============================================================\n",
            "\n",
            "ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: 3\n",
            "  1. /content/drive/MyDrive/Seg3Data\n",
            "  2. /content/drive/MyDrive/Seg3Data/seg3Data_test\n",
            "  3. /content/drive/MyDrive/Seg3Data/seg3Data_train2\n",
            "\n",
            "ğŸ“Š Modalities: ['T1', 'T1_IR', 'T2_FLAIR']\n",
            "ğŸ¯ Classes: 4\n",
            "ğŸ“ˆ Epochs: 150\n",
            "ğŸ“¦ Batch Size: 32\n",
            "\n",
            "============================================================\n",
            "ğŸš€ Ø¨Ø¯Ø¡ Pipeline Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª...\n",
            "============================================================\n",
            "\n",
            "  ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯: Seg3Data\n",
            "    - ØªØ­Ù…ÙŠÙ„: T1.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: T1_IR.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: T2_FLAIR.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: LabelsForTesting.nii\n",
            "    âœ“ Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: (240, 240, 48)\n",
            "    âœ“ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: 48\n",
            "    âœ“ Ø§Ù„Ù€ classes: [0 1 2 3]\n",
            "\n",
            "  ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯: seg3Data_test\n",
            "    - ØªØ­Ù…ÙŠÙ„: T1.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: T1_IR.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: T2_FLAIR.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: LabelsForTesting.nii\n",
            "    âœ“ Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: (240, 240, 48)\n",
            "    âœ“ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: 48\n",
            "    âœ“ Ø§Ù„Ù€ classes: [0 1 2 3]\n",
            "\n",
            "  ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯: seg3Data_train2\n",
            "    - ØªØ­Ù…ÙŠÙ„: T1.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: T1_IR.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: T2_FLAIR.nii\n",
            "    - ØªØ­Ù…ÙŠÙ„: LabelsForTesting.nii\n",
            "    âœ“ Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: (240, 240, 48)\n",
            "    âœ“ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: 48\n",
            "    âœ“ Ø§Ù„Ù€ classes: [0 1 2 3]\n",
            "\n",
            "============================================================\n",
            "âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† 3 Ù…Ø¬Ù„Ø¯\n",
            "âœ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: 144\n",
            "============================================================\n",
            "\n",
            "ğŸ“Š ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
            "  - Training slices: 144\n",
            "  - Training batches: 4\n",
            "\n",
            "ğŸ“¦ Ø¥Ù†Ø´Ø§Ø¡ Data Generators...\n",
            "âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Generators Ø¨Ù†Ø¬Ø§Ø­!\n",
            "\n",
            "============================================================\n",
            "ğŸ¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...\n",
            "============================================================\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## making the test data ready :"
      ],
      "metadata": {
        "id": "-ibL04GTe9Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestPipeline:\n",
        "    \"\"\"Pipeline Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…\"\"\"\n",
        "\n",
        "    def __init__(self, model, config):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "\n",
        "    def load_test_data(self, test_data_dir=\"/content/drive/MyDrive/Seg3Data_test\"):\n",
        "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\"\"\"\n",
        "\n",
        "        print(f\"\\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù†: {test_data_dir}\")\n",
        "\n",
        "        loader = MRIDataLoader(\n",
        "            test_data_dir,\n",
        "            self.config.MODALITIES,\n",
        "            self.config.LABEL_FILE\n",
        "        )\n",
        "        volumes, labels = loader.load_all_data()\n",
        "\n",
        "        return volumes, labels\n",
        "\n",
        "    def predict_slice(self, volumes, slice_idx):\n",
        "        \"\"\"Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø´Ø±ÙŠØ­Ø© ÙˆØ§Ø­Ø¯Ø©\"\"\"\n",
        "        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "        X = np.zeros((1, self.config.IMAGE_HEIGHT,\n",
        "                      self.config.IMAGE_WIDTH,\n",
        "                      len(self.config.MODALITIES)), dtype=np.float32)\n",
        "\n",
        "        for j, modality in enumerate(self.config.MODALITIES):\n",
        "            X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "\n",
        "        # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "        pred = self.model.predict(X, verbose=0)\n",
        "        pred_mask = np.argmax(pred[0], axis=-1)\n",
        "\n",
        "        return pred_mask, pred[0]\n",
        "\n",
        "    def calculate_metrics(self, true_labels, pred_labels):\n",
        "        \"\"\"Ø­Ø³Ø§Ø¨ metrics Ù„Ù„ØªÙ‚ÙŠÙŠÙ…\"\"\"\n",
        "        from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "\n",
        "        # ØªØ³Ø·ÙŠØ­ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª\n",
        "        true_flat = true_labels.flatten()\n",
        "        pred_flat = pred_labels.flatten()\n",
        "\n",
        "        # Ø­Ø³Ø§Ø¨ Metrics\n",
        "        accuracy = accuracy_score(true_flat, pred_flat)\n",
        "\n",
        "        # IoU Ùˆ Dice Ù„ÙƒÙ„ class\n",
        "        iou_per_class = []\n",
        "        dice_per_class = []\n",
        "\n",
        "        for class_id in range(self.config.NUM_CLASSES):\n",
        "            iou = jaccard_score(true_flat == class_id,\n",
        "                               pred_flat == class_id,\n",
        "                               zero_division=0)\n",
        "            dice = f1_score(true_flat == class_id,\n",
        "                           pred_flat == class_id,\n",
        "                           zero_division=0)\n",
        "            iou_per_class.append(iou)\n",
        "            dice_per_class.append(dice)\n",
        "\n",
        "        mean_iou = np.mean(iou_per_class)\n",
        "        mean_dice = np.mean(dice_per_class)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'mean_iou': mean_iou,\n",
        "            'mean_dice': mean_dice,\n",
        "            'iou_per_class': iou_per_class,\n",
        "            'dice_per_class': dice_per_class\n",
        "        }\n",
        "\n",
        "    def visualize_predictions(self, volumes, labels, slice_indices,\n",
        "                             save_path=None, num_cols=4):\n",
        "        \"\"\"Ø±Ø³Ù… Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©\"\"\"\n",
        "        num_slices = len(slice_indices)\n",
        "        num_rows = (num_slices + num_cols - 1) // num_cols\n",
        "\n",
        "        fig, axes = plt.subplots(num_rows, num_cols,\n",
        "                                figsize=(num_cols * 5, num_rows * 5))\n",
        "        axes = axes.flatten() if num_slices > 1 else [axes]\n",
        "\n",
        "        for idx, slice_idx in enumerate(slice_indices):\n",
        "            if idx >= len(axes):\n",
        "                break\n",
        "\n",
        "            # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "            pred_mask, pred_probs = self.predict_slice(volumes, slice_idx)\n",
        "            true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "            # Ø­Ø³Ø§Ø¨ metrics Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø±ÙŠØ­Ø©\n",
        "            slice_metrics = self.calculate_metrics(true_mask, pred_mask)\n",
        "\n",
        "            # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù…Ø±ÙƒØ¨Ø©\n",
        "            # Ù†Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„ modality Ù„Ù„Ø¹Ø±Ø¶\n",
        "            first_modality = self.config.MODALITIES[0]\n",
        "            img = volumes[first_modality][:, :, slice_idx]\n",
        "\n",
        "            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ø¹Ø±Ø¶\n",
        "            img_normalized = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "\n",
        "            # Ø¥Ù†Ø´Ø§Ø¡ overlay\n",
        "            ax = axes[idx]\n",
        "            ax.imshow(img_normalized, cmap='gray', alpha=0.7)\n",
        "\n",
        "            # Ø±Ø³Ù… Ø§Ù„Ù€ true mask ÙˆØ§Ù„Ù€ prediction Ø¨Ø¬Ø§Ù†Ø¨ Ø¨Ø¹Ø¶\n",
        "            true_overlay = np.ma.masked_where(true_mask == 0, true_mask)\n",
        "            pred_overlay = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
        "\n",
        "            # Ù†ØµÙ Ø§Ù„ØµÙˆØ±Ø© trueØŒ Ù†ØµÙÙ‡Ø§ prediction\n",
        "            h = img.shape[0]\n",
        "\n",
        "            # True mask (Ø§Ù„Ù†ØµÙ Ø§Ù„Ø£ÙŠØ³Ø±)\n",
        "            ax.imshow(true_overlay, cmap='Set1', alpha=0.5, vmin=0,\n",
        "                     vmax=self.config.NUM_CLASSES-1)\n",
        "            ax.axvline(x=img.shape[1]//2, color='yellow', linewidth=2,\n",
        "                      linestyle='--', label='Split')\n",
        "\n",
        "            # Prediction mask (Ø§Ù„Ù†ØµÙ Ø§Ù„Ø£ÙŠÙ…Ù†)\n",
        "            pred_overlay_right = pred_overlay.copy()\n",
        "            pred_overlay_right[:, :img.shape[1]//2] = np.ma.masked\n",
        "            ax.imshow(pred_overlay_right, cmap='Set1', alpha=0.5,\n",
        "                     vmin=0, vmax=self.config.NUM_CLASSES-1)\n",
        "\n",
        "            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\n",
        "            ax.set_title(f'Slice {slice_idx}\\n'\n",
        "                        f'Acc: {slice_metrics[\"accuracy\"]:.3f} | '\n",
        "                        f'IoU: {slice_metrics[\"mean_iou\"]:.3f} | '\n",
        "                        f'Dice: {slice_metrics[\"mean_dice\"]:.3f}\\n'\n",
        "                        f'Left: Ground Truth | Right: Prediction',\n",
        "                        fontsize=10)\n",
        "            ax.axis('off')\n",
        "\n",
        "        # Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„ÙØ§Ø±ØºØ©\n",
        "        for idx in range(num_slices, len(axes)):\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± ÙÙŠ: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_all_slices(self, volumes, labels, slice_indices=None):\n",
        "        \"\"\"ØªÙ‚ÙŠÙŠÙ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­\"\"\"\n",
        "        if slice_indices is None:\n",
        "            slice_indices = range(labels.shape[2])\n",
        "\n",
        "        print(f\"\\nğŸ“Š ØªÙ‚ÙŠÙŠÙ… {len(slice_indices)} Ø´Ø±ÙŠØ­Ø©...\")\n",
        "\n",
        "        all_true = []\n",
        "        all_pred = []\n",
        "\n",
        "        for slice_idx in slice_indices:\n",
        "            pred_mask, _ = self.predict_slice(volumes, slice_idx)\n",
        "            true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "            all_true.append(true_mask.flatten())\n",
        "            all_pred.append(pred_mask.flatten())\n",
        "\n",
        "        all_true = np.concatenate(all_true)\n",
        "        all_pred = np.concatenate(all_pred)\n",
        "\n",
        "        # Ø­Ø³Ø§Ø¨ Metrics Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©\n",
        "        metrics = self.calculate_metrics(all_true, all_pred)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©:\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Overall Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
        "        print(f\"Mean Dice: {metrics['mean_dice']:.4f}\")\n",
        "        print(f\"\\nPer-Class Metrics:\")\n",
        "        for i in range(self.config.NUM_CLASSES):\n",
        "            print(f\"  Class {i}:\")\n",
        "            print(f\"    IoU:  {metrics['iou_per_class'][i]:.4f}\")\n",
        "            print(f\"    Dice: {metrics['dice_per_class'][i]:.4f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return metrics"
      ],
      "metadata": {
        "id": "7sM4_WWotp-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D testing result :"
      ],
      "metadata": {
        "id": "0IueubDefIUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "model_path = \"/content/drive/MyDrive/Seg3Data/results/best_model_val_acc.h5\"\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "model = load_model(model_path)\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Test Pipeline\n",
        "\n",
        "\n",
        "test_pipeline = TestPipeline(model, config)\n",
        "\n",
        "print(\"\\nğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… Test Pipeline:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§Ù…Ù„Ø© ÙˆÙ…Ø³ØªÙ‚Ù„Ø© - Ø¹Ø±Ø¶ Ù…Ù†ÙØµÙ„\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "import random\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„Ø© - Ø¹Ø±Ø¶ Ù…Ù†ÙØµÙ„\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
        "# ============================\n",
        "# Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data\"\n",
        "\n",
        "# Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Seg3Data/results/best_model_val_acc.h5\"\n",
        "\n",
        "# Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "# Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª\n",
        "MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø®Ø±Ù‰\n",
        "IMAGE_HEIGHT = 240\n",
        "IMAGE_WIDTH = 240\n",
        "NUM_CLASSES = 4  # ØºÙŠÙ‘Ø±Ù‡Ø§ Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ classes Ø¹Ù†Ø¯Ùƒ\n",
        "\n",
        "# Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø¯ Ø¹Ø±Ø¶Ù‡Ø§\n",
        "NUM_SAMPLES = 5\n",
        "\n",
        "print(f\"\\nğŸ“ Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {TEST_DATA_DIR}\")\n",
        "print(f\"ğŸ¤– Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_PATH}\")\n",
        "\n",
        "# ============================\n",
        "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    model = load_model(MODEL_PATH)\n",
        "    print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}\")\n",
        "    raise\n",
        "\n",
        "# ============================\n",
        "# 3. Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©\n",
        "# ============================\n",
        "def load_nifti_file(filepath):\n",
        "    \"\"\"ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù NIfTI\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        if os.path.exists(filepath.replace('.nii.gz', '.nii')):\n",
        "            filepath = filepath.replace('.nii.gz', '.nii')\n",
        "        elif os.path.exists(filepath.replace('.nii', '.nii.gz')):\n",
        "            filepath = filepath.replace('.nii', '.nii.gz')\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {filepath}\")\n",
        "\n",
        "    nii = nib.load(filepath)\n",
        "    data = nii.get_fdata()\n",
        "    return data\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    \"\"\"ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\"\"\"\n",
        "    volume = volume.astype(np.float32)\n",
        "    mean = np.mean(volume[volume > 0])\n",
        "    std = np.std(volume[volume > 0])\n",
        "    if std > 0:\n",
        "        volume = (volume - mean) / std\n",
        "    return volume\n",
        "\n",
        "# ============================\n",
        "# 4. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not os.path.exists(TEST_DATA_DIR):\n",
        "    print(f\"âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {TEST_DATA_DIR}\")\n",
        "    raise FileNotFoundError(f\"Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {TEST_DATA_DIR}\")\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ modalities\n",
        "volumes = {}\n",
        "for modality in MODALITIES:\n",
        "    filepath = os.path.join(TEST_DATA_DIR, modality + '.nii')\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath = os.path.join(TEST_DATA_DIR, modality + '.nii.gz')\n",
        "\n",
        "    print(f\"   ØªØ­Ù…ÙŠÙ„ {modality}...\")\n",
        "    volume = load_nifti_file(filepath)\n",
        "    volume = normalize_volume(volume)\n",
        "    volumes[modality] = volume\n",
        "    print(f\"      âœ… Ø§Ù„Ø­Ø¬Ù…: {volume.shape}\")\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Labels\n",
        "print(f\"   ØªØ­Ù…ÙŠÙ„ {LABEL_FILE}...\")\n",
        "label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii')\n",
        "if not os.path.exists(label_filepath):\n",
        "    label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii.gz')\n",
        "\n",
        "labels = load_nifti_file(label_filepath).astype(np.int32)\n",
        "print(f\"      âœ… Ø§Ù„Ø­Ø¬Ù…: {labels.shape}\")\n",
        "print(f\"      Classes Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: {np.unique(labels)}\")\n",
        "\n",
        "num_slices = labels.shape[2]\n",
        "print(f\"\\nâœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {num_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 5. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "# ============================\n",
        "def predict_slice(model, volumes, slice_idx, modalities):\n",
        "    \"\"\"Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø´Ø±ÙŠØ­Ø© ÙˆØ§Ø­Ø¯Ø©\"\"\"\n",
        "    X = np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, len(modalities)), dtype=np.float32)\n",
        "\n",
        "    for j, modality in enumerate(modalities):\n",
        "        X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "\n",
        "    pred = model.predict(X, verbose=0)\n",
        "    pred_mask = np.argmax(pred[0], axis=-1)\n",
        "\n",
        "    return pred_mask\n",
        "\n",
        "# ============================\n",
        "# 6. Ø¯Ø§Ù„Ø© Ø­Ø³Ø§Ø¨ Metrics\n",
        "# ============================\n",
        "def calculate_metrics(true_labels, pred_labels, num_classes):\n",
        "    \"\"\"Ø­Ø³Ø§Ø¨ metrics\"\"\"\n",
        "    true_flat = true_labels.flatten()\n",
        "    pred_flat = pred_labels.flatten()\n",
        "\n",
        "    accuracy = accuracy_score(true_flat, pred_flat)\n",
        "\n",
        "    iou_per_class = []\n",
        "    dice_per_class = []\n",
        "\n",
        "    for class_id in range(num_classes):\n",
        "        iou = jaccard_score(true_flat == class_id,\n",
        "                           pred_flat == class_id,\n",
        "                           zero_division=0)\n",
        "        dice = f1_score(true_flat == class_id,\n",
        "                       pred_flat == class_id,\n",
        "                       zero_division=0)\n",
        "        iou_per_class.append(iou)\n",
        "        dice_per_class.append(dice)\n",
        "\n",
        "    mean_iou = np.mean(iou_per_class)\n",
        "    mean_dice = np.mean(dice_per_class)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'mean_iou': mean_iou,\n",
        "        'mean_dice': mean_dice,\n",
        "        'iou_per_class': iou_per_class,\n",
        "        'dice_per_class': dice_per_class\n",
        "    }\n",
        "\n",
        "# ============================\n",
        "# 7. Ø¯Ø§Ù„Ø© Ø±Ø³Ù… Ù…Ù†ÙØµÙ„Ø© - ÙƒÙ„ ØµÙˆØ±Ø© Ù„ÙˆØ­Ø¯Ù‡Ø§\n",
        "# ============================\n",
        "def visualize_predictions_separate(model, volumes, labels, slice_indices,\n",
        "                                   modalities, num_classes, save_path=None):\n",
        "    \"\"\"Ø±Ø³Ù… Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª - ÙƒÙ„ ØµÙˆØ±Ø© Ù…Ù†ÙØµÙ„Ø©\"\"\"\n",
        "    num_samples = len(slice_indices)\n",
        "\n",
        "    # ÙƒÙ„ ØµÙ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰: Image + Ground Truth + Prediction\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
        "\n",
        "    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹ÙŠÙ†Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for row_idx, slice_idx in enumerate(slice_indices):\n",
        "        # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "        pred_mask = predict_slice(model, volumes, slice_idx, modalities)\n",
        "        true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "        # Ø­Ø³Ø§Ø¨ metrics\n",
        "        slice_metrics = calculate_metrics(true_mask, pred_mask, num_classes)\n",
        "\n",
        "        # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©\n",
        "        first_modality = modalities[0]\n",
        "        img = volumes[first_modality][:, :, slice_idx]\n",
        "        img_normalized = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "\n",
        "        # Ø§Ù„Ø¹Ù…ÙˆØ¯ 1: Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©\n",
        "        axes[row_idx, 0].imshow(img_normalized, cmap='gray')\n",
        "        axes[row_idx, 0].set_title(f'Slice {slice_idx}\\nOriginal Image ({first_modality})',\n",
        "                                   fontsize=12, fontweight='bold')\n",
        "        axes[row_idx, 0].axis('off')\n",
        "\n",
        "        # Ø§Ù„Ø¹Ù…ÙˆØ¯ 2: Ground Truth\n",
        "        axes[row_idx, 1].imshow(img_normalized, cmap='gray', alpha=0.3)\n",
        "        true_overlay = np.ma.masked_where(true_mask == 0, true_mask)\n",
        "        axes[row_idx, 1].imshow(true_overlay, cmap='Set1', alpha=0.7,\n",
        "                               vmin=0, vmax=num_classes-1)\n",
        "        axes[row_idx, 1].set_title('Ground Truth\\n(Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©)',\n",
        "                                  fontsize=12, fontweight='bold', color='green')\n",
        "        axes[row_idx, 1].axis('off')\n",
        "\n",
        "        # Ø§Ù„Ø¹Ù…ÙˆØ¯ 3: Prediction\n",
        "        axes[row_idx, 2].imshow(img_normalized, cmap='gray', alpha=0.3)\n",
        "        pred_overlay = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
        "        axes[row_idx, 2].imshow(pred_overlay, cmap='Set1', alpha=0.7,\n",
        "                               vmin=0, vmax=num_classes-1)\n",
        "        axes[row_idx, 2].set_title(\n",
        "            f'Model Prediction\\n(Ø§Ù„ØªÙ†Ø¨Ø¤)\\n'\n",
        "            f'Acc: {slice_metrics[\"accuracy\"]:.3f} | '\n",
        "            f'IoU: {slice_metrics[\"mean_iou\"]:.3f} | '\n",
        "            f'Dice: {slice_metrics[\"mean_dice\"]:.3f}',\n",
        "            fontsize=12, fontweight='bold', color='blue'\n",
        "        )\n",
        "        axes[row_idx, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 8. Ø§Ø®ØªÙŠØ§Ø± Ø¹ÙŠÙ†Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù†ØªØµÙ\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"ğŸ² Ø§Ø®ØªÙŠØ§Ø± {NUM_SAMPLES} Ø¹ÙŠÙ†Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù…Ù† Ù…Ù†ØªØµÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ØªØ­Ø¯ÙŠØ¯ Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ù†ØªØµÙ (25% Ø¥Ù„Ù‰ 75%)\n",
        "start_slice = int(num_slices * 0.25)\n",
        "end_slice = int(num_slices * 0.75)\n",
        "\n",
        "print(f\"Ù†Ø·Ø§Ù‚ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±: Ù…Ù† Ø´Ø±ÙŠØ­Ø© {start_slice} Ø¥Ù„Ù‰ {end_slice}\")\n",
        "\n",
        "# Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ù…Ù†ØªØµÙ\n",
        "random.seed(42)\n",
        "middle_range = list(range(start_slice, end_slice))\n",
        "selected_slices = sorted(random.sample(middle_range, min(NUM_SAMPLES, len(middle_range))))\n",
        "\n",
        "print(f\"Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©: {selected_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 9. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "# ============================\n",
        "visualize_predictions_separate(\n",
        "    model, volumes, labels, selected_slices,\n",
        "    MODALITIES, NUM_CLASSES,\n",
        "    save_path=os.path.join(RESULTS_DIR, 'test_separate_samples.png')\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 10. ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for slice_idx in selected_slices:\n",
        "    pred_mask = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "    slice_metrics = calculate_metrics(true_mask, pred_mask, NUM_CLASSES)\n",
        "\n",
        "    print(f\"\\nSlice {slice_idx}:\")\n",
        "    print(f\"  Accuracy: {slice_metrics['accuracy']:.4f} ({slice_metrics['accuracy']*100:.2f}%)\")\n",
        "    print(f\"  Mean IoU: {slice_metrics['mean_iou']:.4f}\")\n",
        "    print(f\"  Mean Dice: {slice_metrics['mean_dice']:.4f}\")\n",
        "\n",
        "# ============================\n",
        "# 11. ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š Ù‡Ù„ ØªØ±ÙŠØ¯ ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ØŸ\")\n",
        "print(\"=\"*60)\n",
        "print(\"ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ:\")\n",
        "print(\"\"\"\n",
        "all_true = []\n",
        "all_pred = []\n",
        "\n",
        "print(\"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­...\")\n",
        "for slice_idx in range(num_slices):\n",
        "    if (slice_idx + 1) % 10 == 0:\n",
        "        print(f\"   Ù…Ø¹Ø§Ù„Ø¬Ø© {slice_idx + 1}/{num_slices}...\")\n",
        "\n",
        "    pred_mask = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "    all_true.append(true_mask.flatten())\n",
        "    all_pred.append(pred_mask.flatten())\n",
        "\n",
        "all_true = np.concatenate(all_true)\n",
        "all_pred = np.concatenate(all_pred)\n",
        "\n",
        "overall_metrics = calculate_metrics(all_true, all_pred, NUM_CLASSES)\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ˆ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Overall Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
        "print(f\"Mean IoU: {overall_metrics['mean_iou']:.4f}\")\n",
        "print(f\"Mean Dice: {overall_metrics['mean_dice']:.4f}\")\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nğŸ“ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸: test_separate_samples.png\")\n",
        "print(f\"ğŸ“‚ Ø§Ù„Ù…Ø³Ø§Ø±: {RESULTS_DIR}\")\n",
        "\n",
        "# ============================\n",
        "# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "# ============================\n",
        "\n",
        "# 1. Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù„Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø³Ø±ÙŠØ¹)\n",
        "print(\"ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...\")\n",
        "volumes_test, labels_test = test_pipeline.load_test_data()\n",
        "\n",
        "# Ø¹Ø±Ø¶ 8 Ø´Ø±Ø§Ø¦Ø­ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©\n",
        "import random\n",
        "random_slices = random.sample(range(labels_test.shape[2]), 8)\n",
        "test_pipeline.visualize_predictions(\n",
        "    volumes_test,\n",
        "    labels_test,\n",
        "    random_slices,\n",
        "    save_path=os.path.join(config.OUTPUT_DIR, 'test_predictions.png')\n",
        ")\n",
        "\n",
        "# ØªÙ‚ÙŠÙŠÙ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­\n",
        "metrics = test_pipeline.evaluate_all_slices(volumes_test, labels_test)\n",
        "\n",
        "# 2. Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ø¬Ù„Ø¯ Ø¢Ø®Ø±\n",
        "test_dir = \"/content/drive/MyDrive/seg3Data_test\"  # Ø¶Ø¹ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
        "\n",
        "volumes_new, labels_new = test_pipeline.load_test_data(test_dir)\n",
        "\n",
        "# Ø§Ø®ØªØ± Ø´Ø±Ø§Ø¦Ø­ Ù…Ø¹ÙŠÙ†Ø© Ù„Ù„Ø¹Ø±Ø¶\n",
        "slices_to_show = [10, 15, 20, 25, 30, 35, 40, 45]\n",
        "test_pipeline.visualize_predictions(\n",
        "    volumes_new,\n",
        "    labels_new,\n",
        "    slices_to_show,\n",
        "    save_path=os.path.join(config.OUTPUT_DIR, 'new_test_predictions.png')\n",
        ")\n",
        "\n",
        "# ØªÙ‚ÙŠÙŠÙ… ÙƒØ§Ù…Ù„\n",
        "metrics_new = test_pipeline.evaluate_all_slices(volumes_new, labels_new)"
      ],
      "metadata": {
        "id": "efG1fYcSffpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3D with VTK**"
      ],
      "metadata": {
        "id": "kEtDS-V-GJkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹Ø±Ø¶ 3D Ù…Ø­Ø³Ù‘Ù†\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import plotly.graph_objects as go\n",
        "from skimage import measure\n",
        "from scipy import ndimage\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹Ø±Ø¶ 3D Ù…Ø­Ø³Ù‘Ù†\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
        "# ============================\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data/seg3Data_test\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Seg3Data/results/final_model.h5\" # Updated path\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "IMAGE_HEIGHT = 240\n",
        "IMAGE_WIDTH = 240\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ù„Ù„Ø¹Ø±Ø¶ 3D\n",
        "NUM_SLICES_3D = 24\n",
        "\n",
        "print(f\"\\nğŸ“ Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {TEST_DATA_DIR}\")\n",
        "print(f\"ğŸ¤– Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_PATH}\")\n",
        "\n",
        "# ============================\n",
        "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "\n",
        "# ============================\n",
        "# 3. Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©\n",
        "# ============================\n",
        "def load_nifti_file(filepath):\n",
        "    if not os.path.exists(filepath):\n",
        "        if os.path.exists(filepath.replace('.nii.gz', '.nii')):\n",
        "            filepath = filepath.replace('.nii.gz', '.nii')\n",
        "        elif os.path.exists(filepath.replace('.nii', '.nii.gz')):\n",
        "            filepath = filepath.replace('.nii', '.nii.gz')\n",
        "    nii = nib.load(filepath)\n",
        "    return nii.get_fdata()\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    volume = volume.astype(np.float32)\n",
        "    mean = np.mean(volume[volume > 0])\n",
        "    std = np.std(volume[volume > 0])\n",
        "    if std > 0:\n",
        "        volume = (volume - mean) / std\n",
        "    return volume\n",
        "\n",
        "# ============================\n",
        "# 4. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "volumes = {}\n",
        "for modality in MODALITIES:\n",
        "    filepath = os.path.join(TEST_DATA_DIR, modality + '.nii')\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath = os.path.join(TEST_DATA_DIR, modality + '.nii.gz')\n",
        "\n",
        "    print(f\"   ØªØ­Ù…ÙŠÙ„ {modality}...\")\n",
        "    volume = load_nifti_file(filepath)\n",
        "    volume = normalize_volume(volume)\n",
        "    volumes[modality] = volume\n",
        "\n",
        "label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii')\n",
        "if not os.path.exists(label_filepath):\n",
        "    label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii.gz')\n",
        "\n",
        "labels = load_nifti_file(label_filepath).astype(np.int32)\n",
        "num_slices = labels.shape[2]\n",
        "print(f\"\\nâœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {num_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 5. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "# ============================\n",
        "def predict_slice(model, volumes, slice_idx, modalities):\n",
        "    X = np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, len(modalities)), dtype=np.float32)\n",
        "    for j, modality in enumerate(modalities):\n",
        "        X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "    pred = model.predict(X, verbose=0)\n",
        "    return np.argmax(pred[0], axis=-1)\n",
        "\n",
        "# ============================\n",
        "# 6. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø´Ø±Ø§Ø¦Ø­ Ù…ØªØªØ§Ù„ÙŠØ©\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ {NUM_SLICES_3D} Ø´Ø±ÙŠØ­Ø© Ù…ØªØªØ§Ù„ÙŠØ©...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_slice = 0\n",
        "end_slice = start_slice + NUM_SLICES_3D\n",
        "\n",
        "if end_slice > num_slices:\n",
        "    end_slice = num_slices\n",
        "    start_slice = end_slice - NUM_SLICES_3D\n",
        "\n",
        "print(f\"Ù†Ø·Ø§Ù‚ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {start_slice} Ø¥Ù„Ù‰ {end_slice}\")\n",
        "\n",
        "# Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©\n",
        "pred_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "true_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "\n",
        "print(\"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤...\")\n",
        "for i, slice_idx in enumerate(range(start_slice, end_slice)):\n",
        "    print(f\"   {i+1}/{NUM_SLICES_3D}\")\n",
        "    pred_volume[:, :, i] = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_volume[:, :, i] = labels[:, :, slice_idx]\n",
        "\n",
        "print(\"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤!\")\n",
        "\n",
        "# ============================\n",
        "# 7. Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ 3D Ù…Ø­Ø³Ù‘Ù†Ø© Ø¨Ù†Ù…Ø· VTK (Surface Rendering)\n",
        "# ============================\n",
        "def visualize_3d_surface(volume, title, save_path=None, colors=None):\n",
        "    \"\"\"Ø¹Ø±Ø¶ 3D Ø¨Ù†Ù…Ø· Surface Rendering Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù€ VTK\"\"\"\n",
        "\n",
        "    if colors is None:\n",
        "        colors = {\n",
        "            1: [1.0, 0.0, 0.0],    # Ø£Ø­Ù…Ø±\n",
        "            2: [0.0, 1.0, 0.0],    # Ø£Ø®Ø¶Ø±\n",
        "            3: [0.0, 0.5, 1.0]     # Ø£Ø²Ø±Ù‚ Ø³Ù…Ø§ÙˆÙŠ\n",
        "        }\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ©\n",
        "    ax.set_facecolor('black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    # Ø±Ø³Ù… ÙƒÙ„ class ÙƒØ³Ø·Ø­ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\n",
        "    for class_id in range(1, NUM_CLASSES):\n",
        "        print(f\"   Ù…Ø¹Ø§Ù„Ø¬Ø© Class {class_id}...\")\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ mask Ù„Ù‡Ø°Ø§ Ø§Ù„Ù€ class\n",
        "        class_mask = (volume == class_id).astype(np.float32)\n",
        "\n",
        "        if np.any(class_mask):\n",
        "            try:\n",
        "                # Ø§Ø³ØªØ®Ø¯Ø§Ù… marching cubes Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø·Ø­ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\n",
        "                verts, faces, normals, values = measure.marching_cubes(\n",
        "                    class_mask,\n",
        "                    level=0.5,\n",
        "                    spacing=(1.0, 1.0, 1.0)\n",
        "                )\n",
        "\n",
        "                # Ø¥Ù†Ø´Ø§Ø¡ mesh collection\n",
        "                mesh = Poly3DCollection(verts[faces], alpha=0.7)\n",
        "                mesh.set_facecolor(colors.get(class_id, [1, 1, 1]))\n",
        "                mesh.set_edgecolor('none')\n",
        "                ax.add_collection3d(mesh)\n",
        "\n",
        "                print(f\"      âœ“ ØªÙ… Ø±Ø³Ù… {len(faces)} Ù…Ø¶Ù„Ø¹\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"      âš  Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Class {class_id}: {e}\")\n",
        "\n",
        "    # Ø¶Ø¨Ø· Ø§Ù„Ù…Ø­Ø§ÙˆØ±\n",
        "    ax.set_xlabel('X', color='white', fontsize=12)\n",
        "    ax.set_ylabel('Y', color='white', fontsize=12)\n",
        "    ax.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "\n",
        "    # Ø¶Ø¨Ø· Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø­Ø§ÙˆØ±\n",
        "    ax.set_xlim([0, volume.shape[1]])\n",
        "    ax.set_ylim([0, volume.shape[0]])\n",
        "    ax.set_zlim([0, volume.shape[2]])\n",
        "\n",
        "    # ØªØ®ØµÙŠØµ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø­Ø§ÙˆØ± ÙˆØ§Ù„Ø´Ø¨ÙƒØ©\n",
        "    ax.xaxis.pane.fill = False\n",
        "    ax.yaxis.pane.fill = False\n",
        "    ax.zaxis.pane.fill = False\n",
        "    ax.xaxis.pane.set_edgecolor('gray')\n",
        "    ax.yaxis.pane.set_edgecolor('gray')\n",
        "    ax.zaxis.pane.set_edgecolor('gray')\n",
        "    ax.grid(color='gray', alpha=0.3)\n",
        "\n",
        "    # ØªØºÙŠÙŠØ± Ø£Ù„ÙˆØ§Ù† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙˆØ±\n",
        "    ax.tick_params(colors='white')\n",
        "\n",
        "    # Ø¶Ø¨Ø· Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¹Ø±Ø¶\n",
        "    ax.view_init(elev=25, azim=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='black')\n",
        "        print(f\"âœ… ØªÙ… Ø­ÙØ¸: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 8. Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ Volume Rendering Ø¨Ø§Ù„Ø£Ù„ÙˆØ§Ù†\n",
        "# ============================\n",
        "def visualize_3d_volume_slices(volume, title, save_path=None, colors=None):\n",
        "    \"\"\"Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ ÙƒØ·Ø¨Ù‚Ø§Øª Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù„ÙˆÙ†Ø©\"\"\"\n",
        "\n",
        "    if colors is None:\n",
        "        colors = {\n",
        "            1: [1.0, 0.0, 0.0],\n",
        "            2: [0.0, 1.0, 0.0],\n",
        "            3: [0.0, 0.5, 1.0]\n",
        "        }\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    ax.set_facecolor('black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    # Ø±Ø³Ù… ÙƒÙ„ Ø´Ø±ÙŠØ­Ø© ÙƒØ·Ø¨Ù‚Ø©\n",
        "    step = max(1, NUM_SLICES_3D // 12)  # Ø¹Ø±Ø¶ 12 Ø´Ø±ÙŠØ­Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰\n",
        "\n",
        "    for z_idx in range(0, volume.shape[2], step):\n",
        "        slice_data = volume[:, :, z_idx]\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ mesh grid Ù„Ù„Ø´Ø±ÙŠØ­Ø©\n",
        "        x = np.arange(0, slice_data.shape[1])\n",
        "        y = np.arange(0, slice_data.shape[0])\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        Z = np.ones_like(X) * z_idx\n",
        "\n",
        "        # ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø­Ø³Ø¨ Ø§Ù„Ù€ classes\n",
        "        colors_array = np.zeros((slice_data.shape[0], slice_data.shape[1], 4))\n",
        "\n",
        "        for class_id in range(1, NUM_CLASSES):\n",
        "            mask = (slice_data == class_id)\n",
        "            if np.any(mask):\n",
        "                color = colors.get(class_id, [1, 1, 1])\n",
        "                colors_array[mask] = [*color, 0.6]\n",
        "\n",
        "        # Ø±Ø³Ù… Ø§Ù„Ø³Ø·Ø­\n",
        "        ax.plot_surface(X, Y, Z, facecolors=colors_array,\n",
        "                       shade=False, linewidth=0, antialiased=True)\n",
        "\n",
        "    # Ø¶Ø¨Ø· Ø§Ù„Ù…Ø­Ø§ÙˆØ±\n",
        "    ax.set_xlabel('X', color='white', fontsize=12)\n",
        "    ax.set_ylabel('Y', color='white', fontsize=12)\n",
        "    ax.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "\n",
        "    ax.set_xlim([0, volume.shape[1]])\n",
        "    ax.set_ylim([0, volume.shape[0]])\n",
        "    ax.set_zlim([0, volume.shape[2]])\n",
        "\n",
        "    ax.xaxis.pane.fill = False\n",
        "    ax.yaxis.pane.fill = False\n",
        "    ax.zaxis.pane.fill = False\n",
        "    ax.xaxis.pane.set_edgecolor('gray')\n",
        "    ax.yaxis.pane.set_edgecolor('gray')\n",
        "    ax.zaxis.pane.set_edgecolor('gray')\n",
        "    ax.grid(color='gray', alpha=0.3)\n",
        "    ax.tick_params(colors='white')\n",
        "\n",
        "    ax.view_init(elev=25, azim=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='black')\n",
        "        print(f\"âœ… ØªÙ… Ø­ÙØ¸: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 9. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙÙ‚Ø· (Ground Truth Ùˆ Prediction)\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¨ Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø© 3D...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ø£Ù„ÙˆØ§Ù† ØºØ§Ù…Ù‚Ø©\n",
        "dark_colors = {\n",
        "    1: [0.7, 0.0, 0.0],    # Ø£Ø­Ù…Ø± ØºØ§Ù…Ù‚\n",
        "    2: [0.0, 0.5, 0.0],    # Ø£Ø®Ø¶Ø± ØºØ§Ù…Ù‚\n",
        "    3: [0.0, 0.2, 0.6]     # Ø£Ø²Ø±Ù‚ ØºØ§Ù…Ù‚\n",
        "}\n",
        "\n",
        "fig = plt.figure(figsize=(24, 10))\n",
        "fig.patch.set_facecolor('black')\n",
        "\n",
        "# Ground Truth Surface\n",
        "print(\"\\nğŸ“Š Ù…Ø¹Ø§Ù„Ø¬Ø© Ground Truth...\")\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.set_facecolor('black')\n",
        "\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (true_volume == class_id).astype(np.float32)\n",
        "    if np.any(class_mask):\n",
        "        try:\n",
        "            print(f\"   Ù…Ø¹Ø§Ù„Ø¬Ø© Class {class_id}...\")\n",
        "            verts, faces, _, _ = measure.marching_cubes(class_mask, level=0.5)\n",
        "            mesh = Poly3DCollection(verts[faces], alpha=0.8)\n",
        "            mesh.set_facecolor(dark_colors.get(class_id, [0.5, 0.5, 0.5]))\n",
        "            mesh.set_edgecolor('none')\n",
        "            ax1.add_collection3d(mesh)\n",
        "            print(f\"      âœ“ ØªÙ… Ø±Ø³Ù… {len(faces)} Ù…Ø¶Ù„Ø¹\")\n",
        "        except Exception as e:\n",
        "            print(f\"      âš  Ø®Ø·Ø£: {e}\")\n",
        "\n",
        "ax1.set_xlim([0, true_volume.shape[1]])\n",
        "ax1.set_ylim([0, true_volume.shape[0]])\n",
        "ax1.set_zlim([0, true_volume.shape[2]])\n",
        "ax1.set_title('Ground Truth', fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "ax1.set_xlabel('X', color='white', fontsize=12)\n",
        "ax1.set_ylabel('Y', color='white', fontsize=12)\n",
        "ax1.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "ax1.xaxis.pane.fill = False\n",
        "ax1.yaxis.pane.fill = False\n",
        "ax1.zaxis.pane.fill = False\n",
        "ax1.xaxis.pane.set_edgecolor('gray')\n",
        "ax1.yaxis.pane.set_edgecolor('gray')\n",
        "ax1.zaxis.pane.set_edgecolor('gray')\n",
        "ax1.grid(color='gray', alpha=0.3)\n",
        "ax1.tick_params(colors='white')\n",
        "ax1.view_init(elev=25, azim=45)\n",
        "\n",
        "# Prediction Surface\n",
        "print(\"\\nğŸ“Š Ù…Ø¹Ø§Ù„Ø¬Ø© Model Prediction...\")\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "ax2.set_facecolor('black')\n",
        "\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (pred_volume == class_id).astype(np.float32)\n",
        "    if np.any(class_mask):\n",
        "        try:\n",
        "            print(f\"   Ù…Ø¹Ø§Ù„Ø¬Ø© Class {class_id}...\")\n",
        "            verts, faces, _, _ = measure.marching_cubes(class_mask, level=0.5)\n",
        "            mesh = Poly3DCollection(verts[faces], alpha=0.8)\n",
        "            mesh.set_facecolor(dark_colors.get(class_id, [0.5, 0.5, 0.5]))\n",
        "            mesh.set_edgecolor('none')\n",
        "            ax2.add_collection3d(mesh)\n",
        "            print(f\"      âœ“ ØªÙ… Ø±Ø³Ù… {len(faces)} Ù…Ø¶Ù„Ø¹\")\n",
        "        except Exception as e:\n",
        "            print(f\"      âš  Ø®Ø·Ø£: {e}\")\n",
        "\n",
        "ax2.set_xlim([0, pred_volume.shape[1]])\n",
        "ax2.set_ylim([0, pred_volume.shape[0]])\n",
        "ax2.set_zlim([0, pred_volume.shape[2]])\n",
        "ax2.set_title('Model Prediction', fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "ax2.set_xlabel('X', color='white', fontsize=12)\n",
        "ax2.set_ylabel('Y', color='white', fontsize=12)\n",
        "ax2.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "ax2.xaxis.pane.fill = False\n",
        "ax2.yaxis.pane.fill = False\n",
        "ax2.zaxis.pane.fill = False\n",
        "ax2.xaxis.pane.set_edgecolor('gray')\n",
        "ax2.yaxis.pane.set_edgecolor('gray')\n",
        "ax2.zaxis.pane.set_edgecolor('gray')\n",
        "ax2.grid(color='gray', alpha=0.3)\n",
        "ax2.tick_params(colors='white')\n",
        "ax2.view_init(elev=25, azim=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = os.path.join(RESULTS_DIR, '3d_comparison.png')\n",
        "plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='black')\n",
        "print(f\"\\nâœ… ØªÙ… Ø­ÙØ¸: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¹Ø±Ø¶ 3D!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nğŸ“ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸:\")\n",
        "print(f\"  - 3d_comparison.png\")\n",
        "print(f\"ğŸ“‚ Ø§Ù„Ù…Ø³Ø§Ø±: {RESULTS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "d3nYct9zGExG",
        "outputId": "1960acad-37c8-4a42-b99d-eda90104bb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹Ø±Ø¶ 3D Ù…Ø­Ø³Ù‘Ù†\n",
            "============================================================\n",
            "\n",
            "ğŸ“ Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: /content/drive/MyDrive/Seg3Data/seg3Data_test\n",
            "ğŸ¤– Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: /content/drive/MyDrive/Seg3Data/results/final_model.h5\n",
            "\n",
            "============================================================\n",
            "ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3803793664.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3**D predection**"
      ],
      "metadata": {
        "id": "ngwSKyqk_tXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹Ø±Ø¶ 3D\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "import random\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹Ø±Ø¶ 3D\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
        "# ============================\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data/seg3Data_test\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Seg3Data/results/final_model.h5\" # Corrected path to the final model\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "IMAGE_HEIGHT = 240\n",
        "IMAGE_WIDTH = 240\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ù„Ù„Ø¹Ø±Ø¶ 3D\n",
        "NUM_SLICES_3D = 24 # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡Ø§\n",
        "\n",
        "print(f\"\\nğŸ“ Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {TEST_DATA_DIR}\")\n",
        "print(f\"ğŸ¤– Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_PATH}\")\n",
        "\n",
        "# ============================\n",
        "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "\n",
        "# ============================\n",
        "# 3. Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©\n",
        "# ============================\n",
        "def load_nifti_file(filepath):\n",
        "    if not os.path.exists(filepath):\n",
        "        if os.path.exists(filepath.replace('.nii.gz', '.nii')):\n",
        "            filepath = filepath.replace('.nii.gz', '.nii')\n",
        "        elif os.path.exists(filepath.replace('.nii', '.nii.gz')):\n",
        "            filepath = filepath.replace('.nii', '.nii.gz')\n",
        "    nii = nib.load(filepath)\n",
        "    return nii.get_fdata()\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    volume = volume.astype(np.float32)\n",
        "    mean = np.mean(volume[volume > 0])\n",
        "    std = np.std(volume[volume > 0])\n",
        "    if std > 0:\n",
        "        volume = (volume - mean) / std\n",
        "    return volume\n",
        "\n",
        "# ============================\n",
        "# 4. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "volumes = {}\n",
        "for modality in MODALITIES:\n",
        "    filepath = os.path.join(TEST_DATA_DIR, modality + '.nii')\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath = os.path.join(TEST_DATA_DIR, modality + '.nii.gz')\n",
        "\n",
        "    print(f\"   ØªØ­Ù…ÙŠÙ„ {modality}...\")\n",
        "    volume = load_nifti_file(filepath)\n",
        "    volume = normalize_volume(volume)\n",
        "    volumes[modality] = volume\n",
        "\n",
        "label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii')\n",
        "if not os.path.exists(label_filepath):\n",
        "    label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii.gz')\n",
        "\n",
        "labels = load_nifti_file(label_filepath).astype(np.int32)\n",
        "num_slices = labels.shape[2]\n",
        "print(f\"\\nâœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {num_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 5. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "# ============================\n",
        "def predict_slice(model, volumes, slice_idx, modalities):\n",
        "    X = np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, len(modalities)), dtype=np.float32)\n",
        "    for j, modality in enumerate(modalities):\n",
        "        X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "    pred = model.predict(X, verbose=0)\n",
        "    return np.argmax(pred[0], axis=-1)\n",
        "\n",
        "# ============================\n",
        "# 6. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø´Ø±Ø§Ø¦Ø­ Ù…ØªØªØ§Ù„ÙŠØ©\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ {NUM_SLICES_3D} Ø´Ø±ÙŠØ­Ø© Ù…ØªØªØ§Ù„ÙŠØ©...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_slice = 0\n",
        "end_slice = start_slice + NUM_SLICES_3D\n",
        "\n",
        "if end_slice > num_slices:\n",
        "    end_slice = num_slices\n",
        "    start_slice = end_slice - NUM_SLICES_3D\n",
        "\n",
        "print(f\"Ù†Ø·Ø§Ù‚ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­: {start_slice} Ø¥Ù„Ù‰ {end_slice}\")\n",
        "\n",
        "# Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©\n",
        "pred_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "true_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "\n",
        "print(\"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤...\")\n",
        "for i, slice_idx in enumerate(range(start_slice, end_slice)):\n",
        "    print(f\"   {i+1}/{NUM_SLICES_3D}\")\n",
        "    pred_volume[:, :, i] = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_volume[:, :, i] = labels[:, :, slice_idx]\n",
        "\n",
        "print(\"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤!\")\n",
        "\n",
        "# ============================\n",
        "# 7. Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ 3D Ù…Ø¹ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ label\n",
        "# ============================\n",
        "def visualize_3d_segmentation(volume, title, save_path=None, colors=None):\n",
        "    \"\"\"Ø¹Ø±Ø¶ 3D Ù„Ù„Ù€ segmentation Ù…Ø¹ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªÙ„ÙØ©\"\"\"\n",
        "\n",
        "    # Ø£Ù„ÙˆØ§Ù† Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ÙƒÙ„ class\n",
        "    if colors is None:\n",
        "        colors = {\n",
        "            0: [0, 0, 0, 0],          # Background - Ø´ÙØ§Ù\n",
        "            1: [1, 0, 0, 0.3],        # Class 1 - Ø£Ø­Ù…Ø±\n",
        "            2: [0, 1, 0, 0.3],        # Class 2 - Ø£Ø®Ø¶Ø±\n",
        "            3: [0, 0, 1, 0.3]         # Class 3 - Ø£Ø²Ø±Ù‚\n",
        "        }\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 10))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Ø±Ø³Ù… ÙƒÙ„ class Ø¨Ù„ÙˆÙ† Ù…Ø®ØªÙ„Ù\n",
        "    for class_id in range(1, NUM_CLASSES):  # Ù†Ø¨Ø¯Ø£ Ù…Ù† 1 (Ù†ØªØ¬Ø§Ù‡Ù„ background)\n",
        "        # Ø¥ÙŠØ¬Ø§Ø¯ Ù…ÙˆØ§Ø¶Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ù€ class\n",
        "        class_mask = (volume == class_id)\n",
        "\n",
        "        if np.any(class_mask):\n",
        "            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª\n",
        "            z, y, x = np.where(class_mask)\n",
        "\n",
        "            # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø·\n",
        "            color = colors.get(class_id, [1, 1, 1, 0.3])\n",
        "            ax.scatter(x, y, z,\n",
        "                      c=[color[:3]],\n",
        "                      alpha=color[3],\n",
        "                      s=0.5,  # Ø­Ø¬Ù… Ø§Ù„Ù†Ù‚Ø·Ø©\n",
        "                      label=f'Class {class_id}')\n",
        "\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Z (Slices)')\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.legend()\n",
        "\n",
        "    # Ø¶Ø¨Ø· Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¹Ø±Ø¶\n",
        "    ax.view_init(elev=20, azim=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"âœ… ØªÙ… Ø­ÙØ¸: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 8. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© 3D\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¨ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø´ÙƒÙ„ 3D...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ØªØ¹Ø±ÙŠÙ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØµØµØ© Ù„ÙƒÙ„ class\n",
        "custom_colors = {\n",
        "    0: [0, 0, 0, 0],           # Background - Ø´ÙØ§Ù\n",
        "    1: [1, 0, 0, 0.4],         # Class 1 - Ø£Ø­Ù…Ø± ÙØ§ØªØ­\n",
        "    2: [0, 1, 0, 0.4],         # Class 2 - Ø£Ø®Ø¶Ø± ÙØ§ØªØ­\n",
        "    3: [0, 0.5, 1, 0.4]        # Class 3 - Ø£Ø²Ø±Ù‚ Ø³Ù…Ø§ÙˆÙŠ\n",
        "}\n",
        "\n",
        "# Ø¹Ø±Ø¶ Ground Truth\n",
        "print(\"\\nğŸ“Š Ø¹Ø±Ø¶ Ground Truth...\")\n",
        "visualize_3d_segmentation(\n",
        "    true_volume,\n",
        "    'Ground Truth - 3D Segmentation',\n",
        "    save_path=os.path.join(RESULTS_DIR, '3d_ground_truth.png'),\n",
        "    colors=custom_colors\n",
        ")\n",
        "\n",
        "# Ø¹Ø±Ø¶ Prediction\n",
        "print(\"\\nğŸ“Š Ø¹Ø±Ø¶ Model Prediction...\")\n",
        "visualize_3d_segmentation(\n",
        "    pred_volume,\n",
        "    'Model Prediction - 3D Segmentation',\n",
        "    save_path=os.path.join(RESULTS_DIR, '3d_prediction.png'),\n",
        "    colors=custom_colors\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 9. Ø¹Ø±Ø¶ Ø¬Ù†Ø¨ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
        "# ============================\n",
        "print(\"\\nğŸ“Š Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¬Ù†Ø¨ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨...\")\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Ground Truth\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (true_volume == class_id)\n",
        "    if np.any(class_mask):\n",
        "        z, y, x = np.where(class_mask)\n",
        "        color = custom_colors.get(class_id, [1, 1, 1, 0.3])\n",
        "        ax1.scatter(x, y, z, c=[color[:3]], alpha=color[3], s=0.5, label=f'Class {class_id}')\n",
        "\n",
        "ax1.set_title('Ground Truth', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('X')\n",
        "ax1.set_ylabel('Y')\n",
        "ax1.set_zlabel('Z')\n",
        "ax1.legend()\n",
        "ax1.view_init(elev=20, azim=45)\n",
        "\n",
        "# Prediction\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (pred_volume == class_id)\n",
        "    if np.any(class_mask):\n",
        "        z, y, x = np.where(class_mask)\n",
        "        color = custom_colors.get(class_id, [1, 1, 1, 0.3])\n",
        "        ax2.scatter(x, y, z, c=[color[:3]], alpha=color[3], s=0.5, label=f'Class {class_id}')\n",
        "\n",
        "ax2.set_title('Model Prediction', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('X')\n",
        "ax2.set_ylabel('Y')\n",
        "ax2.set_zlabel('Z')\n",
        "ax2.legend()\n",
        "ax2.view_init(elev=20, azim=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, '3d_comparison.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¹Ø±Ø¶ 3D!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©:\")\n",
        "print(f\"  - 3d_ground_truth.png\")\n",
        "print(f\"  - 3d_prediction.png\")\n",
        "print(f\"  - 3d_comparison.png\")\n",
        "print(f\"ğŸ“‚ Ø§Ù„Ù…Ø³Ø§Ø±: {RESULTS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "iQNQc_hc_tEh",
        "outputId": "e79e7fac-95fe-4491-e49b-bd9f7db33aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ§ª Ø®Ù„ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹Ø±Ø¶ 3D\n",
            "============================================================\n",
            "\n",
            "ğŸ“ Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: /content/drive/MyDrive/Seg3Data/seg3Data_test\n",
            "ğŸ¤– Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: /content/drive/MyDrive/Seg3Data/results/final_model.h5\n",
            "\n",
            "============================================================\n",
            "ğŸ¤– ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1744657017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import plotly.graph_objects as go\n",
        "from skimage import measure\n",
        "from scipy import ndimage\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "from tensorflow.keras.models import load_model # Import load_model here\n",
        "from mpl_toolkits.mplot3d import Axes3D # Import Axes3D here\n",
        "from matplotlib import pyplot as plt # Import pyplot here\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection # Import Poly3DCollection\n",
        "\n",
        "# ============================\n",
        "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„Ù‡Ø§ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©)\n",
        "# ============================\n",
        "# !pip install plotly scikit-image ipywidgets\n",
        "\n",
        "class Brain3DVisualizer:\n",
        "    \"\"\"ÙØ¦Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ø³Ø·Ø­ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù„Ø¯Ù…Ø§Øº\"\"\"\n",
        "\n",
        "    def __init__(self, segmentation_volume):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        segmentation_volume : numpy array\n",
        "            Ø­Ø¬Ù… Ø§Ù„Ù€ segmentation (3D array) Ù…Ø¹ Ù‚ÙŠÙ… Ø§Ù„Ù€ classes\n",
        "        \"\"\"\n",
        "        self.volume = segmentation_volume\n",
        "        self.unique_classes = np.unique(segmentation_volume)\n",
        "        self.surfaces = {}\n",
        "        self.colors = {}\n",
        "        self.fig = None\n",
        "\n",
        "        # Ø£Ù„ÙˆØ§Ù† Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ÙƒÙ„ class\n",
        "        self.default_colors = {\n",
        "            0: 'rgba(0,0,0,0)',      # Background (Ø´ÙØ§Ù)\n",
        "            1: 'rgb(255,0,0)',        # Ø£Ø­Ù…Ø±\n",
        "            2: 'rgb(0,255,0)',        # Ø£Ø®Ø¶Ø±\n",
        "            3: 'rgb(0,0,255)',        # Ø£Ø²Ø±Ù‚\n",
        "        }\n",
        "\n",
        "    def extract_surface(self, class_id, step_size=2, smooth=True):\n",
        "        \"\"\"\n",
        "        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù€ class Ù…Ø¹ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Marching Cubes\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        class_id : int\n",
        "            Ø±Ù‚Ù… Ø§Ù„Ù€ class Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø·Ø­Ù‡\n",
        "        step_size : int\n",
        "            Ø®Ø·ÙˆØ© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ (Ø£ÙƒØ¨Ø± = Ø£Ø³Ø±Ø¹ Ù„ÙƒÙ† Ø£Ù‚Ù„ Ø¯Ù‚Ø©)\n",
        "        smooth : bool\n",
        "            ØªØ·Ø¨ÙŠÙ‚ smoothing Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¬Ù… Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬\n",
        "        \"\"\"\n",
        "        print(f\"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­ Ù„Ù„Ù€ class {class_id}...\")\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ binary mask Ù„Ù„Ù€ class\n",
        "        binary_mask = (self.volume == class_id).astype(np.uint8)\n",
        "\n",
        "        # ØªØ·Ø¨ÙŠÙ‚ smoothing Ø§Ø®ØªÙŠØ§Ø±ÙŠ\n",
        "        if smooth:\n",
        "            binary_mask = ndimage.gaussian_filter(binary_mask.astype(float), sigma=1)\n",
        "\n",
        "        try:\n",
        "            # Ø§Ø³ØªØ®Ø¯Ø§Ù… marching cubes Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­\n",
        "            verts, faces, normals, values = measure.marching_cubes(\n",
        "                binary_mask,\n",
        "                level=0.5,\n",
        "                step_size=step_size\n",
        "            )\n",
        "\n",
        "            self.surfaces[class_id] = {\n",
        "                'vertices': verts,\n",
        "                'faces': faces,\n",
        "                'normals': normals\n",
        "            }\n",
        "\n",
        "            print(f\"  âœ“ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(verts)} vertices Ùˆ {len(faces)} faces\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­: {e}\")\n",
        "            self.surfaces[class_id] = None\n",
        "\n",
        "    def extract_all_surfaces(self, step_size=2, smooth=True):\n",
        "        \"\"\"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø·Ø­ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ classes\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø·Ø­ Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for class_id in self.unique_classes:\n",
        "            if class_id == 0:  # ØªØ®Ø·ÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©\n",
        "                continue\n",
        "            self.extract_surface(class_id, step_size, smooth)\n",
        "\n",
        "        print(\"\\nâœ“ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø·Ø­!\")\n",
        "\n",
        "    def create_mesh_trace(self, class_id, color=None, opacity=1.0, visible=True):\n",
        "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ mesh trace Ù„Ù€ Plotly\"\"\"\n",
        "\n",
        "        if class_id not in self.surfaces or self.surfaces[class_id] is None:\n",
        "            return None\n",
        "\n",
        "        surface = self.surfaces[class_id]\n",
        "        verts = surface['vertices']\n",
        "        faces = surface['faces']\n",
        "\n",
        "        if color is None:\n",
        "            color = self.default_colors.get(class_id, 'rgb(128,128,128)')\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ Mesh3d trace\n",
        "        trace = go.Mesh3d(\n",
        "            x=verts[:, 0],\n",
        "            y=verts[:, 1],\n",
        "            z=verts[:, 2],\n",
        "            i=faces[:, 0],\n",
        "            j=faces[:, 1],\n",
        "            k=faces[:, 2],\n",
        "            color=color,\n",
        "            opacity=opacity,\n",
        "            name=f'Class {class_id}',\n",
        "            visible=visible,\n",
        "            hoverinfo='name',\n",
        "            lighting=dict(\n",
        "                ambient=0.5,\n",
        "                diffuse=0.8,\n",
        "                specular=0.2,\n",
        "                roughness=0.5\n",
        "            ),\n",
        "            lightposition=dict(\n",
        "                x=100,\n",
        "                y=200,\n",
        "                z=0\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return trace\n",
        "\n",
        "    def create_interactive_plot(self):\n",
        "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ traces Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ classes\n",
        "        traces = []\n",
        "        for class_id in self.unique_classes:\n",
        "            if class_id == 0:  # ØªØ®Ø·ÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©\n",
        "                continue\n",
        "\n",
        "            trace = self.create_mesh_trace(\n",
        "                class_id,\n",
        "                color=self.default_colors.get(class_id),\n",
        "                opacity=0.8,\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "            if trace is not None:\n",
        "                traces.append(trace)\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ Figure\n",
        "        self.fig = go.Figure(data=traces)\n",
        "\n",
        "        # ØªØ­Ø¯ÙŠØ« Layout\n",
        "        self.fig.update_layout(\n",
        "            title={\n",
        "                'text': 'ğŸ§  Brain Segmentation - 3D Interactive Visualization',\n",
        "                'x': 0.5,\n",
        "                'xanchor': 'center',\n",
        "                'font': {'size': 20, 'color': '#2c3e50'}\n",
        "            },\n",
        "            scene=dict(\n",
        "                xaxis=dict(title='X', backgroundcolor=\"rgb(230, 230,230)\"),\n",
        "                yaxis=dict(title='Y', backgroundcolor=\"rgb(230, 230,230)\"),\n",
        "                zaxis=dict(title='Z', backgroundcolor=\"rgb(230, 230,230)\"),\n",
        "                aspectmode='data',\n",
        "                camera=dict(\n",
        "                    eye=dict(x=1.5, y=1.5, z=1.5)\n",
        "                )\n",
        "            ),\n",
        "            width=1000,\n",
        "            height=800,\n",
        "            hovermode='closest',\n",
        "            showlegend=True,\n",
        "            legend=dict(\n",
        "                x=0.02,\n",
        "                y=0.98,\n",
        "                bgcolor='rgba(255,255,255,0.8)',\n",
        "                bordercolor='black',\n",
        "                borderwidth=1\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print(\"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ!\")\n",
        "\n",
        "        return self.fig\n",
        "\n",
        "    def show(self):\n",
        "        \"\"\"Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù…\"\"\"\n",
        "        if self.fig is None:\n",
        "            self.create_interactive_plot()\n",
        "        self.fig.show()\n",
        "\n",
        "    def create_control_widgets(self):\n",
        "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© ØªØ­ÙƒÙ… ØªÙØ§Ø¹Ù„ÙŠØ©\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if self.fig is None:\n",
        "            self.create_interactive_plot()\n",
        "\n",
        "        # Ù‚Ø§Ù…ÙˆØ³ Ù„Ø­ÙØ¸ Ø§Ù„Ù€ widgets\n",
        "        controls = {}\n",
        "\n",
        "        for i, class_id in enumerate(self.unique_classes):\n",
        "            if class_id == 0:  # ØªØ®Ø·ÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©\n",
        "                continue\n",
        "\n",
        "            print(f\"  Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†Ø§ØµØ± ØªØ­ÙƒÙ… Ù„Ù„Ù€ Class {class_id}\")\n",
        "\n",
        "            # Visibility toggle\n",
        "            visibility_toggle = widgets.Checkbox(\n",
        "                value=True,\n",
        "                description=f'Show Class {class_id}',\n",
        "                style={'description_width': 'initial'}\n",
        "            )\n",
        "\n",
        "            # Opacity slider\n",
        "            opacity_slider = widgets.FloatSlider(\n",
        "                value=0.8,\n",
        "                min=0.0,\n",
        "                max=1.0,\n",
        "                step=0.05,\n",
        "                description=f'Opacity {class_id}:',\n",
        "                style={'description_width': 'initial'}\n",
        "            )\n",
        "\n",
        "            # Color picker\n",
        "            color_picker = widgets.ColorPicker(\n",
        "                value=self.default_colors.get(class_id, '#808080'),\n",
        "                description=f'Color {class_id}:',\n",
        "                style={'description_width': 'initial'}\n",
        "            )\n",
        "\n",
        "            # Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ«\n",
        "            def update_trace(change, trace_idx=i):\n",
        "                vis = controls[trace_idx]['visibility'].value\n",
        "                opa = controls[trace_idx]['opacity'].value\n",
        "                col = controls[trace_idx]['color'].value\n",
        "\n",
        "                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ trace\n",
        "                with self.fig.batch_update():\n",
        "                    self.fig.data[trace_idx].visible = vis\n",
        "                    self.fig.data[trace_idx].opacity = opa\n",
        "                    self.fig.data[trace_idx].color = col\n",
        "\n",
        "            # Ø±Ø¨Ø· Ø§Ù„Ù€ widgets Ø¨Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ«\n",
        "            visibility_toggle.observe(update_trace, names='value')\n",
        "            opacity_slider.observe(update_trace, names='value')\n",
        "            color_picker.observe(update_trace, names='value')\n",
        "\n",
        "            # Ø­ÙØ¸ Ø§Ù„Ù€ widgets\n",
        "            controls[i] = {\n",
        "                'visibility': visibility_toggle,\n",
        "                'opacity': opacity_slider,\n",
        "                'color': color_picker\n",
        "            }\n",
        "\n",
        "        print(\"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªØ­ÙƒÙ…!\")\n",
        "\n",
        "        return controls\n",
        "\n",
        "    def display_interactive(self):\n",
        "        \"\"\"Ø¹Ø±Ø¶ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©\"\"\"\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ controls\n",
        "        controls = self.create_control_widgets()\n",
        "\n",
        "        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¹Ø±Ø¶\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ¨ Ø¹Ø±Ø¶ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nØ§Ø³ØªØ®Ø¯Ù… Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªØ­ÙƒÙ… Ø£Ø¯Ù†Ø§Ù‡ Ù„ØªØºÙŠÙŠØ±:\")\n",
        "        print(\"  â€¢ Ø§Ù„Ø±Ø¤ÙŠØ© (Show/Hide)\")\n",
        "        print(\"  â€¢ Ø§Ù„Ø´ÙØ§ÙÙŠØ© (Opacity)\")\n",
        "        print(\"  â€¢ Ø§Ù„Ù„ÙˆÙ† (Color)\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # Ø¹Ø±Ø¶ Ø§Ù„Ù€ controls\n",
        "        for i, control_set in controls.items():\n",
        "            box = widgets.VBox([\n",
        "                control_set['visibility'],\n",
        "                control_set['opacity'],\n",
        "                control_set['color'],\n",
        "                widgets.HTML(\"<hr style='margin:10px 0;'>\")\n",
        "            ])\n",
        "            display(box)\n",
        "\n",
        "        # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù…\n",
        "        display(self.fig)\n",
        "\n",
        "    def save_html(self, filepath):\n",
        "        \"\"\"Ø­ÙØ¸ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ ÙƒÙ…Ù„Ù HTML\"\"\"\n",
        "        if self.fig is None:\n",
        "            self.create_interactive_plot()\n",
        "\n",
        "        self.fig.write_html(filepath)\n",
        "        print(f\"\\nâœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ ÙÙŠ: {filepath}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…\n",
        "# ============================\n",
        "\n",
        "def visualize_segmentation_3d(segmentation_path, output_dir=None, step_size=2):\n",
        "    \"\"\"\n",
        "    Ø¯Ø§Ù„Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù€ segmentation Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    segmentation_path : str\n",
        "        Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù€ segmentation (NIfTI)\n",
        "    output_dir : str\n",
        "        Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
        "    step_size : int\n",
        "        Ø¯Ù‚Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­ (Ø£ØµØºØ± = Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ù„ÙƒÙ† Ø£Ø¨Ø·Ø£)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¹Ø±Ø¶ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù€ segmentation\n",
        "    print(f\"\\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {segmentation_path}\")\n",
        "    nii = nib.load(segmentation_path)\n",
        "    volume = nii.get_fdata().astype(np.int32)\n",
        "    print(f\"  âœ“ Ø§Ù„Ø­Ø¬Ù…: {volume.shape}\")\n",
        "    print(f\"  âœ“ Classes: {np.unique(volume)}\")\n",
        "\n",
        "    # Ø¥Ù†Ø´Ø§Ø¡ visualizer\n",
        "    viz = Brain3DVisualizer(volume)\n",
        "\n",
        "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø·Ø­\n",
        "    viz.extract_all_surfaces(step_size=step_size, smooth=True)\n",
        "\n",
        "    # Ø¹Ø±Ø¶ ØªÙØ§Ø¹Ù„ÙŠ\n",
        "    viz.display_interactive()\n",
        "\n",
        "    # Ø­ÙØ¸ HTML (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        html_path = os.path.join(output_dir, '3d_brain_visualization.html')\n",
        "        viz.save_html(html_path)\n",
        "\n",
        "    return viz\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "# ============================\n",
        "\n",
        "# Ø§Ø³ØªØ®Ø¯Ù… Ø¥Ù…Ø§ Ù…Ù„Ù Ø§Ù„Ù€ labels Ø§Ù„Ø£ØµÙ„ÙŠ Ø£Ùˆ Ø§Ù„Ù€ predictions\n",
        "# TODO: Verify this path and update if necessary\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data/seg3Data_test/\" # <--- VERIFY THIS PATH\n",
        "# TODO: Verify this file name and path and update if necessary\n",
        "SEGMENTATION_FILE = os.path.join(TEST_DATA_DIR, \"LabelsForTesting.nii\") # <--- VERIFY THIS FILE PATH\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "# ØªØ´ØºÙŠÙ„\n",
        "visualizer = visualize_segmentation_3d(\n",
        "    segmentation_path=SEGMENTATION_FILE,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    step_size=2  # Ø§Ø³ØªØ®Ø¯Ù… 1 Ù„Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø© (Ø£Ø¨Ø·Ø£)\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "KAX29vJ6iVIZ",
        "outputId": "e3b94e36-d121-4786-eea8-ecfe8874fa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¹Ø±Ø¶ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\n",
            "============================================================\n",
            "\n",
            "ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: /content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or no access: '/content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2837541299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;31m# ØªØ´ØºÙŠÙ„\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m visualizer = visualize_segmentation_3d(\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0msegmentation_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEGMENTATION_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2837541299.py\u001b[0m in \u001b[0;36mvisualize_segmentation_3d\u001b[0;34m(segmentation_path, output_dir, step_size)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù€ segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {segmentation_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0mnii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  âœ“ Ø§Ù„Ø­Ø¬Ù…: {volume.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No such file or no access: '{filename}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Empty file: '{filename}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Cv9ciM5jRqjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e035b5",
        "outputId": "d3f7f983-36bc-4c19-f499-e61a7b206b27"
      },
      "source": [
        "import os\n",
        "\n",
        "test_data_dir = \"/content/drive/MyDrive/Seg3Data/seg3Data_test/\"\n",
        "\n",
        "print(f\"Listing contents of: {test_data_dir}\")\n",
        "try:\n",
        "    for item in os.listdir(test_data_dir):\n",
        "        print(item)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The directory {test_data_dir} was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of: /content/drive/MyDrive/Seg3Data/seg3Data_test/\n",
            "Error: The directory /content/drive/MyDrive/Seg3Data/seg3Data_test/ was not found.\n"
          ]
        }
      ]
    }
  ]
}