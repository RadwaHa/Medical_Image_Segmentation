{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHkMneAgs2AV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"🔍 فحص توفر GPU...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# التحقق من GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✅ GPU متاح! عدد GPUs: {len(gpus)}\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"   📍 {gpu}\")\n",
        "    # تفعيل memory growth لتجنب استهلاك كل الذاكرة\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ تم تفعيل GPU Memory Growth\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"⚠️ خطأ في تفعيل Memory Growth: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ GPU غير متاح! سيتم استخدام CPU\")\n",
        "    print(\"❗ للتفعيل: Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# طباعة معلومات TensorFlow\n",
        "print(f\"\\n📦 TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"🔧 Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "from google.colab import drive , auth\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vGxsu_5dsUxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9432cb-ca3f-457a-ef4d-efc0d483fc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🔍 فحص توفر GPU...\n",
            "============================================================\n",
            "⚠️ GPU غير متاح! سيتم استخدام CPU\n",
            "❗ للتفعيل: Runtime > Change runtime type > GPU\n",
            "\n",
            "📦 TensorFlow Version: 2.19.0\n",
            "🔧 Built with CUDA: True\n",
            "============================================================\n",
            "\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # المسارات - عدل هذه حسب بيئتك\n",
        "    DATA_DIR = \"/content/chest_ct_segmentation\"  # تأكد من هذا المسار\n",
        "    OUTPUT_DIR = \"/content/results\"\n",
        "\n",
        "    # أبعاد الصورة\n",
        "    IMAGE_HEIGHT = 256\n",
        "    IMAGE_WIDTH = 256\n",
        "    NUM_CLASSES = 3  # الخلفية، الرئة اليسرى، الرئة اليمنى\n",
        "\n",
        "    # معاملات التدريب\n",
        "    EPOCHS = 50  # تقليل للاختبار السريع\n",
        "    BATCH_SIZE = 8\n",
        "    LEARNING_RATE = 1e-4\n",
        "    VALIDATION_SPLIT = 0.2\n",
        "\n",
        "    # Early stopping\n",
        "    PATIENCE_EARLY_STOP = 10\n",
        "    PATIENCE_LR_REDUCE = 5\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "EwkJ1HW-tSVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    \"\"\"تكوين الهايبر باراميترز والمسارات\"\"\"\n",
        "\n",
        "    # قائمة المجلدات التي تحتوي على البيانات\n",
        "    DATA_DIRS = [\n",
        "        \"/content/drive/MyDrive/Seg3Data\",\n",
        "        \"/content/drive/MyDrive/Seg3Data/seg3Data_test\",\n",
        "        \"/content/drive/MyDrive/Seg3Data/seg3Data_train2\"\n",
        "    ]\n",
        "\n",
        "    # أسماء ملفات الـ modalities (بدون .nii أو .nii.gz)\n",
        "    MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "    LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "    # أبعاد البيانات\n",
        "    IMAGE_HEIGHT = 240\n",
        "    IMAGE_WIDTH = 240\n",
        "    NUM_CLASSES = 4\n",
        "\n",
        "    # هايبر باراميترز\n",
        "    EPOCHS = 150\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 1e-4\n",
        "\n",
        "    # إعدادات التدريب\n",
        "    RANDOM_SEED = 42\n",
        "    PATIENCE_EARLY_STOP = 20\n",
        "    PATIENCE_LR_REDUCE = 10\n",
        "\n",
        "    # مسار حفظ النتائج\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "class MRIDataLoader:\n",
        "    \"\"\"فئة لتحميل ومعالجة بيانات MRI من مجلدات متعددة\"\"\"\n",
        "\n",
        "    def __init__(self, data_dirs, modalities, label_file):\n",
        "        self.data_dirs = data_dirs\n",
        "        self.modalities = modalities\n",
        "        self.label_file = label_file\n",
        "\n",
        "    def load_nifti(self, data_dir, filename):\n",
        "        \"\"\"تحميل ملف NIfTI من مجلد محدد\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(data_dir, filename + '.nii'),\n",
        "            os.path.join(data_dir, filename + '.nii.gz'),\n",
        "            os.path.join(data_dir, filename)\n",
        "        ]\n",
        "\n",
        "        filepath = None\n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                filepath = path\n",
        "                break\n",
        "\n",
        "        if filepath is None:\n",
        "            raise FileNotFoundError(f\"لم يتم العثور على الملف: {filename} في {data_dir}\")\n",
        "\n",
        "        print(f\"    - تحميل: {os.path.basename(filepath)}\")\n",
        "        nii = nib.load(filepath)\n",
        "        data = nii.get_fdata()\n",
        "        return data\n",
        "\n",
        "    def normalize_volume(self, volume):\n",
        "        \"\"\"تطبيع البيانات (normalization)\"\"\"\n",
        "        volume = volume.astype(np.float32)\n",
        "        mean = np.mean(volume[volume > 0])\n",
        "        std = np.std(volume[volume > 0])\n",
        "        if std > 0:\n",
        "            volume = (volume - mean) / std\n",
        "        return volume\n",
        "\n",
        "    def load_data_from_folder(self, data_dir):\n",
        "        \"\"\"تحميل البيانات من مجلد واحد\"\"\"\n",
        "        print(f\"\\n  📂 المجلد: {os.path.basename(data_dir)}\")\n",
        "\n",
        "        # تحميل جميع الـ modalities\n",
        "        volumes = {}\n",
        "        for modality in self.modalities:\n",
        "            volume = self.load_nifti(data_dir, modality)\n",
        "            volume = self.normalize_volume(volume)\n",
        "            volumes[modality] = volume\n",
        "\n",
        "        # تحميل الـ labels\n",
        "        labels = self.load_nifti(data_dir, self.label_file)\n",
        "        labels = labels.astype(np.int32)\n",
        "\n",
        "        num_slices = labels.shape[2]\n",
        "        unique_labels = np.unique(labels)\n",
        "        print(f\"    ✓ حجم البيانات: {labels.shape}\")\n",
        "        print(f\"    ✓ عدد الشرائح: {num_slices}\")\n",
        "        print(f\"    ✓ الـ classes: {unique_labels}\")\n",
        "\n",
        "        return volumes, labels, num_slices\n",
        "\n",
        "    def load_all_data(self):\n",
        "        \"\"\"تحميل جميع البيانات من جميع المجلدات\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"بدء تحميل البيانات من جميع المجلدات...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        all_volumes_list = []\n",
        "        all_labels_list = []\n",
        "        all_slice_indices = []\n",
        "        folder_info = []\n",
        "\n",
        "        for folder_idx, data_dir in enumerate(self.data_dirs):\n",
        "            try:\n",
        "                volumes, labels, num_slices = self.load_data_from_folder(data_dir)\n",
        "\n",
        "                # حفظ معلومات المجلد\n",
        "                folder_info.append({\n",
        "                    'folder_idx': folder_idx,\n",
        "                    'path': data_dir,\n",
        "                    'num_slices': num_slices,\n",
        "                    'volumes': volumes,\n",
        "                    'labels': labels\n",
        "                })\n",
        "\n",
        "                # إنشاء قائمة بمؤشرات الشرائح لهذا المجلد\n",
        "                for slice_idx in range(num_slices):\n",
        "                    all_slice_indices.append({\n",
        "                        'folder_idx': folder_idx,\n",
        "                        'slice_idx': slice_idx\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ⚠ خطأ في تحميل المجلد {data_dir}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"✓ تم تحميل البيانات من {len(folder_info)} مجلد\")\n",
        "        print(f\"✓ إجمالي الشرائح: {len(all_slice_indices)}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return folder_info, all_slice_indices\n",
        "\n",
        "\n",
        "class MultiModalityGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generator لتوليد batches من الـ slices من مجلدات متعددة\"\"\"\n",
        "\n",
        "    def __init__(self, folder_info, slice_indices, batch_size,\n",
        "                 num_classes, modalities, image_height, image_width, shuffle=True):\n",
        "        self.folder_info = folder_info\n",
        "        self.slice_indices = slice_indices\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.modalities = modalities\n",
        "        self.image_height = image_height\n",
        "        self.image_width = image_width\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"عدد الـ batches في كل epoch\"\"\"\n",
        "        return int(np.ceil(len(self.slice_indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"توليد batch واحد\"\"\"\n",
        "        batch_indices = self.indices[\n",
        "            index * self.batch_size:(index + 1) * self.batch_size\n",
        "        ]\n",
        "        batch_slices = [self.slice_indices[i] for i in batch_indices]\n",
        "\n",
        "        X, y = self._generate_data(batch_slices)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"خلط البيانات في نهاية كل epoch\"\"\"\n",
        "        self.indices = np.arange(len(self.slice_indices))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def _generate_data(self, batch_slices):\n",
        "        \"\"\"توليد البيانات لـ batch معين\"\"\"\n",
        "        num_modalities = len(self.modalities)\n",
        "\n",
        "        X = np.zeros((len(batch_slices), self.image_height,\n",
        "                      self.image_width, num_modalities), dtype=np.float32)\n",
        "        y = np.zeros((len(batch_slices), self.image_height,\n",
        "                      self.image_width), dtype=np.int32)\n",
        "\n",
        "        for i, slice_info in enumerate(batch_slices):\n",
        "            folder_idx = slice_info['folder_idx']\n",
        "            slice_idx = slice_info['slice_idx']\n",
        "\n",
        "            # الحصول على البيانات من المجلد المناسب\n",
        "            folder_data = self.folder_info[folder_idx]\n",
        "            volumes = folder_data['volumes']\n",
        "            labels = folder_data['labels']\n",
        "\n",
        "            # تجميع جميع الـ modalities\n",
        "            for j, modality in enumerate(self.modalities):\n",
        "                X[i, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "\n",
        "            y[i] = labels[:, :, slice_idx]\n",
        "\n",
        "        # تحويل الـ labels إلى one-hot encoding\n",
        "        y = to_categorical(y, num_classes=self.num_classes)\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "NRoK5QU5tKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingPipeline:\n",
        "    \"\"\"Pipeline كامل للتدريب على مجلدات متعددة\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        np.random.seed(config.RANDOM_SEED)\n",
        "        tf.random.set_seed(config.RANDOM_SEED)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"تحضير البيانات من جميع المجلدات\"\"\"\n",
        "        loader = MRIDataLoader(\n",
        "            self.config.DATA_DIRS,\n",
        "            self.config.MODALITIES,\n",
        "            self.config.LABEL_FILE\n",
        "        )\n",
        "        folder_info, train_slices = loader.load_all_data()\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 تقسيم البيانات:\")\n",
        "        print(f\"  - Training slices: {len(train_slices)}\")\n",
        "        print(f\"  - Training batches: {len(train_slices) // self.config.BATCH_SIZE}\")\n",
        "\n",
        "        return folder_info, train_slices\n",
        "\n",
        "    def create_generators(self, folder_info, train_slices):\n",
        "        \"\"\"إنشاء data generators\"\"\"\n",
        "        train_gen = MultiModalityGenerator(\n",
        "            folder_info, train_slices,\n",
        "            self.config.BATCH_SIZE,\n",
        "            self.config.NUM_CLASSES,\n",
        "            self.config.MODALITIES,\n",
        "            self.config.IMAGE_HEIGHT,\n",
        "            self.config.IMAGE_WIDTH,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "\n",
        "        return train_gen\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_callbacks(self):\n",
        "        \"\"\"إعداد callbacks للتدريب\"\"\"\n",
        "        from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "        callbacks = [\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(self.config.OUTPUT_DIR, 'best_model_val_loss.h5'),\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True,\n",
        "                mode='min',\n",
        "                verbose=1\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(self.config.OUTPUT_DIR, 'best_model_val_iou.h5'),\n",
        "                monitor='val_mean_io_u',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=self.config.PATIENCE_EARLY_STOP,\n",
        "                verbose=1,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=self.config.PATIENCE_LR_REDUCE,\n",
        "                verbose=1,\n",
        "                min_lr=1e-7\n",
        "            )\n",
        "        ]\n",
        "        return callbacks\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"تنفيذ التدريب الكامل\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🚀 بدء Pipeline التدريب على مجلدات متعددة\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # 1. تحضير البيانات\n",
        "        folder_info, train_slices = self.prepare_data()\n",
        "\n",
        "        # 2. إنشاء generators\n",
        "        print(\"\\n📦 إنشاء Data Generators...\")\n",
        "        train_gen= self.create_generators(\n",
        "            folder_info, train_slices\n",
        "        )\n",
        "        print(\"✓ تم إنشاء Generators بنجاح!\")\n",
        "\n",
        "        model = build_unet(\n",
        "            config.IMAGE_HEIGHT,\n",
        "            config.IMAGE_WIDTH,\n",
        "            len(config.MODALITIES),\n",
        "            config.NUM_CLASSES\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=config.NUM_CLASSES)]\n",
        "        )\n",
        "        # 4. التدريب\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🎯 بدء التدريب...\")\n",
        "        print(\"=\"*60)\n",
        "        history = model.fit(\n",
        "            train_gen,\n",
        "            epochs=self.config.EPOCHS,\n",
        "            callbacks=self.get_callbacks(),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ تم الانتهاء من التدريب بنجاح!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return model, history"
      ],
      "metadata": {
        "id": "Ezf212hstL5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yj-p0wC4ga_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training the model :"
      ],
      "metadata": {
        "id": "qfFd-kHEexPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🧠 MRI Multi-Folder Segmentation Pipeline\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n📁 عدد المجلدات: {len(config.DATA_DIRS)}\")\n",
        "for i, folder in enumerate(config.DATA_DIRS, 1):\n",
        "    print(f\"  {i}. {folder}\")\n",
        "print(f\"\\n📊 Modalities: {config.MODALITIES}\")\n",
        "print(f\"🎯 Classes: {config.NUM_CLASSES}\")\n",
        "print(f\"📈 Epochs: {config.EPOCHS}\")\n",
        "print(f\"📦 Batch Size: {config.BATCH_SIZE}\")\n",
        "\n",
        "pipeline = TrainingPipeline(config)\n",
        "model, history = pipeline.train()\n",
        "\n",
        "# حفظ الموديل النهائي\n",
        "final_model_path = os.path.join(config.OUTPUT_DIR, 'final_model.h5')\n",
        "model.save(final_model_path)\n",
        "print(f\"\\n💾 تم حفظ الموديل النهائي في: {final_model_path}\")"
      ],
      "metadata": {
        "id": "ZatiHlcPtW59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4fc7ec-fd50-4346-9fed-3fe1f48a9a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "🧠 MRI Multi-Folder Segmentation Pipeline\n",
            "============================================================\n",
            "\n",
            "📁 عدد المجلدات: 3\n",
            "  1. /content/drive/MyDrive/Seg3Data\n",
            "  2. /content/drive/MyDrive/Seg3Data/seg3Data_test\n",
            "  3. /content/drive/MyDrive/Seg3Data/seg3Data_train2\n",
            "\n",
            "📊 Modalities: ['T1', 'T1_IR', 'T2_FLAIR']\n",
            "🎯 Classes: 4\n",
            "📈 Epochs: 150\n",
            "📦 Batch Size: 32\n",
            "\n",
            "============================================================\n",
            "🚀 بدء Pipeline التدريب على مجلدات متعددة\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "بدء تحميل البيانات من جميع المجلدات...\n",
            "============================================================\n",
            "\n",
            "  📂 المجلد: Seg3Data\n",
            "    - تحميل: T1.nii\n",
            "    - تحميل: T1_IR.nii\n",
            "    - تحميل: T2_FLAIR.nii\n",
            "    - تحميل: LabelsForTesting.nii\n",
            "    ✓ حجم البيانات: (240, 240, 48)\n",
            "    ✓ عدد الشرائح: 48\n",
            "    ✓ الـ classes: [0 1 2 3]\n",
            "\n",
            "  📂 المجلد: seg3Data_test\n",
            "    - تحميل: T1.nii\n",
            "    - تحميل: T1_IR.nii\n",
            "    - تحميل: T2_FLAIR.nii\n",
            "    - تحميل: LabelsForTesting.nii\n",
            "    ✓ حجم البيانات: (240, 240, 48)\n",
            "    ✓ عدد الشرائح: 48\n",
            "    ✓ الـ classes: [0 1 2 3]\n",
            "\n",
            "  📂 المجلد: seg3Data_train2\n",
            "    - تحميل: T1.nii\n",
            "    - تحميل: T1_IR.nii\n",
            "    - تحميل: T2_FLAIR.nii\n",
            "    - تحميل: LabelsForTesting.nii\n",
            "    ✓ حجم البيانات: (240, 240, 48)\n",
            "    ✓ عدد الشرائح: 48\n",
            "    ✓ الـ classes: [0 1 2 3]\n",
            "\n",
            "============================================================\n",
            "✓ تم تحميل البيانات من 3 مجلد\n",
            "✓ إجمالي الشرائح: 144\n",
            "============================================================\n",
            "\n",
            "📊 تقسيم البيانات:\n",
            "  - Training slices: 144\n",
            "  - Training batches: 4\n",
            "\n",
            "📦 إنشاء Data Generators...\n",
            "✓ تم إنشاء Generators بنجاح!\n",
            "\n",
            "============================================================\n",
            "🎯 بدء التدريب...\n",
            "============================================================\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## making the test data ready :"
      ],
      "metadata": {
        "id": "-ibL04GTe9Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestPipeline:\n",
        "    \"\"\"Pipeline للاختبار والتقييم\"\"\"\n",
        "\n",
        "    def __init__(self, model, config):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "\n",
        "    def load_test_data(self, test_data_dir=\"/content/drive/MyDrive/Seg3Data_test\"):\n",
        "        \"\"\"تحميل بيانات الاختبار\"\"\"\n",
        "\n",
        "        print(f\"\\n📂 تحميل بيانات الاختبار من: {test_data_dir}\")\n",
        "\n",
        "        loader = MRIDataLoader(\n",
        "            test_data_dir,\n",
        "            self.config.MODALITIES,\n",
        "            self.config.LABEL_FILE\n",
        "        )\n",
        "        volumes, labels = loader.load_all_data()\n",
        "\n",
        "        return volumes, labels\n",
        "\n",
        "    def predict_slice(self, volumes, slice_idx):\n",
        "        \"\"\"التنبؤ على شريحة واحدة\"\"\"\n",
        "        # تحضير البيانات\n",
        "        X = np.zeros((1, self.config.IMAGE_HEIGHT,\n",
        "                      self.config.IMAGE_WIDTH,\n",
        "                      len(self.config.MODALITIES)), dtype=np.float32)\n",
        "\n",
        "        for j, modality in enumerate(self.config.MODALITIES):\n",
        "            X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "\n",
        "        # التنبؤ\n",
        "        pred = self.model.predict(X, verbose=0)\n",
        "        pred_mask = np.argmax(pred[0], axis=-1)\n",
        "\n",
        "        return pred_mask, pred[0]\n",
        "\n",
        "    def calculate_metrics(self, true_labels, pred_labels):\n",
        "        \"\"\"حساب metrics للتقييم\"\"\"\n",
        "        from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "\n",
        "        # تسطيح المصفوفات\n",
        "        true_flat = true_labels.flatten()\n",
        "        pred_flat = pred_labels.flatten()\n",
        "\n",
        "        # حساب Metrics\n",
        "        accuracy = accuracy_score(true_flat, pred_flat)\n",
        "\n",
        "        # IoU و Dice لكل class\n",
        "        iou_per_class = []\n",
        "        dice_per_class = []\n",
        "\n",
        "        for class_id in range(self.config.NUM_CLASSES):\n",
        "            iou = jaccard_score(true_flat == class_id,\n",
        "                               pred_flat == class_id,\n",
        "                               zero_division=0)\n",
        "            dice = f1_score(true_flat == class_id,\n",
        "                           pred_flat == class_id,\n",
        "                           zero_division=0)\n",
        "            iou_per_class.append(iou)\n",
        "            dice_per_class.append(dice)\n",
        "\n",
        "        mean_iou = np.mean(iou_per_class)\n",
        "        mean_dice = np.mean(dice_per_class)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'mean_iou': mean_iou,\n",
        "            'mean_dice': mean_dice,\n",
        "            'iou_per_class': iou_per_class,\n",
        "            'dice_per_class': dice_per_class\n",
        "        }\n",
        "\n",
        "    def visualize_predictions(self, volumes, labels, slice_indices,\n",
        "                             save_path=None, num_cols=4):\n",
        "        \"\"\"رسم التنبؤات مقابل الحقيقة\"\"\"\n",
        "        num_slices = len(slice_indices)\n",
        "        num_rows = (num_slices + num_cols - 1) // num_cols\n",
        "\n",
        "        fig, axes = plt.subplots(num_rows, num_cols,\n",
        "                                figsize=(num_cols * 5, num_rows * 5))\n",
        "        axes = axes.flatten() if num_slices > 1 else [axes]\n",
        "\n",
        "        for idx, slice_idx in enumerate(slice_indices):\n",
        "            if idx >= len(axes):\n",
        "                break\n",
        "\n",
        "            # التنبؤ\n",
        "            pred_mask, pred_probs = self.predict_slice(volumes, slice_idx)\n",
        "            true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "            # حساب metrics لهذه الشريحة\n",
        "            slice_metrics = self.calculate_metrics(true_mask, pred_mask)\n",
        "\n",
        "            # إنشاء صورة مركبة\n",
        "            # نستخدم أول modality للعرض\n",
        "            first_modality = self.config.MODALITIES[0]\n",
        "            img = volumes[first_modality][:, :, slice_idx]\n",
        "\n",
        "            # تطبيع الصورة للعرض\n",
        "            img_normalized = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "\n",
        "            # إنشاء overlay\n",
        "            ax = axes[idx]\n",
        "            ax.imshow(img_normalized, cmap='gray', alpha=0.7)\n",
        "\n",
        "            # رسم الـ true mask والـ prediction بجانب بعض\n",
        "            true_overlay = np.ma.masked_where(true_mask == 0, true_mask)\n",
        "            pred_overlay = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
        "\n",
        "            # نصف الصورة true، نصفها prediction\n",
        "            h = img.shape[0]\n",
        "\n",
        "            # True mask (النصف الأيسر)\n",
        "            ax.imshow(true_overlay, cmap='Set1', alpha=0.5, vmin=0,\n",
        "                     vmax=self.config.NUM_CLASSES-1)\n",
        "            ax.axvline(x=img.shape[1]//2, color='yellow', linewidth=2,\n",
        "                      linestyle='--', label='Split')\n",
        "\n",
        "            # Prediction mask (النصف الأيمن)\n",
        "            pred_overlay_right = pred_overlay.copy()\n",
        "            pred_overlay_right[:, :img.shape[1]//2] = np.ma.masked\n",
        "            ax.imshow(pred_overlay_right, cmap='Set1', alpha=0.5,\n",
        "                     vmin=0, vmax=self.config.NUM_CLASSES-1)\n",
        "\n",
        "            # العنوان\n",
        "            ax.set_title(f'Slice {slice_idx}\\n'\n",
        "                        f'Acc: {slice_metrics[\"accuracy\"]:.3f} | '\n",
        "                        f'IoU: {slice_metrics[\"mean_iou\"]:.3f} | '\n",
        "                        f'Dice: {slice_metrics[\"mean_dice\"]:.3f}\\n'\n",
        "                        f'Left: Ground Truth | Right: Prediction',\n",
        "                        fontsize=10)\n",
        "            ax.axis('off')\n",
        "\n",
        "        # إخفاء المحاور الفارغة\n",
        "        for idx in range(num_slices, len(axes)):\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"✅ تم حفظ الصور في: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_all_slices(self, volumes, labels, slice_indices=None):\n",
        "        \"\"\"تقييم جميع الشرائح\"\"\"\n",
        "        if slice_indices is None:\n",
        "            slice_indices = range(labels.shape[2])\n",
        "\n",
        "        print(f\"\\n📊 تقييم {len(slice_indices)} شريحة...\")\n",
        "\n",
        "        all_true = []\n",
        "        all_pred = []\n",
        "\n",
        "        for slice_idx in slice_indices:\n",
        "            pred_mask, _ = self.predict_slice(volumes, slice_idx)\n",
        "            true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "            all_true.append(true_mask.flatten())\n",
        "            all_pred.append(pred_mask.flatten())\n",
        "\n",
        "        all_true = np.concatenate(all_true)\n",
        "        all_pred = np.concatenate(all_pred)\n",
        "\n",
        "        # حساب Metrics الإجمالية\n",
        "        metrics = self.calculate_metrics(all_true, all_pred)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📈 نتائج التقييم الإجمالية:\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Overall Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"Mean IoU: {metrics['mean_iou']:.4f}\")\n",
        "        print(f\"Mean Dice: {metrics['mean_dice']:.4f}\")\n",
        "        print(f\"\\nPer-Class Metrics:\")\n",
        "        for i in range(self.config.NUM_CLASSES):\n",
        "            print(f\"  Class {i}:\")\n",
        "            print(f\"    IoU:  {metrics['iou_per_class'][i]:.4f}\")\n",
        "            print(f\"    Dice: {metrics['dice_per_class'][i]:.4f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return metrics"
      ],
      "metadata": {
        "id": "7sM4_WWotp-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D testing result :"
      ],
      "metadata": {
        "id": "0IueubDefIUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# تحديد المسار الصحيح لملف الموديل\n",
        "model_path = \"/content/drive/MyDrive/Seg3Data/results/best_model_val_acc.h5\"\n",
        "\n",
        "# تحميل الموديل\n",
        "model = load_model(model_path)\n",
        "\n",
        "print(\"✅ تم تحميل الموديل بنجاح!\")\n",
        "\n",
        "# إنشاء Test Pipeline\n",
        "\n",
        "\n",
        "test_pipeline = TestPipeline(model, config)\n",
        "\n",
        "print(\"\\n💡 استخدام Test Pipeline:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 🧪 خلية اختبار كاملة ومستقلة - عرض منفصل\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "import random\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🧪 خلية الاختبار الكاملة - عرض منفصل\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 1. الإعدادات\n",
        "# ============================\n",
        "# مسار بيانات الاختبار\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data\"\n",
        "\n",
        "# مسار النموذج المحفوظ\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Seg3Data/results/best_model_val_acc.h5\"\n",
        "\n",
        "# مسار حفظ النتائج\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "# أسماء الملفات\n",
        "MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "# إعدادات أخرى\n",
        "IMAGE_HEIGHT = 240\n",
        "IMAGE_WIDTH = 240\n",
        "NUM_CLASSES = 4  # غيّرها حسب عدد الـ classes عندك\n",
        "\n",
        "# عدد العينات المراد عرضها\n",
        "NUM_SAMPLES = 5\n",
        "\n",
        "print(f\"\\n📁 مسار بيانات الاختبار: {TEST_DATA_DIR}\")\n",
        "print(f\"🤖 مسار النموذج: {MODEL_PATH}\")\n",
        "\n",
        "# ============================\n",
        "# 2. تحميل النموذج\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🤖 تحميل النموذج...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    model = load_model(MODEL_PATH)\n",
        "    print(\"✅ تم تحميل النموذج بنجاح!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ خطأ في تحميل النموذج: {e}\")\n",
        "    raise\n",
        "\n",
        "# ============================\n",
        "# 3. دوال مساعدة\n",
        "# ============================\n",
        "def load_nifti_file(filepath):\n",
        "    \"\"\"تحميل ملف NIfTI\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        if os.path.exists(filepath.replace('.nii.gz', '.nii')):\n",
        "            filepath = filepath.replace('.nii.gz', '.nii')\n",
        "        elif os.path.exists(filepath.replace('.nii', '.nii.gz')):\n",
        "            filepath = filepath.replace('.nii', '.nii.gz')\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"الملف غير موجود: {filepath}\")\n",
        "\n",
        "    nii = nib.load(filepath)\n",
        "    data = nii.get_fdata()\n",
        "    return data\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    \"\"\"تطبيع البيانات\"\"\"\n",
        "    volume = volume.astype(np.float32)\n",
        "    mean = np.mean(volume[volume > 0])\n",
        "    std = np.std(volume[volume > 0])\n",
        "    if std > 0:\n",
        "        volume = (volume - mean) / std\n",
        "    return volume\n",
        "\n",
        "# ============================\n",
        "# 4. تحميل بيانات الاختبار\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📂 تحميل بيانات الاختبار...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not os.path.exists(TEST_DATA_DIR):\n",
        "    print(f\"❌ المجلد غير موجود: {TEST_DATA_DIR}\")\n",
        "    raise FileNotFoundError(f\"المجلد غير موجود: {TEST_DATA_DIR}\")\n",
        "\n",
        "# تحميل جميع الـ modalities\n",
        "volumes = {}\n",
        "for modality in MODALITIES:\n",
        "    filepath = os.path.join(TEST_DATA_DIR, modality + '.nii')\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath = os.path.join(TEST_DATA_DIR, modality + '.nii.gz')\n",
        "\n",
        "    print(f\"   تحميل {modality}...\")\n",
        "    volume = load_nifti_file(filepath)\n",
        "    volume = normalize_volume(volume)\n",
        "    volumes[modality] = volume\n",
        "    print(f\"      ✅ الحجم: {volume.shape}\")\n",
        "\n",
        "# تحميل Labels\n",
        "print(f\"   تحميل {LABEL_FILE}...\")\n",
        "label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii')\n",
        "if not os.path.exists(label_filepath):\n",
        "    label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii.gz')\n",
        "\n",
        "labels = load_nifti_file(label_filepath).astype(np.int32)\n",
        "print(f\"      ✅ الحجم: {labels.shape}\")\n",
        "print(f\"      Classes الموجودة: {np.unique(labels)}\")\n",
        "\n",
        "num_slices = labels.shape[2]\n",
        "print(f\"\\n✅ إجمالي عدد الشرائح: {num_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 5. دالة التنبؤ\n",
        "# ============================\n",
        "def predict_slice(model, volumes, slice_idx, modalities):\n",
        "    \"\"\"التنبؤ على شريحة واحدة\"\"\"\n",
        "    X = np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, len(modalities)), dtype=np.float32)\n",
        "\n",
        "    for j, modality in enumerate(modalities):\n",
        "        X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "\n",
        "    pred = model.predict(X, verbose=0)\n",
        "    pred_mask = np.argmax(pred[0], axis=-1)\n",
        "\n",
        "    return pred_mask\n",
        "\n",
        "# ============================\n",
        "# 6. دالة حساب Metrics\n",
        "# ============================\n",
        "def calculate_metrics(true_labels, pred_labels, num_classes):\n",
        "    \"\"\"حساب metrics\"\"\"\n",
        "    true_flat = true_labels.flatten()\n",
        "    pred_flat = pred_labels.flatten()\n",
        "\n",
        "    accuracy = accuracy_score(true_flat, pred_flat)\n",
        "\n",
        "    iou_per_class = []\n",
        "    dice_per_class = []\n",
        "\n",
        "    for class_id in range(num_classes):\n",
        "        iou = jaccard_score(true_flat == class_id,\n",
        "                           pred_flat == class_id,\n",
        "                           zero_division=0)\n",
        "        dice = f1_score(true_flat == class_id,\n",
        "                       pred_flat == class_id,\n",
        "                       zero_division=0)\n",
        "        iou_per_class.append(iou)\n",
        "        dice_per_class.append(dice)\n",
        "\n",
        "    mean_iou = np.mean(iou_per_class)\n",
        "    mean_dice = np.mean(dice_per_class)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'mean_iou': mean_iou,\n",
        "        'mean_dice': mean_dice,\n",
        "        'iou_per_class': iou_per_class,\n",
        "        'dice_per_class': dice_per_class\n",
        "    }\n",
        "\n",
        "# ============================\n",
        "# 7. دالة رسم منفصلة - كل صورة لوحدها\n",
        "# ============================\n",
        "def visualize_predictions_separate(model, volumes, labels, slice_indices,\n",
        "                                   modalities, num_classes, save_path=None):\n",
        "    \"\"\"رسم التنبؤات - كل صورة منفصلة\"\"\"\n",
        "    num_samples = len(slice_indices)\n",
        "\n",
        "    # كل صف يحتوي على: Image + Ground Truth + Prediction\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
        "\n",
        "    # إذا كان عينة واحدة فقط\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for row_idx, slice_idx in enumerate(slice_indices):\n",
        "        # التنبؤ\n",
        "        pred_mask = predict_slice(model, volumes, slice_idx, modalities)\n",
        "        true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "        # حساب metrics\n",
        "        slice_metrics = calculate_metrics(true_mask, pred_mask, num_classes)\n",
        "\n",
        "        # الصورة الأصلية\n",
        "        first_modality = modalities[0]\n",
        "        img = volumes[first_modality][:, :, slice_idx]\n",
        "        img_normalized = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "\n",
        "        # العمود 1: الصورة الأصلية\n",
        "        axes[row_idx, 0].imshow(img_normalized, cmap='gray')\n",
        "        axes[row_idx, 0].set_title(f'Slice {slice_idx}\\nOriginal Image ({first_modality})',\n",
        "                                   fontsize=12, fontweight='bold')\n",
        "        axes[row_idx, 0].axis('off')\n",
        "\n",
        "        # العمود 2: Ground Truth\n",
        "        axes[row_idx, 1].imshow(img_normalized, cmap='gray', alpha=0.3)\n",
        "        true_overlay = np.ma.masked_where(true_mask == 0, true_mask)\n",
        "        axes[row_idx, 1].imshow(true_overlay, cmap='Set1', alpha=0.7,\n",
        "                               vmin=0, vmax=num_classes-1)\n",
        "        axes[row_idx, 1].set_title('Ground Truth\\n(الحقيقة)',\n",
        "                                  fontsize=12, fontweight='bold', color='green')\n",
        "        axes[row_idx, 1].axis('off')\n",
        "\n",
        "        # العمود 3: Prediction\n",
        "        axes[row_idx, 2].imshow(img_normalized, cmap='gray', alpha=0.3)\n",
        "        pred_overlay = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
        "        axes[row_idx, 2].imshow(pred_overlay, cmap='Set1', alpha=0.7,\n",
        "                               vmin=0, vmax=num_classes-1)\n",
        "        axes[row_idx, 2].set_title(\n",
        "            f'Model Prediction\\n(التنبؤ)\\n'\n",
        "            f'Acc: {slice_metrics[\"accuracy\"]:.3f} | '\n",
        "            f'IoU: {slice_metrics[\"mean_iou\"]:.3f} | '\n",
        "            f'Dice: {slice_metrics[\"mean_dice\"]:.3f}',\n",
        "            fontsize=12, fontweight='bold', color='blue'\n",
        "        )\n",
        "        axes[row_idx, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"✅ تم حفظ الصورة: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 8. اختيار عينات عشوائية من المنتصف\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"🎲 اختيار {NUM_SAMPLES} عينات عشوائية من منتصف البيانات\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# تحديد نطاق المنتصف (25% إلى 75%)\n",
        "start_slice = int(num_slices * 0.25)\n",
        "end_slice = int(num_slices * 0.75)\n",
        "\n",
        "print(f\"نطاق الاختيار: من شريحة {start_slice} إلى {end_slice}\")\n",
        "\n",
        "# اختيار عشوائي من المنتصف\n",
        "random.seed(42)\n",
        "middle_range = list(range(start_slice, end_slice))\n",
        "selected_slices = sorted(random.sample(middle_range, min(NUM_SAMPLES, len(middle_range))))\n",
        "\n",
        "print(f\"الشرائح المختارة: {selected_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 9. عرض النتائج\n",
        "# ============================\n",
        "visualize_predictions_separate(\n",
        "    model, volumes, labels, selected_slices,\n",
        "    MODALITIES, NUM_CLASSES,\n",
        "    save_path=os.path.join(RESULTS_DIR, 'test_separate_samples.png')\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 10. تقييم على الشرائح المختارة\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 تقييم الشرائح المختارة\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for slice_idx in selected_slices:\n",
        "    pred_mask = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "    slice_metrics = calculate_metrics(true_mask, pred_mask, NUM_CLASSES)\n",
        "\n",
        "    print(f\"\\nSlice {slice_idx}:\")\n",
        "    print(f\"  Accuracy: {slice_metrics['accuracy']:.4f} ({slice_metrics['accuracy']*100:.2f}%)\")\n",
        "    print(f\"  Mean IoU: {slice_metrics['mean_iou']:.4f}\")\n",
        "    print(f\"  Mean Dice: {slice_metrics['mean_dice']:.4f}\")\n",
        "\n",
        "# ============================\n",
        "# 11. تقييم شامل (اختياري)\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 هل تريد تقييم شامل على جميع الشرائح؟\")\n",
        "print(\"=\"*60)\n",
        "print(\"يمكنك إلغاء التعليق على الكود التالي:\")\n",
        "print(\"\"\"\n",
        "all_true = []\n",
        "all_pred = []\n",
        "\n",
        "print(\"جاري التنبؤ على جميع الشرائح...\")\n",
        "for slice_idx in range(num_slices):\n",
        "    if (slice_idx + 1) % 10 == 0:\n",
        "        print(f\"   معالجة {slice_idx + 1}/{num_slices}...\")\n",
        "\n",
        "    pred_mask = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_mask = labels[:, :, slice_idx]\n",
        "\n",
        "    all_true.append(true_mask.flatten())\n",
        "    all_pred.append(pred_mask.flatten())\n",
        "\n",
        "all_true = np.concatenate(all_true)\n",
        "all_pred = np.concatenate(all_pred)\n",
        "\n",
        "overall_metrics = calculate_metrics(all_true, all_pred, NUM_CLASSES)\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"📈 النتائج الإجمالية على جميع الشرائح\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Overall Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
        "print(f\"Mean IoU: {overall_metrics['mean_iou']:.4f}\")\n",
        "print(f\"Mean Dice: {overall_metrics['mean_dice']:.4f}\")\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 انتهى الاختبار!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n📁 الملف المحفوظ: test_separate_samples.png\")\n",
        "print(f\"📂 المسار: {RESULTS_DIR}\")\n",
        "\n",
        "# ============================\n",
        "# اختبار النموذج\n",
        "# ============================\n",
        "\n",
        "# 1. اختبار على نفس البيانات (للتحقق السريع)\n",
        "print(\"🧪 بدء الاختبار...\")\n",
        "volumes_test, labels_test = test_pipeline.load_test_data()\n",
        "\n",
        "# عرض 8 شرائح عشوائية\n",
        "import random\n",
        "random_slices = random.sample(range(labels_test.shape[2]), 8)\n",
        "test_pipeline.visualize_predictions(\n",
        "    volumes_test,\n",
        "    labels_test,\n",
        "    random_slices,\n",
        "    save_path=os.path.join(config.OUTPUT_DIR, 'test_predictions.png')\n",
        ")\n",
        "\n",
        "# تقييم جميع الشرائح\n",
        "metrics = test_pipeline.evaluate_all_slices(volumes_test, labels_test)\n",
        "\n",
        "# 2. اختبار على بيانات من مجلد آخر\n",
        "test_dir = \"/content/drive/MyDrive/seg3Data_test\"  # ضع مسار المجلد الجديد\n",
        "\n",
        "volumes_new, labels_new = test_pipeline.load_test_data(test_dir)\n",
        "\n",
        "# اختر شرائح معينة للعرض\n",
        "slices_to_show = [10, 15, 20, 25, 30, 35, 40, 45]\n",
        "test_pipeline.visualize_predictions(\n",
        "    volumes_new,\n",
        "    labels_new,\n",
        "    slices_to_show,\n",
        "    save_path=os.path.join(config.OUTPUT_DIR, 'new_test_predictions.png')\n",
        ")\n",
        "\n",
        "# تقييم كامل\n",
        "metrics_new = test_pipeline.evaluate_all_slices(volumes_new, labels_new)"
      ],
      "metadata": {
        "id": "efG1fYcSffpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3D with VTK**"
      ],
      "metadata": {
        "id": "kEtDS-V-GJkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🧪 خلية اختبار مع عرض 3D محسّن\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import plotly.graph_objects as go\n",
        "from skimage import measure\n",
        "from scipy import ndimage\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🧪 خلية الاختبار مع عرض 3D محسّن\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 1. الإعدادات\n",
        "# ============================\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data/seg3Data_test\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Seg3Data/results/final_model.h5\" # Updated path\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "IMAGE_HEIGHT = 240\n",
        "IMAGE_WIDTH = 240\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# عدد الشرائح للعرض 3D\n",
        "NUM_SLICES_3D = 24\n",
        "\n",
        "print(f\"\\n📁 مسار بيانات الاختبار: {TEST_DATA_DIR}\")\n",
        "print(f\"🤖 مسار النموذج: {MODEL_PATH}\")\n",
        "\n",
        "# ============================\n",
        "# 2. تحميل النموذج\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🤖 تحميل النموذج...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\"✅ تم تحميل النموذج بنجاح!\")\n",
        "\n",
        "# ============================\n",
        "# 3. دوال مساعدة\n",
        "# ============================\n",
        "def load_nifti_file(filepath):\n",
        "    if not os.path.exists(filepath):\n",
        "        if os.path.exists(filepath.replace('.nii.gz', '.nii')):\n",
        "            filepath = filepath.replace('.nii.gz', '.nii')\n",
        "        elif os.path.exists(filepath.replace('.nii', '.nii.gz')):\n",
        "            filepath = filepath.replace('.nii', '.nii.gz')\n",
        "    nii = nib.load(filepath)\n",
        "    return nii.get_fdata()\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    volume = volume.astype(np.float32)\n",
        "    mean = np.mean(volume[volume > 0])\n",
        "    std = np.std(volume[volume > 0])\n",
        "    if std > 0:\n",
        "        volume = (volume - mean) / std\n",
        "    return volume\n",
        "\n",
        "# ============================\n",
        "# 4. تحميل بيانات الاختبار\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📂 تحميل بيانات الاختبار...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "volumes = {}\n",
        "for modality in MODALITIES:\n",
        "    filepath = os.path.join(TEST_DATA_DIR, modality + '.nii')\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath = os.path.join(TEST_DATA_DIR, modality + '.nii.gz')\n",
        "\n",
        "    print(f\"   تحميل {modality}...\")\n",
        "    volume = load_nifti_file(filepath)\n",
        "    volume = normalize_volume(volume)\n",
        "    volumes[modality] = volume\n",
        "\n",
        "label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii')\n",
        "if not os.path.exists(label_filepath):\n",
        "    label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii.gz')\n",
        "\n",
        "labels = load_nifti_file(label_filepath).astype(np.int32)\n",
        "num_slices = labels.shape[2]\n",
        "print(f\"\\n✅ إجمالي عدد الشرائح: {num_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 5. دالة التنبؤ\n",
        "# ============================\n",
        "def predict_slice(model, volumes, slice_idx, modalities):\n",
        "    X = np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, len(modalities)), dtype=np.float32)\n",
        "    for j, modality in enumerate(modalities):\n",
        "        X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "    pred = model.predict(X, verbose=0)\n",
        "    return np.argmax(pred[0], axis=-1)\n",
        "\n",
        "# ============================\n",
        "# 6. التنبؤ على مجموعة شرائح متتالية\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"🔮 التنبؤ على {NUM_SLICES_3D} شريحة متتالية...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_slice = 0\n",
        "end_slice = start_slice + NUM_SLICES_3D\n",
        "\n",
        "if end_slice > num_slices:\n",
        "    end_slice = num_slices\n",
        "    start_slice = end_slice - NUM_SLICES_3D\n",
        "\n",
        "print(f\"نطاق الشرائح: {start_slice} إلى {end_slice}\")\n",
        "\n",
        "# التنبؤ على جميع الشرائح المحددة\n",
        "pred_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "true_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "\n",
        "print(\"جاري التنبؤ...\")\n",
        "for i, slice_idx in enumerate(range(start_slice, end_slice)):\n",
        "    print(f\"   {i+1}/{NUM_SLICES_3D}\")\n",
        "    pred_volume[:, :, i] = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_volume[:, :, i] = labels[:, :, slice_idx]\n",
        "\n",
        "print(\"✅ اكتمل التنبؤ!\")\n",
        "\n",
        "# ============================\n",
        "# 7. دالة عرض 3D محسّنة بنمط VTK (Surface Rendering)\n",
        "# ============================\n",
        "def visualize_3d_surface(volume, title, save_path=None, colors=None):\n",
        "    \"\"\"عرض 3D بنمط Surface Rendering مشابه لـ VTK\"\"\"\n",
        "\n",
        "    if colors is None:\n",
        "        colors = {\n",
        "            1: [1.0, 0.0, 0.0],    # أحمر\n",
        "            2: [0.0, 1.0, 0.0],    # أخضر\n",
        "            3: [0.0, 0.5, 1.0]     # أزرق سماوي\n",
        "        }\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # إزالة الخلفية الرمادية\n",
        "    ax.set_facecolor('black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    # رسم كل class كسطح ثلاثي الأبعاد\n",
        "    for class_id in range(1, NUM_CLASSES):\n",
        "        print(f\"   معالجة Class {class_id}...\")\n",
        "\n",
        "        # إنشاء mask لهذا الـ class\n",
        "        class_mask = (volume == class_id).astype(np.float32)\n",
        "\n",
        "        if np.any(class_mask):\n",
        "            try:\n",
        "                # استخدام marching cubes لإنشاء سطح ثلاثي الأبعاد\n",
        "                verts, faces, normals, values = measure.marching_cubes(\n",
        "                    class_mask,\n",
        "                    level=0.5,\n",
        "                    spacing=(1.0, 1.0, 1.0)\n",
        "                )\n",
        "\n",
        "                # إنشاء mesh collection\n",
        "                mesh = Poly3DCollection(verts[faces], alpha=0.7)\n",
        "                mesh.set_facecolor(colors.get(class_id, [1, 1, 1]))\n",
        "                mesh.set_edgecolor('none')\n",
        "                ax.add_collection3d(mesh)\n",
        "\n",
        "                print(f\"      ✓ تم رسم {len(faces)} مضلع\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"      ⚠ خطأ في معالجة Class {class_id}: {e}\")\n",
        "\n",
        "    # ضبط المحاور\n",
        "    ax.set_xlabel('X', color='white', fontsize=12)\n",
        "    ax.set_ylabel('Y', color='white', fontsize=12)\n",
        "    ax.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "\n",
        "    # ضبط حدود المحاور\n",
        "    ax.set_xlim([0, volume.shape[1]])\n",
        "    ax.set_ylim([0, volume.shape[0]])\n",
        "    ax.set_zlim([0, volume.shape[2]])\n",
        "\n",
        "    # تخصيص ألوان المحاور والشبكة\n",
        "    ax.xaxis.pane.fill = False\n",
        "    ax.yaxis.pane.fill = False\n",
        "    ax.zaxis.pane.fill = False\n",
        "    ax.xaxis.pane.set_edgecolor('gray')\n",
        "    ax.yaxis.pane.set_edgecolor('gray')\n",
        "    ax.zaxis.pane.set_edgecolor('gray')\n",
        "    ax.grid(color='gray', alpha=0.3)\n",
        "\n",
        "    # تغيير ألوان علامات المحاور\n",
        "    ax.tick_params(colors='white')\n",
        "\n",
        "    # ضبط زاوية العرض\n",
        "    ax.view_init(elev=25, azim=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='black')\n",
        "        print(f\"✅ تم حفظ: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 8. دالة عرض Volume Rendering بالألوان\n",
        "# ============================\n",
        "def visualize_3d_volume_slices(volume, title, save_path=None, colors=None):\n",
        "    \"\"\"عرض الشرائح كطبقات ثلاثية الأبعاد ملونة\"\"\"\n",
        "\n",
        "    if colors is None:\n",
        "        colors = {\n",
        "            1: [1.0, 0.0, 0.0],\n",
        "            2: [0.0, 1.0, 0.0],\n",
        "            3: [0.0, 0.5, 1.0]\n",
        "        }\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    ax.set_facecolor('black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    # رسم كل شريحة كطبقة\n",
        "    step = max(1, NUM_SLICES_3D // 12)  # عرض 12 شريحة كحد أقصى\n",
        "\n",
        "    for z_idx in range(0, volume.shape[2], step):\n",
        "        slice_data = volume[:, :, z_idx]\n",
        "\n",
        "        # إنشاء mesh grid للشريحة\n",
        "        x = np.arange(0, slice_data.shape[1])\n",
        "        y = np.arange(0, slice_data.shape[0])\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        Z = np.ones_like(X) * z_idx\n",
        "\n",
        "        # تلوين الشريحة حسب الـ classes\n",
        "        colors_array = np.zeros((slice_data.shape[0], slice_data.shape[1], 4))\n",
        "\n",
        "        for class_id in range(1, NUM_CLASSES):\n",
        "            mask = (slice_data == class_id)\n",
        "            if np.any(mask):\n",
        "                color = colors.get(class_id, [1, 1, 1])\n",
        "                colors_array[mask] = [*color, 0.6]\n",
        "\n",
        "        # رسم السطح\n",
        "        ax.plot_surface(X, Y, Z, facecolors=colors_array,\n",
        "                       shade=False, linewidth=0, antialiased=True)\n",
        "\n",
        "    # ضبط المحاور\n",
        "    ax.set_xlabel('X', color='white', fontsize=12)\n",
        "    ax.set_ylabel('Y', color='white', fontsize=12)\n",
        "    ax.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "\n",
        "    ax.set_xlim([0, volume.shape[1]])\n",
        "    ax.set_ylim([0, volume.shape[0]])\n",
        "    ax.set_zlim([0, volume.shape[2]])\n",
        "\n",
        "    ax.xaxis.pane.fill = False\n",
        "    ax.yaxis.pane.fill = False\n",
        "    ax.zaxis.pane.fill = False\n",
        "    ax.xaxis.pane.set_edgecolor('gray')\n",
        "    ax.yaxis.pane.set_edgecolor('gray')\n",
        "    ax.zaxis.pane.set_edgecolor('gray')\n",
        "    ax.grid(color='gray', alpha=0.3)\n",
        "    ax.tick_params(colors='white')\n",
        "\n",
        "    ax.view_init(elev=25, azim=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='black')\n",
        "        print(f\"✅ تم حفظ: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 9. عرض المقارنة فقط (Ground Truth و Prediction)\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎨 عرض مقارنة 3D...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ألوان غامقة\n",
        "dark_colors = {\n",
        "    1: [0.7, 0.0, 0.0],    # أحمر غامق\n",
        "    2: [0.0, 0.5, 0.0],    # أخضر غامق\n",
        "    3: [0.0, 0.2, 0.6]     # أزرق غامق\n",
        "}\n",
        "\n",
        "fig = plt.figure(figsize=(24, 10))\n",
        "fig.patch.set_facecolor('black')\n",
        "\n",
        "# Ground Truth Surface\n",
        "print(\"\\n📊 معالجة Ground Truth...\")\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.set_facecolor('black')\n",
        "\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (true_volume == class_id).astype(np.float32)\n",
        "    if np.any(class_mask):\n",
        "        try:\n",
        "            print(f\"   معالجة Class {class_id}...\")\n",
        "            verts, faces, _, _ = measure.marching_cubes(class_mask, level=0.5)\n",
        "            mesh = Poly3DCollection(verts[faces], alpha=0.8)\n",
        "            mesh.set_facecolor(dark_colors.get(class_id, [0.5, 0.5, 0.5]))\n",
        "            mesh.set_edgecolor('none')\n",
        "            ax1.add_collection3d(mesh)\n",
        "            print(f\"      ✓ تم رسم {len(faces)} مضلع\")\n",
        "        except Exception as e:\n",
        "            print(f\"      ⚠ خطأ: {e}\")\n",
        "\n",
        "ax1.set_xlim([0, true_volume.shape[1]])\n",
        "ax1.set_ylim([0, true_volume.shape[0]])\n",
        "ax1.set_zlim([0, true_volume.shape[2]])\n",
        "ax1.set_title('Ground Truth', fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "ax1.set_xlabel('X', color='white', fontsize=12)\n",
        "ax1.set_ylabel('Y', color='white', fontsize=12)\n",
        "ax1.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "ax1.xaxis.pane.fill = False\n",
        "ax1.yaxis.pane.fill = False\n",
        "ax1.zaxis.pane.fill = False\n",
        "ax1.xaxis.pane.set_edgecolor('gray')\n",
        "ax1.yaxis.pane.set_edgecolor('gray')\n",
        "ax1.zaxis.pane.set_edgecolor('gray')\n",
        "ax1.grid(color='gray', alpha=0.3)\n",
        "ax1.tick_params(colors='white')\n",
        "ax1.view_init(elev=25, azim=45)\n",
        "\n",
        "# Prediction Surface\n",
        "print(\"\\n📊 معالجة Model Prediction...\")\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "ax2.set_facecolor('black')\n",
        "\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (pred_volume == class_id).astype(np.float32)\n",
        "    if np.any(class_mask):\n",
        "        try:\n",
        "            print(f\"   معالجة Class {class_id}...\")\n",
        "            verts, faces, _, _ = measure.marching_cubes(class_mask, level=0.5)\n",
        "            mesh = Poly3DCollection(verts[faces], alpha=0.8)\n",
        "            mesh.set_facecolor(dark_colors.get(class_id, [0.5, 0.5, 0.5]))\n",
        "            mesh.set_edgecolor('none')\n",
        "            ax2.add_collection3d(mesh)\n",
        "            print(f\"      ✓ تم رسم {len(faces)} مضلع\")\n",
        "        except Exception as e:\n",
        "            print(f\"      ⚠ خطأ: {e}\")\n",
        "\n",
        "ax2.set_xlim([0, pred_volume.shape[1]])\n",
        "ax2.set_ylim([0, pred_volume.shape[0]])\n",
        "ax2.set_zlim([0, pred_volume.shape[2]])\n",
        "ax2.set_title('Model Prediction', fontsize=16, fontweight='bold', color='white', pad=20)\n",
        "ax2.set_xlabel('X', color='white', fontsize=12)\n",
        "ax2.set_ylabel('Y', color='white', fontsize=12)\n",
        "ax2.set_zlabel('Z (Slices)', color='white', fontsize=12)\n",
        "ax2.xaxis.pane.fill = False\n",
        "ax2.yaxis.pane.fill = False\n",
        "ax2.zaxis.pane.fill = False\n",
        "ax2.xaxis.pane.set_edgecolor('gray')\n",
        "ax2.yaxis.pane.set_edgecolor('gray')\n",
        "ax2.zaxis.pane.set_edgecolor('gray')\n",
        "ax2.grid(color='gray', alpha=0.3)\n",
        "ax2.tick_params(colors='white')\n",
        "ax2.view_init(elev=25, azim=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = os.path.join(RESULTS_DIR, '3d_comparison.png')\n",
        "plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='black')\n",
        "print(f\"\\n✅ تم حفظ: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 انتهى العرض 3D!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n📁 الملف المحفوظ:\")\n",
        "print(f\"  - 3d_comparison.png\")\n",
        "print(f\"📂 المسار: {RESULTS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "d3nYct9zGExG",
        "outputId": "1960acad-37c8-4a42-b99d-eda90104bb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🧪 خلية الاختبار مع عرض 3D محسّن\n",
            "============================================================\n",
            "\n",
            "📁 مسار بيانات الاختبار: /content/drive/MyDrive/Seg3Data/seg3Data_test\n",
            "🤖 مسار النموذج: /content/drive/MyDrive/Seg3Data/results/final_model.h5\n",
            "\n",
            "============================================================\n",
            "🤖 تحميل النموذج...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3803793664.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ تم تحميل النموذج بنجاح!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3**D predection**"
      ],
      "metadata": {
        "id": "ngwSKyqk_tXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🧪 خلية اختبار مع عرض 3D\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "import random\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🧪 خلية الاختبار مع عرض 3D\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================\n",
        "# 1. الإعدادات\n",
        "# ============================\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data/seg3Data_test\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Seg3Data/results/final_model.h5\" # Corrected path to the final model\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "MODALITIES = ['T1', 'T1_IR', 'T2_FLAIR']\n",
        "LABEL_FILE = 'LabelsForTesting'\n",
        "\n",
        "IMAGE_HEIGHT = 240\n",
        "IMAGE_WIDTH = 240\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# عدد الشرائح للعرض 3D\n",
        "NUM_SLICES_3D = 24 # يمكنك تغييرها\n",
        "\n",
        "print(f\"\\n📁 مسار بيانات الاختبار: {TEST_DATA_DIR}\")\n",
        "print(f\"🤖 مسار النموذج: {MODEL_PATH}\")\n",
        "\n",
        "# ============================\n",
        "# 2. تحميل النموذج\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🤖 تحميل النموذج...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\"✅ تم تحميل النموذج بنجاح!\")\n",
        "\n",
        "# ============================\n",
        "# 3. دوال مساعدة\n",
        "# ============================\n",
        "def load_nifti_file(filepath):\n",
        "    if not os.path.exists(filepath):\n",
        "        if os.path.exists(filepath.replace('.nii.gz', '.nii')):\n",
        "            filepath = filepath.replace('.nii.gz', '.nii')\n",
        "        elif os.path.exists(filepath.replace('.nii', '.nii.gz')):\n",
        "            filepath = filepath.replace('.nii', '.nii.gz')\n",
        "    nii = nib.load(filepath)\n",
        "    return nii.get_fdata()\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    volume = volume.astype(np.float32)\n",
        "    mean = np.mean(volume[volume > 0])\n",
        "    std = np.std(volume[volume > 0])\n",
        "    if std > 0:\n",
        "        volume = (volume - mean) / std\n",
        "    return volume\n",
        "\n",
        "# ============================\n",
        "# 4. تحميل بيانات الاختبار\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📂 تحميل بيانات الاختبار...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "volumes = {}\n",
        "for modality in MODALITIES:\n",
        "    filepath = os.path.join(TEST_DATA_DIR, modality + '.nii')\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath = os.path.join(TEST_DATA_DIR, modality + '.nii.gz')\n",
        "\n",
        "    print(f\"   تحميل {modality}...\")\n",
        "    volume = load_nifti_file(filepath)\n",
        "    volume = normalize_volume(volume)\n",
        "    volumes[modality] = volume\n",
        "\n",
        "label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii')\n",
        "if not os.path.exists(label_filepath):\n",
        "    label_filepath = os.path.join(TEST_DATA_DIR, LABEL_FILE + '.nii.gz')\n",
        "\n",
        "labels = load_nifti_file(label_filepath).astype(np.int32)\n",
        "num_slices = labels.shape[2]\n",
        "print(f\"\\n✅ إجمالي عدد الشرائح: {num_slices}\")\n",
        "\n",
        "# ============================\n",
        "# 5. دالة التنبؤ\n",
        "# ============================\n",
        "def predict_slice(model, volumes, slice_idx, modalities):\n",
        "    X = np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, len(modalities)), dtype=np.float32)\n",
        "    for j, modality in enumerate(modalities):\n",
        "        X[0, :, :, j] = volumes[modality][:, :, slice_idx]\n",
        "    pred = model.predict(X, verbose=0)\n",
        "    return np.argmax(pred[0], axis=-1)\n",
        "\n",
        "# ============================\n",
        "# 6. التنبؤ على مجموعة شرائح متتالية\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"🔮 التنبؤ على {NUM_SLICES_3D} شريحة متتالية...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_slice = 0\n",
        "end_slice = start_slice + NUM_SLICES_3D\n",
        "\n",
        "if end_slice > num_slices:\n",
        "    end_slice = num_slices\n",
        "    start_slice = end_slice - NUM_SLICES_3D\n",
        "\n",
        "print(f\"نطاق الشرائح: {start_slice} إلى {end_slice}\")\n",
        "\n",
        "# التنبؤ على جميع الشرائح المحددة\n",
        "pred_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "true_volume = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_SLICES_3D), dtype=np.int32)\n",
        "\n",
        "print(\"جاري التنبؤ...\")\n",
        "for i, slice_idx in enumerate(range(start_slice, end_slice)):\n",
        "    print(f\"   {i+1}/{NUM_SLICES_3D}\")\n",
        "    pred_volume[:, :, i] = predict_slice(model, volumes, slice_idx, MODALITIES)\n",
        "    true_volume[:, :, i] = labels[:, :, slice_idx]\n",
        "\n",
        "print(\"✅ اكتمل التنبؤ!\")\n",
        "\n",
        "# ============================\n",
        "# 7. دالة عرض 3D مع ألوان مختلفة لكل label\n",
        "# ============================\n",
        "def visualize_3d_segmentation(volume, title, save_path=None, colors=None):\n",
        "    \"\"\"عرض 3D للـ segmentation مع ألوان مختلفة\"\"\"\n",
        "\n",
        "    # ألوان افتراضية لكل class\n",
        "    if colors is None:\n",
        "        colors = {\n",
        "            0: [0, 0, 0, 0],          # Background - شفاف\n",
        "            1: [1, 0, 0, 0.3],        # Class 1 - أحمر\n",
        "            2: [0, 1, 0, 0.3],        # Class 2 - أخضر\n",
        "            3: [0, 0, 1, 0.3]         # Class 3 - أزرق\n",
        "        }\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 10))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # رسم كل class بلون مختلف\n",
        "    for class_id in range(1, NUM_CLASSES):  # نبدأ من 1 (نتجاهل background)\n",
        "        # إيجاد مواضع هذا الـ class\n",
        "        class_mask = (volume == class_id)\n",
        "\n",
        "        if np.any(class_mask):\n",
        "            # الحصول على الإحداثيات\n",
        "            z, y, x = np.where(class_mask)\n",
        "\n",
        "            # رسم النقاط\n",
        "            color = colors.get(class_id, [1, 1, 1, 0.3])\n",
        "            ax.scatter(x, y, z,\n",
        "                      c=[color[:3]],\n",
        "                      alpha=color[3],\n",
        "                      s=0.5,  # حجم النقطة\n",
        "                      label=f'Class {class_id}')\n",
        "\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Z (Slices)')\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.legend()\n",
        "\n",
        "    # ضبط زاوية العرض\n",
        "    ax.view_init(elev=20, azim=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"✅ تم حفظ: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 8. عرض المقارنة 3D\n",
        "# ============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎨 عرض النتائج بشكل 3D...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# تعريف ألوان مخصصة لكل class\n",
        "custom_colors = {\n",
        "    0: [0, 0, 0, 0],           # Background - شفاف\n",
        "    1: [1, 0, 0, 0.4],         # Class 1 - أحمر فاتح\n",
        "    2: [0, 1, 0, 0.4],         # Class 2 - أخضر فاتح\n",
        "    3: [0, 0.5, 1, 0.4]        # Class 3 - أزرق سماوي\n",
        "}\n",
        "\n",
        "# عرض Ground Truth\n",
        "print(\"\\n📊 عرض Ground Truth...\")\n",
        "visualize_3d_segmentation(\n",
        "    true_volume,\n",
        "    'Ground Truth - 3D Segmentation',\n",
        "    save_path=os.path.join(RESULTS_DIR, '3d_ground_truth.png'),\n",
        "    colors=custom_colors\n",
        ")\n",
        "\n",
        "# عرض Prediction\n",
        "print(\"\\n📊 عرض Model Prediction...\")\n",
        "visualize_3d_segmentation(\n",
        "    pred_volume,\n",
        "    'Model Prediction - 3D Segmentation',\n",
        "    save_path=os.path.join(RESULTS_DIR, '3d_prediction.png'),\n",
        "    colors=custom_colors\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 9. عرض جنب إلى جنب (اختياري)\n",
        "# ============================\n",
        "print(\"\\n📊 عرض مقارنة جنب إلى جنب...\")\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Ground Truth\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (true_volume == class_id)\n",
        "    if np.any(class_mask):\n",
        "        z, y, x = np.where(class_mask)\n",
        "        color = custom_colors.get(class_id, [1, 1, 1, 0.3])\n",
        "        ax1.scatter(x, y, z, c=[color[:3]], alpha=color[3], s=0.5, label=f'Class {class_id}')\n",
        "\n",
        "ax1.set_title('Ground Truth', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('X')\n",
        "ax1.set_ylabel('Y')\n",
        "ax1.set_zlabel('Z')\n",
        "ax1.legend()\n",
        "ax1.view_init(elev=20, azim=45)\n",
        "\n",
        "# Prediction\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "for class_id in range(1, NUM_CLASSES):\n",
        "    class_mask = (pred_volume == class_id)\n",
        "    if np.any(class_mask):\n",
        "        z, y, x = np.where(class_mask)\n",
        "        color = custom_colors.get(class_id, [1, 1, 1, 0.3])\n",
        "        ax2.scatter(x, y, z, c=[color[:3]], alpha=color[3], s=0.5, label=f'Class {class_id}')\n",
        "\n",
        "ax2.set_title('Model Prediction', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('X')\n",
        "ax2.set_ylabel('Y')\n",
        "ax2.set_zlabel('Z')\n",
        "ax2.legend()\n",
        "ax2.view_init(elev=20, azim=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, '3d_comparison.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 انتهى العرض 3D!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n📁 الملفات المحفوظة:\")\n",
        "print(f\"  - 3d_ground_truth.png\")\n",
        "print(f\"  - 3d_prediction.png\")\n",
        "print(f\"  - 3d_comparison.png\")\n",
        "print(f\"📂 المسار: {RESULTS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "iQNQc_hc_tEh",
        "outputId": "e79e7fac-95fe-4491-e49b-bd9f7db33aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🧪 خلية الاختبار مع عرض 3D\n",
            "============================================================\n",
            "\n",
            "📁 مسار بيانات الاختبار: /content/drive/MyDrive/Seg3Data/seg3Data_test\n",
            "🤖 مسار النموذج: /content/drive/MyDrive/Seg3Data/results/final_model.h5\n",
            "\n",
            "============================================================\n",
            "🤖 تحميل النموذج...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1744657017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ تم تحميل النموذج بنجاح!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/Seg3Data/results/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import plotly.graph_objects as go\n",
        "from skimage import measure\n",
        "from scipy import ndimage\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "from tensorflow.keras.models import load_model # Import load_model here\n",
        "from mpl_toolkits.mplot3d import Axes3D # Import Axes3D here\n",
        "from matplotlib import pyplot as plt # Import pyplot here\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection # Import Poly3DCollection\n",
        "\n",
        "# ============================\n",
        "# تثبيت المكتبات المطلوبة (قم بتشغيلها مرة واحدة)\n",
        "# ============================\n",
        "# !pip install plotly scikit-image ipywidgets\n",
        "\n",
        "class Brain3DVisualizer:\n",
        "    \"\"\"فئة لاستخراج وعرض السطح ثلاثي الأبعاد للدماغ\"\"\"\n",
        "\n",
        "    def __init__(self, segmentation_volume):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        segmentation_volume : numpy array\n",
        "            حجم الـ segmentation (3D array) مع قيم الـ classes\n",
        "        \"\"\"\n",
        "        self.volume = segmentation_volume\n",
        "        self.unique_classes = np.unique(segmentation_volume)\n",
        "        self.surfaces = {}\n",
        "        self.colors = {}\n",
        "        self.fig = None\n",
        "\n",
        "        # ألوان افتراضية لكل class\n",
        "        self.default_colors = {\n",
        "            0: 'rgba(0,0,0,0)',      # Background (شفاف)\n",
        "            1: 'rgb(255,0,0)',        # أحمر\n",
        "            2: 'rgb(0,255,0)',        # أخضر\n",
        "            3: 'rgb(0,0,255)',        # أزرق\n",
        "        }\n",
        "\n",
        "    def extract_surface(self, class_id, step_size=2, smooth=True):\n",
        "        \"\"\"\n",
        "        استخراج السطح ثلاثي الأبعاد لـ class معين باستخدام Marching Cubes\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        class_id : int\n",
        "            رقم الـ class المراد استخراج سطحه\n",
        "        step_size : int\n",
        "            خطوة الاستخراج (أكبر = أسرع لكن أقل دقة)\n",
        "        smooth : bool\n",
        "            تطبيق smoothing على الحجم قبل الاستخراج\n",
        "        \"\"\"\n",
        "        print(f\"استخراج السطح للـ class {class_id}...\")\n",
        "\n",
        "        # إنشاء binary mask للـ class\n",
        "        binary_mask = (self.volume == class_id).astype(np.uint8)\n",
        "\n",
        "        # تطبيق smoothing اختياري\n",
        "        if smooth:\n",
        "            binary_mask = ndimage.gaussian_filter(binary_mask.astype(float), sigma=1)\n",
        "\n",
        "        try:\n",
        "            # استخدام marching cubes لاستخراج السطح\n",
        "            verts, faces, normals, values = measure.marching_cubes(\n",
        "                binary_mask,\n",
        "                level=0.5,\n",
        "                step_size=step_size\n",
        "            )\n",
        "\n",
        "            self.surfaces[class_id] = {\n",
        "                'vertices': verts,\n",
        "                'faces': faces,\n",
        "                'normals': normals\n",
        "            }\n",
        "\n",
        "            print(f\"  ✓ تم استخراج {len(verts)} vertices و {len(faces)} faces\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ خطأ في استخراج السطح: {e}\")\n",
        "            self.surfaces[class_id] = None\n",
        "\n",
        "    def extract_all_surfaces(self, step_size=2, smooth=True):\n",
        "        \"\"\"استخراج الأسطح لجميع الـ classes\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"استخراج الأسطح ثلاثية الأبعاد...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for class_id in self.unique_classes:\n",
        "            if class_id == 0:  # تخطي الخلفية\n",
        "                continue\n",
        "            self.extract_surface(class_id, step_size, smooth)\n",
        "\n",
        "        print(\"\\n✓ تم الانتهاء من استخراج جميع الأسطح!\")\n",
        "\n",
        "    def create_mesh_trace(self, class_id, color=None, opacity=1.0, visible=True):\n",
        "        \"\"\"إنشاء mesh trace لـ Plotly\"\"\"\n",
        "\n",
        "        if class_id not in self.surfaces or self.surfaces[class_id] is None:\n",
        "            return None\n",
        "\n",
        "        surface = self.surfaces[class_id]\n",
        "        verts = surface['vertices']\n",
        "        faces = surface['faces']\n",
        "\n",
        "        if color is None:\n",
        "            color = self.default_colors.get(class_id, 'rgb(128,128,128)')\n",
        "\n",
        "        # إنشاء Mesh3d trace\n",
        "        trace = go.Mesh3d(\n",
        "            x=verts[:, 0],\n",
        "            y=verts[:, 1],\n",
        "            z=verts[:, 2],\n",
        "            i=faces[:, 0],\n",
        "            j=faces[:, 1],\n",
        "            k=faces[:, 2],\n",
        "            color=color,\n",
        "            opacity=opacity,\n",
        "            name=f'Class {class_id}',\n",
        "            visible=visible,\n",
        "            hoverinfo='name',\n",
        "            lighting=dict(\n",
        "                ambient=0.5,\n",
        "                diffuse=0.8,\n",
        "                specular=0.2,\n",
        "                roughness=0.5\n",
        "            ),\n",
        "            lightposition=dict(\n",
        "                x=100,\n",
        "                y=200,\n",
        "                z=0\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return trace\n",
        "\n",
        "    def create_interactive_plot(self):\n",
        "        \"\"\"إنشاء الرسم ثلاثي الأبعاد التفاعلي\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"إنشاء العرض التفاعلي...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # إنشاء traces لجميع الـ classes\n",
        "        traces = []\n",
        "        for class_id in self.unique_classes:\n",
        "            if class_id == 0:  # تخطي الخلفية\n",
        "                continue\n",
        "\n",
        "            trace = self.create_mesh_trace(\n",
        "                class_id,\n",
        "                color=self.default_colors.get(class_id),\n",
        "                opacity=0.8,\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "            if trace is not None:\n",
        "                traces.append(trace)\n",
        "\n",
        "        # إنشاء Figure\n",
        "        self.fig = go.Figure(data=traces)\n",
        "\n",
        "        # تحديث Layout\n",
        "        self.fig.update_layout(\n",
        "            title={\n",
        "                'text': '🧠 Brain Segmentation - 3D Interactive Visualization',\n",
        "                'x': 0.5,\n",
        "                'xanchor': 'center',\n",
        "                'font': {'size': 20, 'color': '#2c3e50'}\n",
        "            },\n",
        "            scene=dict(\n",
        "                xaxis=dict(title='X', backgroundcolor=\"rgb(230, 230,230)\"),\n",
        "                yaxis=dict(title='Y', backgroundcolor=\"rgb(230, 230,230)\"),\n",
        "                zaxis=dict(title='Z', backgroundcolor=\"rgb(230, 230,230)\"),\n",
        "                aspectmode='data',\n",
        "                camera=dict(\n",
        "                    eye=dict(x=1.5, y=1.5, z=1.5)\n",
        "                )\n",
        "            ),\n",
        "            width=1000,\n",
        "            height=800,\n",
        "            hovermode='closest',\n",
        "            showlegend=True,\n",
        "            legend=dict(\n",
        "                x=0.02,\n",
        "                y=0.98,\n",
        "                bgcolor='rgba(255,255,255,0.8)',\n",
        "                bordercolor='black',\n",
        "                borderwidth=1\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print(\"✓ تم إنشاء العرض التفاعلي!\")\n",
        "\n",
        "        return self.fig\n",
        "\n",
        "    def show(self):\n",
        "        \"\"\"عرض الرسم\"\"\"\n",
        "        if self.fig is None:\n",
        "            self.create_interactive_plot()\n",
        "        self.fig.show()\n",
        "\n",
        "    def create_control_widgets(self):\n",
        "        \"\"\"إنشاء واجهة تحكم تفاعلية\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"إنشاء عناصر التحكم التفاعلية...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if self.fig is None:\n",
        "            self.create_interactive_plot()\n",
        "\n",
        "        # قاموس لحفظ الـ widgets\n",
        "        controls = {}\n",
        "\n",
        "        for i, class_id in enumerate(self.unique_classes):\n",
        "            if class_id == 0:  # تخطي الخلفية\n",
        "                continue\n",
        "\n",
        "            print(f\"  إنشاء عناصر تحكم للـ Class {class_id}\")\n",
        "\n",
        "            # Visibility toggle\n",
        "            visibility_toggle = widgets.Checkbox(\n",
        "                value=True,\n",
        "                description=f'Show Class {class_id}',\n",
        "                style={'description_width': 'initial'}\n",
        "            )\n",
        "\n",
        "            # Opacity slider\n",
        "            opacity_slider = widgets.FloatSlider(\n",
        "                value=0.8,\n",
        "                min=0.0,\n",
        "                max=1.0,\n",
        "                step=0.05,\n",
        "                description=f'Opacity {class_id}:',\n",
        "                style={'description_width': 'initial'}\n",
        "            )\n",
        "\n",
        "            # Color picker\n",
        "            color_picker = widgets.ColorPicker(\n",
        "                value=self.default_colors.get(class_id, '#808080'),\n",
        "                description=f'Color {class_id}:',\n",
        "                style={'description_width': 'initial'}\n",
        "            )\n",
        "\n",
        "            # دالة التحديث\n",
        "            def update_trace(change, trace_idx=i):\n",
        "                vis = controls[trace_idx]['visibility'].value\n",
        "                opa = controls[trace_idx]['opacity'].value\n",
        "                col = controls[trace_idx]['color'].value\n",
        "\n",
        "                # تحديث الـ trace\n",
        "                with self.fig.batch_update():\n",
        "                    self.fig.data[trace_idx].visible = vis\n",
        "                    self.fig.data[trace_idx].opacity = opa\n",
        "                    self.fig.data[trace_idx].color = col\n",
        "\n",
        "            # ربط الـ widgets بدالة التحديث\n",
        "            visibility_toggle.observe(update_trace, names='value')\n",
        "            opacity_slider.observe(update_trace, names='value')\n",
        "            color_picker.observe(update_trace, names='value')\n",
        "\n",
        "            # حفظ الـ widgets\n",
        "            controls[i] = {\n",
        "                'visibility': visibility_toggle,\n",
        "                'opacity': opacity_slider,\n",
        "                'color': color_picker\n",
        "            }\n",
        "\n",
        "        print(\"✓ تم إنشاء عناصر التحكم!\")\n",
        "\n",
        "        return controls\n",
        "\n",
        "    def display_interactive(self):\n",
        "        \"\"\"عرض الواجهة التفاعلية الكاملة\"\"\"\n",
        "\n",
        "        # إنشاء الـ controls\n",
        "        controls = self.create_control_widgets()\n",
        "\n",
        "        # ترتيب العرض\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🎨 عرض الواجهة التفاعلية الكاملة\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nاستخدم عناصر التحكم أدناه لتغيير:\")\n",
        "        print(\"  • الرؤية (Show/Hide)\")\n",
        "        print(\"  • الشفافية (Opacity)\")\n",
        "        print(\"  • اللون (Color)\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # عرض الـ controls\n",
        "        for i, control_set in controls.items():\n",
        "            box = widgets.VBox([\n",
        "                control_set['visibility'],\n",
        "                control_set['opacity'],\n",
        "                control_set['color'],\n",
        "                widgets.HTML(\"<hr style='margin:10px 0;'>\")\n",
        "            ])\n",
        "            display(box)\n",
        "\n",
        "        # عرض الرسم\n",
        "        display(self.fig)\n",
        "\n",
        "    def save_html(self, filepath):\n",
        "        \"\"\"حفظ العرض التفاعلي كملف HTML\"\"\"\n",
        "        if self.fig is None:\n",
        "            self.create_interactive_plot()\n",
        "\n",
        "        self.fig.write_html(filepath)\n",
        "        print(f\"\\n✓ تم حفظ العرض التفاعلي في: {filepath}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# مثال على الاستخدام\n",
        "# ============================\n",
        "\n",
        "def visualize_segmentation_3d(segmentation_path, output_dir=None, step_size=2):\n",
        "    \"\"\"\n",
        "    دالة رئيسية لتحميل وعرض الـ segmentation ثلاثي الأبعاد\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    segmentation_path : str\n",
        "        مسار ملف الـ segmentation (NIfTI)\n",
        "    output_dir : str\n",
        "        مسار حفظ النتائج (اختياري)\n",
        "    step_size : int\n",
        "        دقة استخراج السطح (أصغر = أعلى دقة لكن أبطأ)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🚀 بدء عملية العرض ثلاثي الأبعاد\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # تحميل ملف الـ segmentation\n",
        "    print(f\"\\n📂 تحميل الملف: {segmentation_path}\")\n",
        "    nii = nib.load(segmentation_path)\n",
        "    volume = nii.get_fdata().astype(np.int32)\n",
        "    print(f\"  ✓ الحجم: {volume.shape}\")\n",
        "    print(f\"  ✓ Classes: {np.unique(volume)}\")\n",
        "\n",
        "    # إنشاء visualizer\n",
        "    viz = Brain3DVisualizer(volume)\n",
        "\n",
        "    # استخراج الأسطح\n",
        "    viz.extract_all_surfaces(step_size=step_size, smooth=True)\n",
        "\n",
        "    # عرض تفاعلي\n",
        "    viz.display_interactive()\n",
        "\n",
        "    # حفظ HTML (اختياري)\n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        html_path = os.path.join(output_dir, '3d_brain_visualization.html')\n",
        "        viz.save_html(html_path)\n",
        "\n",
        "    return viz\n",
        "\n",
        "\n",
        "# ============================\n",
        "# تشغيل على بيانات الاختبار\n",
        "# ============================\n",
        "\n",
        "# استخدم إما ملف الـ labels الأصلي أو الـ predictions\n",
        "# TODO: Verify this path and update if necessary\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/Seg3Data/seg3Data_test/\" # <--- VERIFY THIS PATH\n",
        "# TODO: Verify this file name and path and update if necessary\n",
        "SEGMENTATION_FILE = os.path.join(TEST_DATA_DIR, \"LabelsForTesting.nii\") # <--- VERIFY THIS FILE PATH\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Seg3Data/results\"\n",
        "\n",
        "# تشغيل\n",
        "visualizer = visualize_segmentation_3d(\n",
        "    segmentation_path=SEGMENTATION_FILE,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    step_size=2  # استخدم 1 لأعلى دقة (أبطأ)\n",
        ")\n",
        "\n",
        "print(\"\\n🎉 تم الانتهاء!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "KAX29vJ6iVIZ",
        "outputId": "e3b94e36-d121-4786-eea8-ecfe8874fa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "🚀 بدء عملية العرض ثلاثي الأبعاد\n",
            "============================================================\n",
            "\n",
            "📂 تحميل الملف: /content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or no access: '/content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2837541299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;31m# تشغيل\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m visualizer = visualize_segmentation_3d(\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0msegmentation_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEGMENTATION_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2837541299.py\u001b[0m in \u001b[0;36mvisualize_segmentation_3d\u001b[0;34m(segmentation_path, output_dir, step_size)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# تحميل ملف الـ segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n📂 تحميل الملف: {segmentation_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0mnii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  ✓ الحجم: {volume.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No such file or no access: '{filename}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Empty file: '{filename}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/content/drive/MyDrive/Seg3Data/seg3Data_test/LabelsForTesting.nii'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Cv9ciM5jRqjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e035b5",
        "outputId": "d3f7f983-36bc-4c19-f499-e61a7b206b27"
      },
      "source": [
        "import os\n",
        "\n",
        "test_data_dir = \"/content/drive/MyDrive/Seg3Data/seg3Data_test/\"\n",
        "\n",
        "print(f\"Listing contents of: {test_data_dir}\")\n",
        "try:\n",
        "    for item in os.listdir(test_data_dir):\n",
        "        print(item)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The directory {test_data_dir} was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of: /content/drive/MyDrive/Seg3Data/seg3Data_test/\n",
            "Error: The directory /content/drive/MyDrive/Seg3Data/seg3Data_test/ was not found.\n"
          ]
        }
      ]
    }
  ]
}